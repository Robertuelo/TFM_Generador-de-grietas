{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xYbvevOpr4D9oc39nUgHe1bAS7rrOu_j","timestamp":1687592383100}],"gpuType":"T4","authorship_tag":"ABX9TyO5HiSdvDb2LaMTwHWthcx6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://github.com/ozanciga/gans-with-pytorch/tree/master/wgan-gp"],"metadata":{"id":"8iDPDfODsr0Y"}},{"cell_type":"code","source":["#torch cuda\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"o3O6OVP0srQI","executionInfo":{"status":"ok","timestamp":1687589431742,"user_tz":-120,"elapsed":6182,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coCS0m76swXn","executionInfo":{"status":"ok","timestamp":1687589454842,"user_tz":-120,"elapsed":23102,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"abf0749b-d7c9-4768-f5c2-4b6869bd3aff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import numpy as np"],"metadata":{"id":"Xu5UYC9IszG0","executionInfo":{"status":"ok","timestamp":1687589456260,"user_tz":-120,"elapsed":1422,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UAU_eyz3q6Bz","executionInfo":{"status":"ok","timestamp":1687589630036,"user_tz":-120,"elapsed":440,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"outputs":[],"source":["from torch import nn\n","# from torch.legacy.nn import Identity\n","\n","# Residual network.\n","# WGAN-GP paper defines a residual block with up & downsampling.\n","# See the official implementation (given in the paper).\n","# I use architectures described in the official implementation,\n","# since I find it hard to deduce the blocks given here from the text alone.\n","class MeanPoolConv(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(MeanPoolConv, self).__init__()\n","        conv1 = nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        self.model = nn.Sequential(conv1)\n","\n","    def forward(self, x):\n","        out = (x[:, :, ::2, ::2] + x[:, :, 1::2, ::2] + x[:, :, ::2, 1::2] + x[:, :, 1::2, 1::2]) / 4.0\n","        out = self.model(out)\n","        return out\n","\n","class ConvMeanPool(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(ConvMeanPool, self).__init__()\n","        conv1 = nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        self.model = nn.Sequential(conv1)\n","\n","    def forward(self, x):\n","        out = self.model(x)\n","        out = (out[:, :, ::2, ::2] + out[:, :, 1::2, ::2] + out[:, :, ::2, 1::2] + out[:, :, 1::2, 1::2]) / 4.0\n","        return out\n","\n","class UpsampleConv(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(UpsampleConv, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        )\n","    def forward(self, x):\n","        x = x.repeat((1, 4, 1, 1)) # Weird concat of WGAN-GPs upsampling process.\n","        out = self.model(x)\n","        return out\n","\n","#class UpsampleConv(nn.Module):\n","#    def __init__(self, n_input, n_output, k_size):\n","#        super(UpsampleConv, self).__init__()\n","\n","#        self.model = nn.Sequential(\n","#            nn.PixelShuffle(upscale_factor=2),  # Modificación aquí\n","#            nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","#        )\n","#    def forward(self, x):\n","#        x = x.repeat((1, 4, 1, 1)) # Weird concat of WGAN-GPs upsampling process.\n","#        out = self.model(x)\n","#        return out\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, n_input, n_output, k_size, resample='up', bn=True, spatial_dim=None):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.resample = resample\n","\n","        if resample == 'up':\n","            self.conv1 = UpsampleConv(n_input, n_output, k_size)\n","            self.conv2 = nn.Conv2d(n_output, n_output, k_size, padding=(k_size-1)//2)\n","            self.conv_shortcut = UpsampleConv(n_input, n_output, k_size)\n","            self.out_dim = n_output\n","        elif resample == 'down':\n","            self.conv1 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv2 = ConvMeanPool(n_input, n_output, k_size)\n","            self.conv_shortcut = ConvMeanPool(n_input, n_output, k_size)\n","            self.out_dim = n_output\n","            self.ln_dims = [n_input, spatial_dim, spatial_dim] # Define the dimensions for layer normalization.\n","        else:\n","            self.conv1 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv2 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv_shortcut = None # Identity\n","            self.out_dim = n_input\n","            self.ln_dims = [n_input, spatial_dim, spatial_dim]\n","\n","        self.model = nn.Sequential(\n","            nn.BatchNorm2d(n_input) if bn else nn.LayerNorm(self.ln_dims),\n","            nn.ReLU(inplace=True),\n","            self.conv1,\n","            nn.BatchNorm2d(self.out_dim) if bn else nn.LayerNorm(self.ln_dims),\n","            nn.ReLU(inplace=True),\n","            self.conv2,\n","        )\n","\n","    def forward(self, x):\n","        if self.conv_shortcut is None:\n","            return x + self.model(x)\n","        else:\n","            return self.conv_shortcut(x) + self.model(x)\n","\n","class DiscBlock1(nn.Module):\n","    def __init__(self, n_output):\n","        super(DiscBlock1, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, n_output, 3, padding=(3-1)//2)\n","        self.conv2 = ConvMeanPool(n_output, n_output, 1)\n","        self.conv_shortcut = MeanPoolConv(3, n_output, 1)\n","\n","        self.model = nn.Sequential(\n","            self.conv1,\n","            nn.ReLU(inplace=True),\n","            self.conv2\n","        )\n","\n","    def forward(self, x):\n","        return self.conv_shortcut(x) + self.model(x)\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        self.model = nn.Sequential(                     # 128 x 1 x 1\n","            nn.ConvTranspose2d(128, 128, 4, 1, 0),      # 128 x 4 x 4\n","            #nn.ConvTranspose2d(128, 128, 4, 2, 1),     #Para 64x64 pixeles de entrada\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 8 x 8\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 16 x 16\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 32 x 32\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 3, 3, padding=(3-1)//2),     # 3 x 32 x 32\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        return img\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        n_output = 128\n","        '''\n","        This is a parameter but since we experiment with a single size\n","        of 3 x 32 x 32 images, it is hardcoded here.\n","        '''\n","\n","        self.DiscBlock1 = DiscBlock1(n_output)                      # 128 x 16 x 16\n","\n","        self.model = nn.Sequential(\n","            ResidualBlock(n_output, n_output, 3, resample='down', bn=False, spatial_dim=16),  # 128 x 8 x 8\n","            #ResidualBlock(n_output, n_output, 3, resample='down', bn=False, spatial_dim=32),  #Para 64x64\n","            ResidualBlock(n_output, n_output, 3, resample=None, bn=False, spatial_dim=8),    # 128 x 8 x 8\n","            ResidualBlock(n_output, n_output, 3, resample=None, bn=False, spatial_dim=8),    # 128 x 8 x 8\n","            nn.ReLU(inplace=True),\n","        )\n","        self.l1 = nn.Sequential(nn.Linear(128, 1))                  # 128 x 1\n","\n","    def forward(self, x):\n","        # x = x.view(-1, 3, 32, 32)\n","        y = self.DiscBlock1(x)\n","        y = self.model(y)\n","        y = y.view(x.size(0), 128, -1)\n","        y = y.mean(dim=2)\n","        out = self.l1(y).unsqueeze_(1).unsqueeze_(2) # or *.view(x.size(0), 128, 1, 1, 1)\n","        return out"]},{"cell_type":"code","source":["import torch.utils.data as data\n","\n","class CustomDataset(data.Dataset):\n","    def __init__(self, X_folder, y_folder, transform=None):\n","        self.X_folder = X_folder\n","        self.y_folder = y_folder\n","        self.transform = transform\n","\n","        # Obtener la lista de nombres de archivo en las carpetas\n","        self.X_filenames = [filename for filename in os.listdir(X_folder) if filename.endswith('.jpg')]\n","        self.y_filenames = [filename for filename in os.listdir(y_folder) if filename.endswith('.jpg')]\n","\n","    def __len__(self):\n","        return len(self.X_filenames)\n","\n","    def __getitem__(self, index):\n","      X_filename = self.X_filenames[index]\n","      y_filename = self.y_filenames[index]\n","\n","      if not X_filename.endswith(\".jpg\"):\n","          return self.__getitem__((index + 1) % len(self))\n","\n","      # Cargar las imágenes y las etiquetas\n","      X = Image.open(os.path.join(self.X_folder, X_filename)).convert(\"RGB\")\n","      y = Image.open(os.path.join(self.y_folder, y_filename)).convert(\"RGB\")\n","\n","      if self.transform:\n","          X = self.transform(X)\n","          y = self.transform(y)\n","\n","      return X, y\n","\n","\n","    def get_images(self):\n","        images = []\n","        for X_filename in self.X_filenames:\n","            X = Image.open(os.path.join(self.X_folder, X_filename))\n","            if self.transform:\n","                X = self.transform(X)\n","            images.append(X)\n","        return images\n","\n","    def get_labels(self):\n","            labels = []\n","            for y_filename in self.y_filenames:\n","                y = Image.open(os.path.join(self.y_folder, y_filename))\n","                if self.transform:\n","                    y = self.transform(y)\n","                labels.append(y)\n","            return labels"],"metadata":{"id":"Wf9iRqQjuEtZ","executionInfo":{"status":"ok","timestamp":1687589635008,"user_tz":-120,"elapsed":414,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import argparse\n","\n","import torch\n","from torch import nn, optim\n","from torch.autograd.variable import Variable\n","\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","import torchvision.utils as vutils\n","\n","import errno\n","\n","#from models import Discriminator, Generator\n","\n","#parser = argparse.ArgumentParser()\n","#parser.add_argument('--n_epochs', type=int, default=200, help='number of epochs of training')\n","#parser.add_argument('--batch_size', type=int, default=64, help='size of the batches')\n","#parser.add_argument('--alpha', type=float, default=0.0001, help='adam: learning rate')\n","#parser.add_argument('--b1', type=float, default=0.5, help='adam: beta 1')\n","#parser.add_argument('--b2', type=float, default=0.9, help='adam: beta 2')\n","#parser.add_argument('--n_critic', type=int, default=5, help='number of critic iterations per generator iteration')\n","#parser.add_argument('--lambda_1', type=int, default=10, help='gradient penalty coefficient')\n","#parser.add_argument('--img_size', type=int, default=64, help='size of each image dimension')\n","#parser.add_argument('--channels', type=int, default=3, help='is image rgb (3) or grayscale (1) ?')\n","#parser.add_argument('--display_port', type=int, default=8097, help='where to run the visdom for visualization? useful if running multiple visdom tabs')\n","#parser.add_argument('--display_server', type=str, default=\"http://localhost\", help='visdom server of the web display')\n","#parser.add_argument('--sample_interval', type=int, default=256, help='interval betwen image samples')\n","#opt = parser.parse_args()\n","\n","class Args:\n","    def __init__(self):\n","        self.n_epochs = 100\n","        self.batch_size = 64\n","        self.alpha = 0.0001\n","        self.b1 = 0.5\n","        self.b2 = 0.9\n","        self.n_critic = 5\n","        self.lambda_1 = 10\n","        self.img_size = 32\n","        self.channels = 3\n","        #self.display_port = 8097\n","        #self.display_server = \"http://localhost\"\n","        self.sample_interval = 256\n","opt = Args()\n","\n","\n","#try:\n","#    import visdom\n","#    vis = visdom.Visdom(server=opt.display_server, port=opt.display_port, raise_exceptions=True) # Create vis env.\n","#except ImportError:\n","#    vis = None\n","#else:\n","#    vis.close(None) # Clear all figures.\n","\n","img_dims = (opt.channels, opt.img_size, opt.img_size)\n","n_features = opt.channels * opt.img_size * opt.img_size\n","\n","def init_weights(m):\n","    if isinstance(m, nn.ConvTranspose2d) and m.weight.requires_grad:\n","        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","    elif isinstance(m, nn.Conv2d) and m.weight.requires_grad:\n","        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n","\n","\n","#def load_cifar10(img_size):\n","#    compose = transforms.Compose(\n","#        [transforms.Resize(img_size),\n","#         transforms.ToTensor(),\n","#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","#         ])\n","#    output_dir = './data/cifar10'\n","#    cifar = datasets.CIFAR10(root=output_dir, download=True, train=True,\n","#                             transform=compose)\n","#    return cifar\n","\n","#cifar = load_cifar10(opt.img_size)\n","#batch_iterator = DataLoader(cifar, shuffle=True, batch_size=opt.batch_size) # List, NCHW format.\n","\n","# Definir las rutas de las carpetas de entrenamiento y prueba\n","trainX_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/traindata/traindata/'\n","trainy_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/valdata/valdata/'\n","\n","# Crear las transformaciones\n","transform = transforms.Compose([\n","    transforms.Resize((opt.img_size, opt.img_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","# Con esta implementación personalizada:\n","#class CustomNormalize(object):\n","#    def __init__(self, mean, std):\n","#        self.mean = mean\n","#        self.std = std\n","\n","#    def __call__(self, tensor):\n","        # Convertir los valores de media y desviación estándar a tensores\n","#        mean_tensor = torch.tensor(self.mean)\n","#        std_tensor = torch.tensor(self.std)\n","\n","        # Asegurar que los tensores tengan las dimensiones adecuadas\n","#        if tensor.size(1) != mean_tensor.size(0):\n","#            mean_tensor = mean_tensor.unsqueeze(1).unsqueeze(2)\n","#            std_tensor = std_tensor.unsqueeze(1).unsqueeze(2)\n","\n","        # Normalizar el tensor\n","#        return (tensor - mean_tensor) / std_tensor\n","\n","\n","\n","\n","#transform = transforms.Compose([\n","#    transforms.Resize((opt.img_size, opt.img_size)),\n","#    transforms.ToTensor(),\n","#    CustomNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","#])\n","\n","\n","\n","# Crear el dataset personalizado de entrenamiento\n","dataset_full = CustomDataset(trainX_folder, trainy_folder, transform=transform)\n","# Obtener xtrain e ytrain\n","dataset = dataset_full.get_images()\n","\n","# Crear los dataloaders\n","batch_iterator = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=2)\n","\n","cuda = torch.cuda.is_available()\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","gan_loss = nn.BCELoss()\n","\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=opt.alpha, betas=(opt.b1, opt.b2))\n","optimizer_G = optim.Adam(generator.parameters(), lr=opt.alpha, betas=(opt.b1, opt.b2))\n","\n","# Loss record.\n","g_losses = []\n","d_losses = []\n","epochs = []\n","loss_legend = ['Discriminator', 'Generator']\n","\n","if cuda:\n","    generator = generator.cuda()\n","    discriminator = discriminator.cuda()\n","\n","noise_fixed = Variable(Tensor(25, 128, 1, 1).normal_(0, 1), requires_grad=False) # To track the progress of the GAN.\n","\n","#Generar carpetas para almacenar las imágenes creadas\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/fake_samples')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","\n","for epoch in range(opt.n_epochs):\n","    print('Epoch {}'.format(epoch))\n","    for i, batch in enumerate(batch_iterator):\n","        # == Discriminator update == #\n","        for iter in range(opt.n_critic):\n","            # Sample real and fake images, using notation in paper.\n","            x = Variable(batch.type(Tensor))\n","            noise = Variable(Tensor(batch.size(0), 128, 1, 1).normal_(0, 1))\n","            x_tilde = Variable(generator(noise), requires_grad=True)\n","\n","            epsilon = Variable(Tensor(batch.size(0), 1, 1, 1).uniform_(0, 1))\n","\n","            x_hat = epsilon*x + (1 - epsilon)*x_tilde\n","            x_hat = torch.autograd.Variable(x_hat, requires_grad=True)\n","\n","            x_tilde = Variable(generator(noise), requires_grad=True)\n","\n","            # Ajustar el tamaño de x_tilde para que coincida con x\n","            #x_tilde = F.interpolate(x_tilde, size=x.size()[2:], mode='bilinear', align_corners=False)\n","\n","            #epsilon = Variable(Tensor(batch.size(0), 1, 1, 1).uniform_(0, 1))\n","\n","            #x_hat = epsilon * x + (1 - epsilon) * x_tilde\n","            #x_hat = torch.autograd.Variable(x_hat, requires_grad=True)\n","\n","            # Put the interpolated data through critic.\n","            dw_x = discriminator(x_hat)\n","            # A great exercise on learning how the autograd.grad works!\n","            grad_x = torch.autograd.grad(outputs=dw_x, inputs=x_hat,\n","                                         grad_outputs=Variable(Tensor(batch.size(0), 1, 1, 1).fill_(1.0), requires_grad=False),\n","                                         create_graph=True, retain_graph=True, only_inputs=True)\n","            grad_x = grad_x[0].view(batch.size(0), -1)\n","            grad_x = grad_x.norm(p=2, dim=1) # My naming is inaccurate, this is the 2-norm of grad(D_w(x_hat))\n","\n","            # Update discriminator (or critic, since we don't output probabilities anymore).\n","            optimizer_D.zero_grad()\n","\n","            # WGAN-GP loss, defined properly as a loss unlike the WGAN paper.\n","            d_loss = torch.mean(discriminator(x_tilde)) - torch.mean(discriminator(x)) + opt.lambda_1*torch.mean((grad_x - 1)**2)\n","            # d_loss = torch.mean(d_loss) # there's a reason for why this shouldn't be done this way :)\n","\n","            d_loss.backward()\n","            optimizer_D.step()\n","\n","        # == Generator update == #\n","        noise = Variable(Tensor(batch.size(0), 128, 1, 1).normal_(0, 1))\n","        imgs_fake = generator(noise)\n","\n","        optimizer_G.zero_grad()\n","\n","        g_loss = -torch.mean(discriminator(imgs_fake))\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch+1, 70, i+1, len(batch_iterator), d_loss.data, g_loss.data))\n","        if i % 100 == 0: # Every 100 steps:\n","            vutils.save_image(x, '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/real_samples.png', normalize = True) # We save the real images of the minibatch.\n","            fake = generator(noise) # We get our fake generated images.\n","            vutils.save_image(fake.detach(), f\"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/fake_samples/fake_samples_epoch_{epoch:03d}.png\", normalize=True) # We also save the fake generated images of the minibatch.\n","\n","\n","# Guardar el modelo en un archivo .pth\n","gen_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/generator.pth\"\n","dis_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/discriminator.pth\"\n","\n","torch.save(generator.state_dict(), gen_path)\n","torch.save(discriminator.state_dict(), dis_path)\n","\n","# Función para generar una imagen aleatoria y guardarla en un archivo .jpg\n","def generar_imagen_aleatoria(generator_path, output_path):\n","    # Cargar los pesos del generador desde el archivo .pth\n","    generator = Generator()  # Reemplaza \"Generator()\" con la clase o función que define tu generador\n","    generator.load_state_dict(torch.load(generator_path))\n","    generator.eval()\n","\n","    # Generar una imagen aleatoria\n","    with torch.no_grad():\n","        noise = torch.randn(1, 32, 1, 1)  # Ajusta el tamaño del ruido según tu generador\n","        imagen_generada = generator(noise)\n","\n","    # Guardar la imagen generada en un archivo .jpg\n","    vutils.save_image(imagen_generada, output_path, normalize=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CdvQ52nirB2X","executionInfo":{"status":"error","timestamp":1687590720447,"user_tz":-120,"elapsed":470528,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"98fd16c8-a673-459a-8aff-75f4d3ef04ca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n","[1/70][1/4] Loss_D: 3.3418 Loss_G: 0.1329\n","[1/70][2/4] Loss_D: 0.3129 Loss_G: 0.6926\n","[1/70][3/4] Loss_D: -1.3017 Loss_G: 2.9768\n","[1/70][4/4] Loss_D: -3.2588 Loss_G: 3.2113\n","Epoch 1\n","[2/70][1/4] Loss_D: -7.0726 Loss_G: 6.1896\n","[2/70][2/4] Loss_D: -8.2490 Loss_G: 5.1133\n","[2/70][3/4] Loss_D: -8.4582 Loss_G: 5.1040\n","[2/70][4/4] Loss_D: -7.9932 Loss_G: 4.2572\n","Epoch 2\n","[3/70][1/4] Loss_D: -7.7087 Loss_G: 4.3401\n","[3/70][2/4] Loss_D: -8.2081 Loss_G: 6.5820\n","[3/70][3/4] Loss_D: -7.9591 Loss_G: 7.3586\n","[3/70][4/4] Loss_D: -8.8585 Loss_G: 7.5593\n","Epoch 3\n","[4/70][1/4] Loss_D: -3.7506 Loss_G: 5.3383\n","[4/70][2/4] Loss_D: -8.5901 Loss_G: 7.0899\n","[4/70][3/4] Loss_D: -7.8185 Loss_G: 6.6909\n","[4/70][4/4] Loss_D: -7.5025 Loss_G: 6.3827\n","Epoch 4\n","[5/70][1/4] Loss_D: -6.4543 Loss_G: 8.3698\n","[5/70][2/4] Loss_D: -7.0784 Loss_G: 5.9722\n","[5/70][3/4] Loss_D: -7.2058 Loss_G: -5.4186\n","[5/70][4/4] Loss_D: -5.9803 Loss_G: 5.8591\n","Epoch 5\n","[6/70][1/4] Loss_D: -5.3791 Loss_G: 4.2180\n","[6/70][2/4] Loss_D: -5.3025 Loss_G: 6.7865\n","[6/70][3/4] Loss_D: -4.5585 Loss_G: 4.4438\n","[6/70][4/4] Loss_D: -4.4773 Loss_G: 5.9105\n","Epoch 6\n","[7/70][1/4] Loss_D: -3.8244 Loss_G: 7.9572\n","[7/70][2/4] Loss_D: -3.1264 Loss_G: 2.4697\n","[7/70][3/4] Loss_D: -3.5373 Loss_G: 4.0329\n","[7/70][4/4] Loss_D: -2.7078 Loss_G: 5.0526\n","Epoch 7\n","[8/70][1/4] Loss_D: -3.3697 Loss_G: 6.9910\n","[8/70][2/4] Loss_D: -3.7449 Loss_G: 5.9266\n","[8/70][3/4] Loss_D: -2.9963 Loss_G: 4.6158\n","[8/70][4/4] Loss_D: -2.3651 Loss_G: 4.3393\n","Epoch 8\n","[9/70][1/4] Loss_D: -0.1535 Loss_G: 7.4010\n","[9/70][2/4] Loss_D: -4.9744 Loss_G: 5.3366\n","[9/70][3/4] Loss_D: -2.9682 Loss_G: 3.7182\n","[9/70][4/4] Loss_D: -1.3935 Loss_G: 1.5652\n","Epoch 9\n","[10/70][1/4] Loss_D: -4.8200 Loss_G: 3.4056\n","[10/70][2/4] Loss_D: -3.1813 Loss_G: 8.0454\n","[10/70][3/4] Loss_D: -3.5130 Loss_G: 4.9060\n","[10/70][4/4] Loss_D: -3.0792 Loss_G: 3.7658\n","Epoch 10\n","[11/70][1/4] Loss_D: -1.8047 Loss_G: 0.9427\n","[11/70][2/4] Loss_D: -1.3436 Loss_G: -0.7268\n","[11/70][3/4] Loss_D: -0.4236 Loss_G: -1.7191\n","[11/70][4/4] Loss_D: -0.9215 Loss_G: -2.1512\n","Epoch 11\n","[12/70][1/4] Loss_D: -2.8754 Loss_G: -2.5768\n","[12/70][2/4] Loss_D: -3.6431 Loss_G: -1.6509\n","[12/70][3/4] Loss_D: -2.6273 Loss_G: 0.2364\n","[12/70][4/4] Loss_D: -2.1876 Loss_G: 3.1903\n","Epoch 12\n","[13/70][1/4] Loss_D: -1.6755 Loss_G: 4.5305\n","[13/70][2/4] Loss_D: -1.4700 Loss_G: 3.9677\n","[13/70][3/4] Loss_D: -1.5884 Loss_G: 2.3390\n","[13/70][4/4] Loss_D: -0.5269 Loss_G: -0.7671\n","Epoch 13\n","[14/70][1/4] Loss_D: -2.2271 Loss_G: 2.3257\n","[14/70][2/4] Loss_D: -0.8945 Loss_G: -4.4706\n","[14/70][3/4] Loss_D: 2.0024 Loss_G: -1.2947\n","[14/70][4/4] Loss_D: -2.8262 Loss_G: -0.4060\n","Epoch 14\n","[15/70][1/4] Loss_D: -4.5891 Loss_G: 3.4180\n","[15/70][2/4] Loss_D: -3.2286 Loss_G: 3.0840\n","[15/70][3/4] Loss_D: -0.5584 Loss_G: 2.4428\n","[15/70][4/4] Loss_D: 0.5507 Loss_G: 4.0566\n","Epoch 15\n","[16/70][1/4] Loss_D: -4.0259 Loss_G: 4.9390\n","[16/70][2/4] Loss_D: -4.4035 Loss_G: 3.9221\n","[16/70][3/4] Loss_D: -2.0578 Loss_G: 5.0686\n","[16/70][4/4] Loss_D: 0.0594 Loss_G: 4.8155\n","Epoch 16\n","[17/70][1/4] Loss_D: 4.1955 Loss_G: 7.8737\n","[17/70][2/4] Loss_D: -1.2872 Loss_G: 6.2145\n","[17/70][3/4] Loss_D: -6.5696 Loss_G: 3.4631\n","[17/70][4/4] Loss_D: -6.1754 Loss_G: 0.6575\n","Epoch 17\n","[18/70][1/4] Loss_D: -4.7977 Loss_G: -0.7956\n","[18/70][2/4] Loss_D: -4.6635 Loss_G: -2.3127\n","[18/70][3/4] Loss_D: -3.5428 Loss_G: -0.1855\n","[18/70][4/4] Loss_D: -1.9340 Loss_G: 1.7972\n","Epoch 18\n","[19/70][1/4] Loss_D: -1.3152 Loss_G: 6.1169\n","[19/70][2/4] Loss_D: -2.2408 Loss_G: 6.2504\n","[19/70][3/4] Loss_D: -2.5159 Loss_G: 7.5588\n","[19/70][4/4] Loss_D: -1.4870 Loss_G: 5.6207\n","Epoch 19\n","[20/70][1/4] Loss_D: -1.5353 Loss_G: 3.3369\n","[20/70][2/4] Loss_D: -4.1940 Loss_G: 3.6277\n","[20/70][3/4] Loss_D: -3.5506 Loss_G: 2.5643\n","[20/70][4/4] Loss_D: -2.1529 Loss_G: 2.9734\n","Epoch 20\n","[21/70][1/4] Loss_D: -0.8413 Loss_G: 1.4792\n","[21/70][2/4] Loss_D: -0.4211 Loss_G: 0.3244\n","[21/70][3/4] Loss_D: -4.4605 Loss_G: 0.4528\n","[21/70][4/4] Loss_D: -4.2929 Loss_G: 2.1589\n","Epoch 21\n","[22/70][1/4] Loss_D: -2.2327 Loss_G: -2.1805\n","[22/70][2/4] Loss_D: -0.1311 Loss_G: -1.4971\n","[22/70][3/4] Loss_D: -0.5079 Loss_G: 4.1006\n","[22/70][4/4] Loss_D: -3.3355 Loss_G: 8.7846\n","Epoch 22\n","[23/70][1/4] Loss_D: -3.1243 Loss_G: 8.2998\n","[23/70][2/4] Loss_D: -1.6985 Loss_G: 9.6786\n","[23/70][3/4] Loss_D: -1.3636 Loss_G: 8.6981\n","[23/70][4/4] Loss_D: -2.7549 Loss_G: 6.8977\n","Epoch 23\n","[24/70][1/4] Loss_D: -3.8749 Loss_G: 7.0278\n","[24/70][2/4] Loss_D: -2.2741 Loss_G: 6.8068\n","[24/70][3/4] Loss_D: -0.4456 Loss_G: 5.0620\n","[24/70][4/4] Loss_D: -2.1718 Loss_G: -0.7797\n","Epoch 24\n","[25/70][1/4] Loss_D: -2.3994 Loss_G: -0.3519\n","[25/70][2/4] Loss_D: -1.6657 Loss_G: -3.5257\n","[25/70][3/4] Loss_D: -1.5829 Loss_G: -4.1334\n","[25/70][4/4] Loss_D: -2.6686 Loss_G: 0.1470\n","Epoch 25\n","[26/70][1/4] Loss_D: -3.2809 Loss_G: 4.8494\n","[26/70][2/4] Loss_D: -2.1742 Loss_G: 5.6357\n","[26/70][3/4] Loss_D: -1.2214 Loss_G: 6.7049\n","[26/70][4/4] Loss_D: -0.4920 Loss_G: 2.3221\n","Epoch 26\n","[27/70][1/4] Loss_D: -0.8977 Loss_G: 0.9458\n","[27/70][2/4] Loss_D: -2.5303 Loss_G: -1.1038\n","[27/70][3/4] Loss_D: -2.9948 Loss_G: 0.6436\n","[27/70][4/4] Loss_D: -1.8356 Loss_G: 2.5817\n","Epoch 27\n","[28/70][1/4] Loss_D: -1.1548 Loss_G: 7.8003\n","[28/70][2/4] Loss_D: -1.0214 Loss_G: 9.6720\n","[28/70][3/4] Loss_D: -1.4333 Loss_G: 10.5037\n","[28/70][4/4] Loss_D: -0.7253 Loss_G: 10.8771\n","Epoch 28\n","[29/70][1/4] Loss_D: -0.3818 Loss_G: 8.3818\n","[29/70][2/4] Loss_D: -3.6601 Loss_G: 3.8744\n","[29/70][3/4] Loss_D: -2.6347 Loss_G: -1.2335\n","[29/70][4/4] Loss_D: -1.3857 Loss_G: -5.4885\n","Epoch 29\n","[30/70][1/4] Loss_D: -1.3717 Loss_G: -3.4086\n","[30/70][2/4] Loss_D: -2.2852 Loss_G: -1.0838\n","[30/70][3/4] Loss_D: -1.6896 Loss_G: 0.2953\n","[30/70][4/4] Loss_D: -0.8159 Loss_G: 1.9113\n","Epoch 30\n","[31/70][1/4] Loss_D: -1.9174 Loss_G: 4.1044\n","[31/70][2/4] Loss_D: -2.3959 Loss_G: 2.2108\n","[31/70][3/4] Loss_D: -1.7491 Loss_G: -2.7482\n","[31/70][4/4] Loss_D: -2.1578 Loss_G: -4.3397\n","Epoch 31\n","[32/70][1/4] Loss_D: -1.3954 Loss_G: -0.6833\n","[32/70][2/4] Loss_D: -1.9084 Loss_G: 4.6127\n","[32/70][3/4] Loss_D: -2.2388 Loss_G: 6.7579\n","[32/70][4/4] Loss_D: -2.9781 Loss_G: 9.2826\n","Epoch 32\n","[33/70][1/4] Loss_D: -1.9336 Loss_G: 9.9905\n","[33/70][2/4] Loss_D: -2.6543 Loss_G: 9.3588\n","[33/70][3/4] Loss_D: -1.7416 Loss_G: 3.5215\n","[33/70][4/4] Loss_D: -2.0245 Loss_G: 2.0929\n","Epoch 33\n","[34/70][1/4] Loss_D: -2.6837 Loss_G: 2.6986\n","[34/70][2/4] Loss_D: -1.7483 Loss_G: 1.0979\n","[34/70][3/4] Loss_D: -2.3812 Loss_G: 8.1938\n","[34/70][4/4] Loss_D: -1.7765 Loss_G: 8.1172\n","Epoch 34\n","[35/70][1/4] Loss_D: -1.5091 Loss_G: 7.3880\n","[35/70][2/4] Loss_D: -2.3654 Loss_G: 1.0394\n","[35/70][3/4] Loss_D: -1.4845 Loss_G: 1.6107\n","[35/70][4/4] Loss_D: -1.8729 Loss_G: 8.0422\n","Epoch 35\n","[36/70][1/4] Loss_D: -2.3648 Loss_G: 8.4119\n","[36/70][2/4] Loss_D: -1.7244 Loss_G: 8.8994\n","[36/70][3/4] Loss_D: -1.8964 Loss_G: 5.3731\n","[36/70][4/4] Loss_D: -2.3110 Loss_G: 0.5524\n","Epoch 36\n","[37/70][1/4] Loss_D: -1.4582 Loss_G: -0.0081\n","[37/70][2/4] Loss_D: -2.0368 Loss_G: 4.0499\n","[37/70][3/4] Loss_D: -1.5137 Loss_G: 3.0536\n","[37/70][4/4] Loss_D: -1.6780 Loss_G: 1.3888\n","Epoch 37\n","[38/70][1/4] Loss_D: -1.5128 Loss_G: 4.7463\n","[38/70][2/4] Loss_D: -1.3054 Loss_G: 4.3967\n","[38/70][3/4] Loss_D: -1.7577 Loss_G: 8.3872\n","[38/70][4/4] Loss_D: -2.1166 Loss_G: 9.0869\n","Epoch 38\n","[39/70][1/4] Loss_D: -1.7080 Loss_G: 8.5679\n","[39/70][2/4] Loss_D: -1.5517 Loss_G: 6.9202\n","[39/70][3/4] Loss_D: -1.5870 Loss_G: 4.9026\n","[39/70][4/4] Loss_D: -2.0320 Loss_G: 3.9185\n","Epoch 39\n","[40/70][1/4] Loss_D: -1.4552 Loss_G: 5.4197\n","[40/70][2/4] Loss_D: -1.9909 Loss_G: 5.4402\n","[40/70][3/4] Loss_D: -1.4998 Loss_G: 7.9970\n","[40/70][4/4] Loss_D: -1.5849 Loss_G: 8.7359\n","Epoch 40\n","[41/70][1/4] Loss_D: -2.1337 Loss_G: 6.5256\n","[41/70][2/4] Loss_D: -1.4157 Loss_G: 6.8087\n","[41/70][3/4] Loss_D: -1.6246 Loss_G: 4.2015\n","[41/70][4/4] Loss_D: -2.0133 Loss_G: 7.5408\n","Epoch 41\n","[42/70][1/4] Loss_D: -1.1993 Loss_G: 4.5464\n","[42/70][2/4] Loss_D: -1.6650 Loss_G: 4.4350\n","[42/70][3/4] Loss_D: -1.7115 Loss_G: -0.1993\n","[42/70][4/4] Loss_D: -0.9745 Loss_G: 2.0972\n","Epoch 42\n","[43/70][1/4] Loss_D: -1.3313 Loss_G: 1.5448\n","[43/70][2/4] Loss_D: -1.4592 Loss_G: 8.9101\n","[43/70][3/4] Loss_D: -0.6338 Loss_G: 5.4426\n","[43/70][4/4] Loss_D: -1.5055 Loss_G: 7.7334\n","Epoch 43\n","[44/70][1/4] Loss_D: -2.3025 Loss_G: 4.7280\n","[44/70][2/4] Loss_D: -1.2397 Loss_G: 5.4872\n","[44/70][3/4] Loss_D: -1.2384 Loss_G: 4.8813\n","[44/70][4/4] Loss_D: -2.1815 Loss_G: 5.2835\n","Epoch 44\n","[45/70][1/4] Loss_D: -1.3145 Loss_G: 2.1099\n","[45/70][2/4] Loss_D: -1.2302 Loss_G: -0.0163\n","[45/70][3/4] Loss_D: -2.1342 Loss_G: 9.9662\n","[45/70][4/4] Loss_D: -2.0217 Loss_G: 5.6426\n","Epoch 45\n","[46/70][1/4] Loss_D: -0.5560 Loss_G: 4.4640\n","[46/70][2/4] Loss_D: -0.4584 Loss_G: 2.3130\n","[46/70][3/4] Loss_D: -3.0050 Loss_G: 8.0657\n","[46/70][4/4] Loss_D: -2.9313 Loss_G: 8.8010\n","Epoch 46\n","[47/70][1/4] Loss_D: -0.9856 Loss_G: 10.8965\n","[47/70][2/4] Loss_D: -1.0810 Loss_G: 11.3798\n","[47/70][3/4] Loss_D: -1.8743 Loss_G: 6.5046\n","[47/70][4/4] Loss_D: -2.2126 Loss_G: 9.1740\n","Epoch 47\n","[48/70][1/4] Loss_D: -2.7163 Loss_G: 6.7237\n","[48/70][2/4] Loss_D: -0.9224 Loss_G: 3.9477\n","[48/70][3/4] Loss_D: -0.5973 Loss_G: 1.2068\n","[48/70][4/4] Loss_D: -1.7198 Loss_G: 1.0655\n","Epoch 48\n","[49/70][1/4] Loss_D: -3.1342 Loss_G: 5.2333\n","[49/70][2/4] Loss_D: -2.4490 Loss_G: 7.7118\n","[49/70][3/4] Loss_D: -0.6139 Loss_G: 6.8313\n","[49/70][4/4] Loss_D: -0.6654 Loss_G: 8.4992\n","Epoch 49\n","[50/70][1/4] Loss_D: -1.3389 Loss_G: 4.7597\n","[50/70][2/4] Loss_D: -1.4986 Loss_G: 0.8807\n","[50/70][3/4] Loss_D: -0.9768 Loss_G: -4.6905\n","[50/70][4/4] Loss_D: -2.0999 Loss_G: -1.0610\n","Epoch 50\n","[51/70][1/4] Loss_D: -1.7000 Loss_G: 0.0090\n","[51/70][2/4] Loss_D: -0.6061 Loss_G: 5.5426\n","[51/70][3/4] Loss_D: -0.3511 Loss_G: 15.1898\n","[51/70][4/4] Loss_D: -1.7203 Loss_G: 10.5621\n","Epoch 51\n","[52/70][1/4] Loss_D: -1.8843 Loss_G: 9.9124\n","[52/70][2/4] Loss_D: -0.6951 Loss_G: 8.5568\n","[52/70][3/4] Loss_D: -0.2297 Loss_G: 0.5619\n","[52/70][4/4] Loss_D: -1.9285 Loss_G: -0.1602\n","Epoch 52\n","[53/70][1/4] Loss_D: -2.9644 Loss_G: 4.5562\n","[53/70][2/4] Loss_D: -3.4311 Loss_G: 5.2977\n","[53/70][3/4] Loss_D: -3.0086 Loss_G: 4.2566\n","[53/70][4/4] Loss_D: -1.7538 Loss_G: 5.1917\n","Epoch 53\n","[54/70][1/4] Loss_D: -0.8039 Loss_G: 2.6064\n","[54/70][2/4] Loss_D: -1.8191 Loss_G: 3.4027\n","[54/70][3/4] Loss_D: -1.6390 Loss_G: 8.4546\n","[54/70][4/4] Loss_D: -1.0515 Loss_G: 10.4457\n","Epoch 54\n","[55/70][1/4] Loss_D: -0.1028 Loss_G: 12.9569\n","[55/70][2/4] Loss_D: 0.7563 Loss_G: 15.5665\n","[55/70][3/4] Loss_D: -1.1633 Loss_G: 10.2873\n","[55/70][4/4] Loss_D: -2.2988 Loss_G: 1.4608\n","Epoch 55\n","[56/70][1/4] Loss_D: -2.6006 Loss_G: -2.9714\n","[56/70][2/4] Loss_D: -2.5312 Loss_G: -7.5294\n","[56/70][3/4] Loss_D: -2.1391 Loss_G: -7.6056\n","[56/70][4/4] Loss_D: -2.4235 Loss_G: -4.4140\n","Epoch 56\n","[57/70][1/4] Loss_D: -2.1595 Loss_G: -6.1409\n","[57/70][2/4] Loss_D: -1.2772 Loss_G: -1.8049\n","[57/70][3/4] Loss_D: -0.5294 Loss_G: -7.4626\n","[57/70][4/4] Loss_D: -1.1999 Loss_G: -3.4262\n","Epoch 57\n","[58/70][1/4] Loss_D: -0.8443 Loss_G: -2.0962\n","[58/70][2/4] Loss_D: -0.2440 Loss_G: 0.0302\n","[58/70][3/4] Loss_D: -1.9252 Loss_G: 4.0403\n","[58/70][4/4] Loss_D: -2.0792 Loss_G: 8.7441\n","Epoch 58\n","[59/70][1/4] Loss_D: -0.8286 Loss_G: 6.3170\n","[59/70][2/4] Loss_D: -0.3641 Loss_G: -3.3704\n","[59/70][3/4] Loss_D: -1.8141 Loss_G: 0.9852\n","[59/70][4/4] Loss_D: -2.2395 Loss_G: 0.6310\n","Epoch 59\n","[60/70][1/4] Loss_D: -1.0450 Loss_G: -0.6976\n","[60/70][2/4] Loss_D: -0.7016 Loss_G: -2.6506\n","[60/70][3/4] Loss_D: -1.7849 Loss_G: -1.6286\n","[60/70][4/4] Loss_D: -1.3361 Loss_G: -4.1832\n","Epoch 60\n","[61/70][1/4] Loss_D: -1.0328 Loss_G: -5.0947\n","[61/70][2/4] Loss_D: -1.5828 Loss_G: -0.2582\n","[61/70][3/4] Loss_D: -1.6709 Loss_G: 1.3568\n","[61/70][4/4] Loss_D: -0.5713 Loss_G: 2.7234\n","Epoch 61\n","[62/70][1/4] Loss_D: -1.2566 Loss_G: 4.6163\n","[62/70][2/4] Loss_D: -1.3674 Loss_G: 1.8282\n","[62/70][3/4] Loss_D: -1.0726 Loss_G: -0.0697\n","[62/70][4/4] Loss_D: -1.4592 Loss_G: 2.8025\n","Epoch 62\n","[63/70][1/4] Loss_D: -1.7826 Loss_G: 4.3101\n","[63/70][2/4] Loss_D: -1.3457 Loss_G: 4.3120\n","[63/70][3/4] Loss_D: -1.5486 Loss_G: 0.1407\n","[63/70][4/4] Loss_D: -1.3026 Loss_G: -1.1082\n","Epoch 63\n","[64/70][1/4] Loss_D: -1.2030 Loss_G: 1.6721\n","[64/70][2/4] Loss_D: -2.0599 Loss_G: 2.0688\n","[64/70][3/4] Loss_D: -1.3063 Loss_G: 1.2502\n","[64/70][4/4] Loss_D: -1.4496 Loss_G: -0.7954\n","Epoch 64\n","[65/70][1/4] Loss_D: -1.8087 Loss_G: 1.3487\n","[65/70][2/4] Loss_D: -1.0924 Loss_G: 5.5474\n","[65/70][3/4] Loss_D: -1.3546 Loss_G: 8.5547\n","[65/70][4/4] Loss_D: -2.3722 Loss_G: 8.6596\n","Epoch 65\n","[66/70][1/4] Loss_D: -1.7894 Loss_G: 5.4670\n","[66/70][2/4] Loss_D: -0.7943 Loss_G: 2.3967\n","[66/70][3/4] Loss_D: -0.3758 Loss_G: -3.7908\n","[66/70][4/4] Loss_D: -2.3133 Loss_G: -5.0349\n","Epoch 66\n","[67/70][1/4] Loss_D: -2.2830 Loss_G: -4.1271\n","[67/70][2/4] Loss_D: -1.5062 Loss_G: -1.9586\n","[67/70][3/4] Loss_D: -1.1419 Loss_G: 5.8278\n","[67/70][4/4] Loss_D: -1.6626 Loss_G: 10.3203\n","Epoch 67\n","[68/70][1/4] Loss_D: -1.7107 Loss_G: 11.7179\n","[68/70][2/4] Loss_D: -1.1792 Loss_G: 12.1060\n","[68/70][3/4] Loss_D: -1.2993 Loss_G: 13.2728\n","[68/70][4/4] Loss_D: -2.0529 Loss_G: 8.9540\n","Epoch 68\n","[69/70][1/4] Loss_D: -2.4670 Loss_G: 3.3273\n","[69/70][2/4] Loss_D: -2.7300 Loss_G: -3.6038\n","[69/70][3/4] Loss_D: -2.0842 Loss_G: -4.6121\n","[69/70][4/4] Loss_D: -1.4860 Loss_G: -3.7657\n","Epoch 69\n","[70/70][1/4] Loss_D: -1.9052 Loss_G: 4.8384\n","[70/70][2/4] Loss_D: -1.6454 Loss_G: 5.9019\n","[70/70][3/4] Loss_D: -0.9912 Loss_G: 7.1527\n","[70/70][4/4] Loss_D: -0.2175 Loss_G: 8.7692\n","Epoch 70\n","[71/70][1/4] Loss_D: -1.7690 Loss_G: 7.3137\n","[71/70][2/4] Loss_D: -1.6096 Loss_G: 9.2791\n","[71/70][3/4] Loss_D: -1.6424 Loss_G: 7.2613\n","[71/70][4/4] Loss_D: -0.9822 Loss_G: 4.8950\n","Epoch 71\n","[72/70][1/4] Loss_D: -1.1309 Loss_G: 1.3842\n","[72/70][2/4] Loss_D: -1.2667 Loss_G: -0.9028\n","[72/70][3/4] Loss_D: -1.3547 Loss_G: -3.2525\n","[72/70][4/4] Loss_D: -1.6237 Loss_G: -2.7600\n","Epoch 72\n","[73/70][1/4] Loss_D: -2.0710 Loss_G: 0.7875\n","[73/70][2/4] Loss_D: -2.2585 Loss_G: 0.7808\n","[73/70][3/4] Loss_D: -1.8755 Loss_G: 3.1211\n","[73/70][4/4] Loss_D: -1.9648 Loss_G: 3.8761\n","Epoch 73\n","[74/70][1/4] Loss_D: -1.8400 Loss_G: 3.7942\n","[74/70][2/4] Loss_D: -0.4503 Loss_G: 2.6425\n","[74/70][3/4] Loss_D: -0.1423 Loss_G: 1.3547\n","[74/70][4/4] Loss_D: -0.9168 Loss_G: -1.8900\n","Epoch 74\n","[75/70][1/4] Loss_D: -1.4354 Loss_G: -2.2183\n","[75/70][2/4] Loss_D: -1.3931 Loss_G: -6.2406\n","[75/70][3/4] Loss_D: -1.0150 Loss_G: -5.1948\n","[75/70][4/4] Loss_D: -1.5820 Loss_G: -0.7477\n","Epoch 75\n","[76/70][1/4] Loss_D: -1.3327 Loss_G: 3.1291\n","[76/70][2/4] Loss_D: -0.7885 Loss_G: 0.1874\n","[76/70][3/4] Loss_D: -0.8329 Loss_G: 2.3210\n","[76/70][4/4] Loss_D: -1.4877 Loss_G: 3.3241\n","Epoch 76\n","[77/70][1/4] Loss_D: -1.4582 Loss_G: 2.6431\n","[77/70][2/4] Loss_D: -1.6170 Loss_G: 6.8456\n","[77/70][3/4] Loss_D: -1.5291 Loss_G: -2.9258\n","[77/70][4/4] Loss_D: -1.1787 Loss_G: -5.8880\n","Epoch 77\n","[78/70][1/4] Loss_D: -1.4377 Loss_G: 2.8757\n","[78/70][2/4] Loss_D: -1.4657 Loss_G: 1.9439\n","[78/70][3/4] Loss_D: -1.2712 Loss_G: 6.3963\n","[78/70][4/4] Loss_D: -1.3892 Loss_G: 5.4655\n","Epoch 78\n","[79/70][1/4] Loss_D: -1.4172 Loss_G: 4.4160\n","[79/70][2/4] Loss_D: -1.1530 Loss_G: 9.4481\n","[79/70][3/4] Loss_D: -1.3773 Loss_G: -2.5212\n","[79/70][4/4] Loss_D: -1.4523 Loss_G: 9.1170\n","Epoch 79\n","[80/70][1/4] Loss_D: -1.5951 Loss_G: 7.8484\n","[80/70][2/4] Loss_D: -1.3481 Loss_G: 4.1170\n","[80/70][3/4] Loss_D: -1.3796 Loss_G: 4.4649\n","[80/70][4/4] Loss_D: -1.4758 Loss_G: 7.9277\n","Epoch 80\n","[81/70][1/4] Loss_D: -1.4289 Loss_G: 4.5448\n","[81/70][2/4] Loss_D: -1.4730 Loss_G: 1.1282\n","[81/70][3/4] Loss_D: -1.4131 Loss_G: 6.7135\n","[81/70][4/4] Loss_D: -1.7077 Loss_G: 9.6060\n","Epoch 81\n","[82/70][1/4] Loss_D: -1.2050 Loss_G: 2.7437\n","[82/70][2/4] Loss_D: -1.4233 Loss_G: 1.4165\n","[82/70][3/4] Loss_D: -1.5420 Loss_G: 4.0877\n","[82/70][4/4] Loss_D: -1.5143 Loss_G: -0.1546\n","Epoch 82\n","[83/70][1/4] Loss_D: -1.2215 Loss_G: 2.5655\n","[83/70][2/4] Loss_D: -0.9900 Loss_G: 1.3651\n","[83/70][3/4] Loss_D: -1.4598 Loss_G: 9.1675\n","[83/70][4/4] Loss_D: -1.2091 Loss_G: 8.7399\n","Epoch 83\n","[84/70][1/4] Loss_D: -1.6544 Loss_G: 4.2700\n","[84/70][2/4] Loss_D: -1.6502 Loss_G: 0.9551\n","[84/70][3/4] Loss_D: -1.2009 Loss_G: 1.3746\n","[84/70][4/4] Loss_D: -2.0326 Loss_G: 2.7431\n","Epoch 84\n","[85/70][1/4] Loss_D: -1.6551 Loss_G: 0.0363\n","[85/70][2/4] Loss_D: -1.2605 Loss_G: -3.5519\n","[85/70][3/4] Loss_D: -1.8369 Loss_G: 0.7060\n","[85/70][4/4] Loss_D: -1.4623 Loss_G: 2.5000\n","Epoch 85\n","[86/70][1/4] Loss_D: -0.9842 Loss_G: 9.8104\n","[86/70][2/4] Loss_D: -1.4562 Loss_G: 8.7945\n","[86/70][3/4] Loss_D: -1.9594 Loss_G: 6.1667\n","[86/70][4/4] Loss_D: -1.4208 Loss_G: 8.4054\n","Epoch 86\n","[87/70][1/4] Loss_D: -0.7979 Loss_G: 9.1350\n","[87/70][2/4] Loss_D: -1.8284 Loss_G: 4.5664\n","[87/70][3/4] Loss_D: -1.0745 Loss_G: 2.1876\n","[87/70][4/4] Loss_D: -0.9568 Loss_G: -5.3934\n","Epoch 87\n","[88/70][1/4] Loss_D: -0.8201 Loss_G: -6.6776\n","[88/70][2/4] Loss_D: -1.8045 Loss_G: -0.7670\n","[88/70][3/4] Loss_D: -1.9925 Loss_G: 4.8640\n","[88/70][4/4] Loss_D: -1.1132 Loss_G: 4.7337\n","Epoch 88\n","[89/70][1/4] Loss_D: -0.0557 Loss_G: 6.7653\n","[89/70][2/4] Loss_D: 1.4930 Loss_G: 8.4099\n","[89/70][3/4] Loss_D: -3.5199 Loss_G: 5.4169\n","[89/70][4/4] Loss_D: -3.0770 Loss_G: 2.9930\n","Epoch 89\n","[90/70][1/4] Loss_D: -1.9462 Loss_G: 2.2716\n","[90/70][2/4] Loss_D: -0.2417 Loss_G: 5.1639\n","[90/70][3/4] Loss_D: -0.0379 Loss_G: 14.7800\n","[90/70][4/4] Loss_D: -0.9782 Loss_G: 18.1494\n","Epoch 90\n","[91/70][1/4] Loss_D: -1.2436 Loss_G: 15.7659\n","[91/70][2/4] Loss_D: -1.9413 Loss_G: 7.5216\n","[91/70][3/4] Loss_D: -2.0587 Loss_G: -1.2906\n","[91/70][4/4] Loss_D: -1.7642 Loss_G: -5.4991\n","Epoch 91\n","[92/70][1/4] Loss_D: -1.6713 Loss_G: -5.2258\n","[92/70][2/4] Loss_D: -1.2845 Loss_G: -8.1331\n","[92/70][3/4] Loss_D: -1.0173 Loss_G: -4.1975\n","[92/70][4/4] Loss_D: -2.5693 Loss_G: -3.9030\n","Epoch 92\n","[93/70][1/4] Loss_D: -1.2441 Loss_G: -1.1234\n","[93/70][2/4] Loss_D: -0.8049 Loss_G: -3.4151\n","[93/70][3/4] Loss_D: -0.7999 Loss_G: 1.3531\n","[93/70][4/4] Loss_D: -1.9988 Loss_G: 5.9723\n","Epoch 93\n","[94/70][1/4] Loss_D: -1.3200 Loss_G: 10.7090\n","[94/70][2/4] Loss_D: -1.3921 Loss_G: 11.3547\n","[94/70][3/4] Loss_D: -1.1412 Loss_G: 10.8299\n","[94/70][4/4] Loss_D: -0.9341 Loss_G: 7.6938\n","Epoch 94\n","[95/70][1/4] Loss_D: -0.9730 Loss_G: 2.9034\n","[95/70][2/4] Loss_D: -1.0544 Loss_G: -1.5338\n","[95/70][3/4] Loss_D: -1.5969 Loss_G: -4.0670\n","[95/70][4/4] Loss_D: -1.1290 Loss_G: 1.2339\n","Epoch 95\n","[96/70][1/4] Loss_D: -1.1171 Loss_G: 2.2620\n","[96/70][2/4] Loss_D: -0.9825 Loss_G: 5.0475\n","[96/70][3/4] Loss_D: -1.0161 Loss_G: 3.9581\n","[96/70][4/4] Loss_D: -1.0546 Loss_G: 6.7756\n","Epoch 96\n","[97/70][1/4] Loss_D: -1.6198 Loss_G: 8.9035\n","[97/70][2/4] Loss_D: -1.3236 Loss_G: 8.8907\n","[97/70][3/4] Loss_D: -0.8692 Loss_G: 5.7062\n","[97/70][4/4] Loss_D: -1.0580 Loss_G: 6.6639\n","Epoch 97\n","[98/70][1/4] Loss_D: -1.8196 Loss_G: 3.5686\n","[98/70][2/4] Loss_D: -1.6557 Loss_G: 4.0651\n","[98/70][3/4] Loss_D: -0.4377 Loss_G: 3.4811\n","[98/70][4/4] Loss_D: -1.2529 Loss_G: 3.7983\n","Epoch 98\n","[99/70][1/4] Loss_D: -1.5206 Loss_G: 0.9901\n","[99/70][2/4] Loss_D: -0.6261 Loss_G: 4.0988\n","[99/70][3/4] Loss_D: -1.0999 Loss_G: 2.7577\n","[99/70][4/4] Loss_D: -1.3464 Loss_G: 5.7423\n","Epoch 99\n","[100/70][1/4] Loss_D: -1.0378 Loss_G: 4.9234\n","[100/70][2/4] Loss_D: -1.2701 Loss_G: 10.1393\n","[100/70][3/4] Loss_D: -1.2452 Loss_G: 6.4523\n","[100/70][4/4] Loss_D: -0.6815 Loss_G: 6.6116\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-8890bdb75945>\u001b[0m in \u001b[0;36m<cell line: 228>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0mdis_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/discriminator.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models does not exist."]}]},{"cell_type":"code","source":["# Guardar el modelo en un archivo .pth\n","gen_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/generator.pth\"\n","dis_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/discriminator.pth\"\n","\n","torch.save(generator.state_dict(), gen_path)\n","torch.save(discriminator.state_dict(), dis_path)\n","\n","# Función para generar una imagen aleatoria y guardarla en un archivo .jpg\n","def generar_imagen_aleatoria(generator_path, output_path):\n","    # Cargar los pesos del generador desde el archivo .pth\n","    generator = Generator()  # Reemplaza \"Generator()\" con la clase o función que define tu generador\n","    generator.load_state_dict(torch.load(generator_path))\n","    generator.eval()\n","\n","    # Generar una imagen aleatoria\n","    with torch.no_grad():\n","        noise = torch.randn(1, 128, 1, 1)  # Ajusta el tamaño del ruido según tu generador\n","        imagen_generada = generator(noise)\n","\n","    # Guardar la imagen generada en un archivo .jpg\n","    vutils.save_image(imagen_generada, output_path, normalize=True)\n"],"metadata":{"id":"aNfVHFEbQHSN","executionInfo":{"status":"ok","timestamp":1687590855819,"user_tz":-120,"elapsed":405,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Ejemplo de uso:\n","output_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v0_Images/models/output.jpg\"\n","generar_imagen_aleatoria(gen_path, output_path)"],"metadata":{"id":"QKgFDLfGt1c0","executionInfo":{"status":"ok","timestamp":1687591029796,"user_tz":-120,"elapsed":511,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AEwMELE4QI0L"},"execution_count":null,"outputs":[]}]}
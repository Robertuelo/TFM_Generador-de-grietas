{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xYbvevOpr4D9oc39nUgHe1bAS7rrOu_j","timestamp":1687592383100}],"gpuType":"T4","authorship_tag":"ABX9TyPnmY6WTRtMvfZP25BKXd2O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://github.com/ozanciga/gans-with-pytorch/tree/master/wgan-gp"],"metadata":{"id":"8iDPDfODsr0Y"}},{"cell_type":"code","source":["#torch cuda\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"o3O6OVP0srQI","executionInfo":{"status":"ok","timestamp":1687683233825,"user_tz":-120,"elapsed":5159,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coCS0m76swXn","executionInfo":{"status":"ok","timestamp":1687683247728,"user_tz":-120,"elapsed":13910,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"5b36c045-e753-4113-f452-2e8742716561"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import numpy as np"],"metadata":{"id":"Xu5UYC9IszG0","executionInfo":{"status":"ok","timestamp":1687683248042,"user_tz":-120,"elapsed":317,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"UAU_eyz3q6Bz","executionInfo":{"status":"ok","timestamp":1687683249509,"user_tz":-120,"elapsed":198,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"outputs":[],"source":["from torch import nn\n","\n","# Residual network.\n","# WGAN-GP paper defines a residual block with up & downsampling.\n","# See the official implementation (given in the paper).\n","# I use architectures described in the official implementation,\n","# since I find it hard to deduce the blocks given here from the text alone.\n","class MeanPoolConv(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(MeanPoolConv, self).__init__()\n","        conv1 = nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        self.model = nn.Sequential(conv1)\n","    def forward(self, x):\n","        out = (x[:,:,::2,::2] + x[:,:,1::2,::2] + x[:,:,::2,1::2] + x[:,:,1::2,1::2]) / 4.0\n","        out = self.model(out)\n","        return out\n","\n","class ConvMeanPool(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(ConvMeanPool, self).__init__()\n","        conv1 = nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        self.model = nn.Sequential(conv1)\n","    def forward(self, x):\n","        out = self.model(x)\n","        out = (out[:,:,::2,::2] + out[:,:,1::2,::2] + out[:,:,::2,1::2] + out[:,:,1::2,1::2]) / 4.0\n","        return out\n","\n","class UpsampleConv(nn.Module):\n","    def __init__(self, n_input, n_output, k_size):\n","        super(UpsampleConv, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.PixelShuffle(2),\n","            nn.Conv2d(n_input, n_output, k_size, stride=1, padding=(k_size-1)//2, bias=True)\n","        )\n","    def forward(self, x):\n","        x = x.repeat((1, 4, 1, 1)) # Weird concat of WGAN-GPs upsampling process.\n","        out = self.model(x)\n","        return out\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, n_input, n_output, k_size, resample='up', bn=True, spatial_dim=None):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.resample = resample\n","\n","        if resample == 'up':\n","            self.conv1 = UpsampleConv(n_input, n_output, k_size)\n","            self.conv2 = nn.Conv2d(n_output, n_output, k_size, padding=(k_size-1)//2)\n","            self.conv_shortcut = UpsampleConv(n_input, n_output, k_size)\n","            self.out_dim = n_output\n","        elif resample == 'down':\n","            self.conv1 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv2 = ConvMeanPool(n_input, n_output, k_size)\n","            self.conv_shortcut = ConvMeanPool(n_input, n_output, k_size)\n","            self.out_dim = n_output\n","            self.ln_dims = [n_input, spatial_dim, spatial_dim] # Define the dimensions for layer normalization.\n","        else:\n","            self.conv1 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv2 = nn.Conv2d(n_input, n_input, k_size, padding=(k_size-1)//2)\n","            self.conv_shortcut = None # Identity\n","            self.out_dim = n_input\n","            self.ln_dims = [n_input, spatial_dim, spatial_dim]\n","\n","        self.model = nn.Sequential(\n","            nn.BatchNorm2d(n_input) if bn else nn.LayerNorm(self.ln_dims),\n","            nn.ReLU(inplace=True),\n","            self.conv1,\n","            nn.BatchNorm2d(self.out_dim) if bn else nn.LayerNorm(self.ln_dims),\n","            nn.ReLU(inplace=True),\n","            self.conv2,\n","        )\n","\n","    def forward(self, x):\n","        if self.conv_shortcut is None:\n","            return x + self.model(x)\n","        else:\n","            return self.conv_shortcut(x) + self.model(x)\n","\n","class DiscBlock1(nn.Module):\n","    def __init__(self, n_output):\n","        super(DiscBlock1, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, n_output, 3, padding=(3-1)//2)\n","        self.conv2 = ConvMeanPool(n_output, n_output, 1)\n","        self.conv_shortcut = MeanPoolConv(1, n_output, 1)\n","\n","        self.model = nn.Sequential(\n","            self.conv1,\n","            nn.ReLU(inplace=True),\n","            self.conv2\n","        )\n","\n","    def forward(self, x):\n","        return self.conv_shortcut(x) + self.model(x)\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        self.model = nn.Sequential(                     # 128 x 1 x 1\n","            nn.ConvTranspose2d(128, 128, 4, 1, 0),      # 128 x 4 x 4\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 8 x 8\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 16 x 16\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 32 x 32\n","            ResidualBlock(128, 128, 3, resample='up'),  # 128 x 64 x 64\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 1, 3, padding=(3-1)//2),     # 1 x 64 x 64\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        return img\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        n_output = 128\n","        '''\n","        This is a parameter but since we experiment with a single size\n","        of 3 x 32 x 32 images, it is hardcoded here.\n","        '''\n","\n","        self.DiscBlock1 = DiscBlock1(n_output)                      # 128 x 32 x 32\n","\n","        self.model = nn.Sequential(\n","            ResidualBlock(n_output, n_output, 3, resample='down', bn=False, spatial_dim=32),  # 128 x 16 x 16\n","            ResidualBlock(n_output, n_output, 3, resample='down', bn=False, spatial_dim=16),  # 128 x 8 x 8\n","            ResidualBlock(n_output, n_output, 3, resample=None, bn=False, spatial_dim=8),    # 128 x 8 x 8\n","            ResidualBlock(n_output, n_output, 3, resample=None, bn=False, spatial_dim=8),    # 128 x 8 x 8\n","            nn.ReLU(inplace=True),\n","        )\n","        self.l1 = nn.Sequential(nn.Linear(128, 1))                  # 128 x 1\n","\n","    def forward(self, x):\n","        # x = x.view(-1, 3, 32, 32)\n","        y = self.DiscBlock1(x)\n","        y = self.model(y)\n","        y = y.view(x.size(0), 128, -1)\n","        y = y.mean(dim=2)\n","        out = self.l1(y).unsqueeze_(1).unsqueeze_(2) # or *.view(x.size(0), 128, 1, 1, 1)\n","        return out\n","\n","\n"]},{"cell_type":"code","source":["import torch.utils.data as data\n","import torchvision.transforms as transforms\n","\n","class CustomDataset(data.Dataset):\n","    def __init__(self, X_folder, y_folder, transform=None):\n","        self.X_folder = X_folder\n","        self.y_folder = y_folder\n","        self.transform = transform\n","\n","        # Obtener la lista de nombres de archivo en las carpetas\n","        self.X_filenames = [filename for filename in os.listdir(X_folder) if filename.endswith('.jpg')]\n","        self.y_filenames = [filename for filename in os.listdir(y_folder) if filename.endswith('.jpg')]\n","\n","        #self.resizer = transforms.Resize((64, 64))  # Redimensionar las imágenes a 64x64 píxeles\n","        #self.to_grayscale = transforms.Grayscale()  # Convertir las imágenes a escala de grises\n","\n","    def __len__(self):\n","        return len(self.X_filenames)\n","\n","    def __getitem__(self, index):\n","        X_filename = self.X_filenames[index]\n","        y_filename = self.y_filenames[index]\n","\n","        if not X_filename.endswith(\".jpg\"):\n","            return self.__getitem__((index + 1) % len(self))\n","\n","        # Cargar las imágenes y las etiquetas\n","        X = Image.open(os.path.join(self.X_folder, X_filename))\n","        y = Image.open(os.path.join(self.y_folder, y_filename))\n","\n","        # Redimensionar las imágenes a 64x64 píxeles y convertirlas a escala de grises\n","        #X = self.resizer(X)\n","        #X = self.to_grayscale(X)\n","        #y = self.resizer(y)\n","        #y = self.to_grayscale(y)\n","\n","        if self.transform:\n","            X = self.transform(X)\n","            y = self.transform(y)\n","\n","        return X, y\n","\n","    def get_images(self):\n","        images = []\n","        for X_filename in self.X_filenames:\n","            X = Image.open(os.path.join(self.X_folder, X_filename))#.convert(\"RGB\")\n","            #X = self.resizer(X)\n","            if self.transform:\n","                X = self.transform(X)\n","            images.append(X)\n","        return images\n","\n","    def get_labels(self):\n","        labels = []\n","        for y_filename in self.y_filenames:\n","            y = Image.open(os.path.join(self.y_folder, y_filename))#.convert(\"RGB\")\n","            #y = self.resizer(y)\n","            if self.transform:\n","                y = self.transform(y)\n","            labels.append(y)\n","        return labels\n"],"metadata":{"id":"Wf9iRqQjuEtZ","executionInfo":{"status":"ok","timestamp":1687683326231,"user_tz":-120,"elapsed":192,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn, optim\n","from torch.autograd.variable import Variable\n","\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","import torchvision.utils as vutils\n","\n","import errno\n","\n","class Args:\n","    def __init__(self):\n","        self.n_epochs = 100\n","        self.batch_size = 64\n","        self.alpha = 0.0001\n","        self.b1 = 0.5\n","        self.b2 = 0.9\n","        self.n_critic = 5\n","        self.lambda_1 = 10\n","        self.img_size = 64\n","        self.channels = 1\n","        #self.display_port = 8097\n","        #self.display_server = \"http://localhost\"\n","        self.sample_interval = 256\n","opt = Args()\n","\n","\n","img_dims = (opt.channels, opt.img_size, opt.img_size)\n","n_features = opt.channels * opt.img_size * opt.img_size\n","\n","# TODO: Use some initialization in the future.\n","def init_weights(m):\n","    if type(m) == nn.ConvTranspose2d:\n","        torch.nn.init.kaiming_normal(m.weight, mode='fan_out', nonlinearity='relu')\n","    elif type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n","\n","# Definir las rutas de las carpetas de entrenamiento y prueba\n","trainX_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/traindata/traindata/'\n","trainy_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/valdata/valdata/'\n","\n","# Crear las transformaciones\n","transform = transforms.Compose([\n","    transforms.Resize((opt.img_size, opt.img_size)),\n","    transforms.Grayscale(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5), (0.5)),\n","])\n","\n","# Crear el dataset personalizado de entrenamiento\n","dataset_full = CustomDataset(trainX_folder, trainy_folder, transform=transform)\n","# Obtener xtrain e ytrain\n","dataset = dataset_full.get_images()\n","# Crear los dataloaders\n","batch_iterator = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=2)\n","\n","cuda = torch.cuda.is_available()\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","gan_loss = nn.BCELoss()\n","\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=opt.alpha, betas=(opt.b1, opt.b2))\n","optimizer_G = optim.Adam(generator.parameters(), lr=opt.alpha, betas=(opt.b1, opt.b2))\n","\n","# Loss record.\n","g_losses = []\n","d_losses = []\n","epochs = []\n","loss_legend = ['Discriminator', 'Generator']\n","\n","if cuda:\n","    generator = generator.cuda()\n","    discriminator = discriminator.cuda()\n","\n","noise_fixed = Variable(Tensor(25, 128, 1, 1).normal_(0, 1), requires_grad=False) # To track the progress of the GAN.\n","\n","#Generar carpetas para almacenar las imágenes creadas\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/Images')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/Images/fake_samples')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/models')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","\n","for epoch in range(opt.n_epochs):\n","    print('Epoch {}'.format(epoch))\n","    for i, batch in enumerate(batch_iterator):\n","        # == Discriminator update == #\n","        for iter in range(opt.n_critic):\n","            # Sample real and fake images, using notation in paper.\n","            x = Variable(batch.type(Tensor))\n","            noise = Variable(Tensor(batch.size(0), 128, 1, 1).normal_(0, 1))\n","            x_tilde = Variable(generator(noise), requires_grad=True)\n","\n","            epsilon = Variable(Tensor(batch.size(0), 1, 1, 1).uniform_(0, 1))\n","\n","            x_hat = epsilon*x + (1 - epsilon)*x_tilde\n","            x_hat = torch.autograd.Variable(x_hat, requires_grad=True)\n","\n","            # Put the interpolated data through critic.\n","            dw_x = discriminator(x_hat)\n","            # A great exercise on learning how the autograd.grad works!\n","            grad_x = torch.autograd.grad(outputs=dw_x, inputs=x_hat,\n","                                         grad_outputs=Variable(Tensor(batch.size(0), 1, 1, 1).fill_(1.0), requires_grad=False),\n","                                         create_graph=True, retain_graph=True, only_inputs=True)\n","            grad_x = grad_x[0].view(batch.size(0), -1)\n","            grad_x = grad_x.norm(p=2, dim=1) # My naming is inaccurate, this is the 2-norm of grad(D_w(x_hat))\n","\n","            # Update discriminator (or critic, since we don't output probabilities anymore).\n","            optimizer_D.zero_grad()\n","\n","            # WGAN-GP loss, defined properly as a loss unlike the WGAN paper.\n","            d_loss = torch.mean(discriminator(x_tilde)) - torch.mean(discriminator(x)) + opt.lambda_1*torch.mean((grad_x - 1)**2)\n","            # d_loss = torch.mean(d_loss) # there's a reason for why this shouldn't be done this way :)\n","\n","            d_loss.backward()\n","            optimizer_D.step()\n","\n","        # == Generator update == #\n","        noise = Variable(Tensor(batch.size(0), 128, 1, 1).normal_(0, 1))\n","        imgs_fake = generator(noise)\n","\n","        optimizer_G.zero_grad()\n","\n","        g_loss = -torch.mean(discriminator(imgs_fake))\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch+1, 70, i+1, len(batch_iterator), d_loss.data, g_loss.data))\n","        if i % 100 == 0: # Every 100 steps:\n","            vutils.save_image(x, '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/Images/real_samples.png', normalize = True) # We save the real images of the minibatch.\n","            fake = generator(noise) # We get our fake generated images.\n","            vutils.save_image(fake.detach(), f\"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/Images/fake_samples/fake_samples_epoch_{epoch:03d}.png\", normalize=True) # We also save the fake generated images of the minibatch.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdvQ52nirB2X","executionInfo":{"status":"ok","timestamp":1687684954424,"user_tz":-120,"elapsed":1362844,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"e9fa314e-5051-4e7b-e128-ed753e04e954"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n","[1/70][1/4] Loss_D: 3.5614 Loss_G: 2.1454\n","[1/70][2/4] Loss_D: -2.1152 Loss_G: 3.2847\n","[1/70][3/4] Loss_D: -9.0679 Loss_G: 5.2284\n","[1/70][4/4] Loss_D: -12.4211 Loss_G: 5.5290\n","Epoch 1\n","[2/70][1/4] Loss_D: -15.0394 Loss_G: 5.7267\n","[2/70][2/4] Loss_D: -11.6112 Loss_G: 2.3604\n","[2/70][3/4] Loss_D: -9.8819 Loss_G: 4.1748\n","[2/70][4/4] Loss_D: -8.7720 Loss_G: 3.3304\n","Epoch 2\n","[3/70][1/4] Loss_D: -11.1477 Loss_G: 2.6605\n","[3/70][2/4] Loss_D: -11.0056 Loss_G: -2.1903\n","[3/70][3/4] Loss_D: -10.1030 Loss_G: 0.1036\n","[3/70][4/4] Loss_D: -7.4022 Loss_G: -11.4411\n","Epoch 3\n","[4/70][1/4] Loss_D: -4.8199 Loss_G: -2.7249\n","[4/70][2/4] Loss_D: -5.0151 Loss_G: -0.0633\n","[4/70][3/4] Loss_D: -3.8620 Loss_G: -7.7062\n","[4/70][4/4] Loss_D: -4.0150 Loss_G: -5.0372\n","Epoch 4\n","[5/70][1/4] Loss_D: -2.2256 Loss_G: -2.1776\n","[5/70][2/4] Loss_D: -3.6258 Loss_G: -11.1762\n","[5/70][3/4] Loss_D: -4.9445 Loss_G: -12.1255\n","[5/70][4/4] Loss_D: -3.5545 Loss_G: 0.0895\n","Epoch 5\n","[6/70][1/4] Loss_D: -1.3777 Loss_G: -5.9649\n","[6/70][2/4] Loss_D: 0.1368 Loss_G: -0.2866\n","[6/70][3/4] Loss_D: -2.5337 Loss_G: 8.5208\n","[6/70][4/4] Loss_D: -4.9038 Loss_G: -5.0068\n","Epoch 6\n","[7/70][1/4] Loss_D: -1.4655 Loss_G: -15.4140\n","[7/70][2/4] Loss_D: 1.9341 Loss_G: -20.9671\n","[7/70][3/4] Loss_D: 7.5212 Loss_G: -27.8801\n","[7/70][4/4] Loss_D: 1.0595 Loss_G: -22.6569\n","Epoch 7\n","[8/70][1/4] Loss_D: -6.7842 Loss_G: -16.8166\n","[8/70][2/4] Loss_D: -6.9773 Loss_G: 5.7266\n","[8/70][3/4] Loss_D: -4.9212 Loss_G: 6.3155\n","[8/70][4/4] Loss_D: -1.4081 Loss_G: 6.1872\n","Epoch 8\n","[9/70][1/4] Loss_D: 2.1066 Loss_G: 23.1368\n","[9/70][2/4] Loss_D: 6.3959 Loss_G: 23.5267\n","[9/70][3/4] Loss_D: -0.9061 Loss_G: -15.6881\n","[9/70][4/4] Loss_D: -4.2136 Loss_G: -17.4071\n","Epoch 9\n","[10/70][1/4] Loss_D: -6.0595 Loss_G: -8.4323\n","[10/70][2/4] Loss_D: -3.3873 Loss_G: -4.7802\n","[10/70][3/4] Loss_D: -1.0280 Loss_G: -2.9620\n","[10/70][4/4] Loss_D: 2.9390 Loss_G: -3.4058\n","Epoch 10\n","[11/70][1/4] Loss_D: 0.5784 Loss_G: -13.6333\n","[11/70][2/4] Loss_D: -7.5305 Loss_G: 6.7520\n","[11/70][3/4] Loss_D: -6.2538 Loss_G: 7.9351\n","[11/70][4/4] Loss_D: -4.3663 Loss_G: 2.8307\n","Epoch 11\n","[12/70][1/4] Loss_D: -3.3938 Loss_G: 2.1836\n","[12/70][2/4] Loss_D: -0.8702 Loss_G: 5.1889\n","[12/70][3/4] Loss_D: 0.0621 Loss_G: -3.7433\n","[12/70][4/4] Loss_D: -2.5441 Loss_G: -4.1100\n","Epoch 12\n","[13/70][1/4] Loss_D: -3.8986 Loss_G: -9.5813\n","[13/70][2/4] Loss_D: -3.1829 Loss_G: -14.1282\n","[13/70][3/4] Loss_D: 1.1015 Loss_G: -21.8754\n","[13/70][4/4] Loss_D: -3.7293 Loss_G: -0.0162\n","Epoch 13\n","[14/70][1/4] Loss_D: -2.9017 Loss_G: 3.1376\n","[14/70][2/4] Loss_D: -2.1230 Loss_G: 5.0301\n","[14/70][3/4] Loss_D: -2.1290 Loss_G: -1.7965\n","[14/70][4/4] Loss_D: -2.5922 Loss_G: 5.3635\n","Epoch 14\n","[15/70][1/4] Loss_D: -1.9451 Loss_G: -8.6577\n","[15/70][2/4] Loss_D: -3.1744 Loss_G: -15.4536\n","[15/70][3/4] Loss_D: -1.5658 Loss_G: -8.0786\n","[15/70][4/4] Loss_D: -2.2300 Loss_G: -5.9544\n","Epoch 15\n","[16/70][1/4] Loss_D: -1.8947 Loss_G: -6.3482\n","[16/70][2/4] Loss_D: -3.3835 Loss_G: -4.1961\n","[16/70][3/4] Loss_D: -5.4912 Loss_G: -4.3298\n","[16/70][4/4] Loss_D: -2.4678 Loss_G: -6.1329\n","Epoch 16\n","[17/70][1/4] Loss_D: -2.0596 Loss_G: -6.2730\n","[17/70][2/4] Loss_D: -2.7141 Loss_G: 5.0479\n","[17/70][3/4] Loss_D: 5.4323 Loss_G: -28.5358\n","[17/70][4/4] Loss_D: 1.3573 Loss_G: -21.5268\n","Epoch 17\n","[18/70][1/4] Loss_D: 0.3454 Loss_G: -23.4894\n","[18/70][2/4] Loss_D: -1.7856 Loss_G: 15.1708\n","[18/70][3/4] Loss_D: -4.3807 Loss_G: 1.7419\n","[18/70][4/4] Loss_D: -3.3627 Loss_G: 1.3792\n","Epoch 18\n","[19/70][1/4] Loss_D: -3.7680 Loss_G: -14.8292\n","[19/70][2/4] Loss_D: -2.1642 Loss_G: -22.4012\n","[19/70][3/4] Loss_D: -1.9616 Loss_G: -8.4385\n","[19/70][4/4] Loss_D: 1.0095 Loss_G: -8.7966\n","Epoch 19\n","[20/70][1/4] Loss_D: 0.8313 Loss_G: -16.1810\n","[20/70][2/4] Loss_D: -5.1901 Loss_G: 4.3856\n","[20/70][3/4] Loss_D: -3.5542 Loss_G: 6.2528\n","[20/70][4/4] Loss_D: -2.0407 Loss_G: 12.1364\n","Epoch 20\n","[21/70][1/4] Loss_D: 0.1157 Loss_G: -8.6655\n","[21/70][2/4] Loss_D: 1.7790 Loss_G: -39.8204\n","[21/70][3/4] Loss_D: -1.5044 Loss_G: -22.2239\n","[21/70][4/4] Loss_D: -1.1827 Loss_G: -5.6810\n","Epoch 21\n","[22/70][1/4] Loss_D: -1.2936 Loss_G: -3.2913\n","[22/70][2/4] Loss_D: 0.2144 Loss_G: 0.5770\n","[22/70][3/4] Loss_D: -1.1732 Loss_G: -16.9587\n","[22/70][4/4] Loss_D: -1.0437 Loss_G: -3.7432\n","Epoch 22\n","[23/70][1/4] Loss_D: -0.3494 Loss_G: 20.3758\n","[23/70][2/4] Loss_D: 0.7696 Loss_G: 14.2432\n","[23/70][3/4] Loss_D: -2.8523 Loss_G: -24.7881\n","[23/70][4/4] Loss_D: -3.5719 Loss_G: -17.2209\n","Epoch 23\n","[24/70][1/4] Loss_D: -1.0878 Loss_G: -18.4701\n","[24/70][2/4] Loss_D: 1.2363 Loss_G: -21.0792\n","[24/70][3/4] Loss_D: 2.8691 Loss_G: -26.9127\n","[24/70][4/4] Loss_D: 4.6291 Loss_G: -37.2343\n","Epoch 24\n","[25/70][1/4] Loss_D: -4.4801 Loss_G: 3.9874\n","[25/70][2/4] Loss_D: -4.7361 Loss_G: -10.2488\n","[25/70][3/4] Loss_D: -3.5902 Loss_G: -6.1093\n","[25/70][4/4] Loss_D: -1.1568 Loss_G: 8.4601\n","Epoch 25\n","[26/70][1/4] Loss_D: -0.8813 Loss_G: 6.7779\n","[26/70][2/4] Loss_D: -1.8854 Loss_G: -15.6353\n","[26/70][3/4] Loss_D: -2.5812 Loss_G: -0.9086\n","[26/70][4/4] Loss_D: -2.5422 Loss_G: -2.5971\n","Epoch 26\n","[27/70][1/4] Loss_D: -0.7620 Loss_G: -14.3140\n","[27/70][2/4] Loss_D: -4.4432 Loss_G: -6.2517\n","[27/70][3/4] Loss_D: -4.3885 Loss_G: -22.1212\n","[27/70][4/4] Loss_D: -3.2026 Loss_G: 3.2631\n","Epoch 27\n","[28/70][1/4] Loss_D: -2.2444 Loss_G: 1.4045\n","[28/70][2/4] Loss_D: -1.8732 Loss_G: -19.5749\n","[28/70][3/4] Loss_D: -1.2139 Loss_G: 10.7102\n","[28/70][4/4] Loss_D: -0.8291 Loss_G: -5.8915\n","Epoch 28\n","[29/70][1/4] Loss_D: -1.3269 Loss_G: 3.8664\n","[29/70][2/4] Loss_D: -1.3995 Loss_G: 19.0877\n","[29/70][3/4] Loss_D: -0.7936 Loss_G: 26.1420\n","[29/70][4/4] Loss_D: 3.2594 Loss_G: 34.5942\n","Epoch 29\n","[30/70][1/4] Loss_D: -2.4697 Loss_G: 21.3991\n","[30/70][2/4] Loss_D: -2.4809 Loss_G: 27.6687\n","[30/70][3/4] Loss_D: -1.5819 Loss_G: 26.0975\n","[30/70][4/4] Loss_D: -1.1534 Loss_G: -24.4690\n","Epoch 30\n","[31/70][1/4] Loss_D: -0.6621 Loss_G: -31.1689\n","[31/70][2/4] Loss_D: 0.4660 Loss_G: -29.6115\n","[31/70][3/4] Loss_D: -0.3309 Loss_G: -29.8955\n","[31/70][4/4] Loss_D: 0.3278 Loss_G: -24.8081\n","Epoch 31\n","[32/70][1/4] Loss_D: 1.4154 Loss_G: -19.3298\n","[32/70][2/4] Loss_D: -3.1790 Loss_G: -10.8659\n","[32/70][3/4] Loss_D: -2.5919 Loss_G: -27.8846\n","[32/70][4/4] Loss_D: -1.2030 Loss_G: -21.0292\n","Epoch 32\n","[33/70][1/4] Loss_D: 0.3143 Loss_G: -14.3870\n","[33/70][2/4] Loss_D: 1.1625 Loss_G: -17.7040\n","[33/70][3/4] Loss_D: -0.7813 Loss_G: -19.4284\n","[33/70][4/4] Loss_D: -3.9057 Loss_G: 3.1145\n","Epoch 33\n","[34/70][1/4] Loss_D: -2.2457 Loss_G: 8.8404\n","[34/70][2/4] Loss_D: -2.2236 Loss_G: 9.7749\n","[34/70][3/4] Loss_D: -1.6691 Loss_G: -2.2662\n","[34/70][4/4] Loss_D: -3.2419 Loss_G: -12.9406\n","Epoch 34\n","[35/70][1/4] Loss_D: -3.9214 Loss_G: -19.6005\n","[35/70][2/4] Loss_D: -3.3702 Loss_G: 0.2127\n","[35/70][3/4] Loss_D: -2.0460 Loss_G: -2.8473\n","[35/70][4/4] Loss_D: -1.3852 Loss_G: -8.1862\n","Epoch 35\n","[36/70][1/4] Loss_D: -1.8000 Loss_G: -13.7626\n","[36/70][2/4] Loss_D: -1.5696 Loss_G: 4.5434\n","[36/70][3/4] Loss_D: -1.2300 Loss_G: -28.6133\n","[36/70][4/4] Loss_D: -2.0970 Loss_G: -10.3857\n","Epoch 36\n","[37/70][1/4] Loss_D: -2.6249 Loss_G: -2.8076\n","[37/70][2/4] Loss_D: -4.0332 Loss_G: -6.5550\n","[37/70][3/4] Loss_D: -1.7148 Loss_G: 1.0564\n","[37/70][4/4] Loss_D: -2.8278 Loss_G: 2.4359\n","Epoch 37\n","[38/70][1/4] Loss_D: -2.5828 Loss_G: 1.4540\n","[38/70][2/4] Loss_D: -2.1565 Loss_G: 11.3911\n","[38/70][3/4] Loss_D: -2.7429 Loss_G: 24.5058\n","[38/70][4/4] Loss_D: -2.4780 Loss_G: 24.3757\n","Epoch 38\n","[39/70][1/4] Loss_D: -5.7630 Loss_G: -4.7236\n","[39/70][2/4] Loss_D: -5.4465 Loss_G: 3.3378\n","[39/70][3/4] Loss_D: -2.1947 Loss_G: 23.7287\n","[39/70][4/4] Loss_D: -1.5199 Loss_G: 21.5321\n","Epoch 39\n","[40/70][1/4] Loss_D: -0.2808 Loss_G: 26.5246\n","[40/70][2/4] Loss_D: -1.1033 Loss_G: 24.0019\n","[40/70][3/4] Loss_D: -0.5821 Loss_G: 19.5235\n","[40/70][4/4] Loss_D: -1.4496 Loss_G: -24.6142\n","Epoch 40\n","[41/70][1/4] Loss_D: 0.7541 Loss_G: -24.3925\n","[41/70][2/4] Loss_D: -0.2000 Loss_G: -51.6981\n","[41/70][3/4] Loss_D: -3.9841 Loss_G: -39.1223\n","[41/70][4/4] Loss_D: -2.4427 Loss_G: -25.3496\n","Epoch 41\n","[42/70][1/4] Loss_D: -1.6190 Loss_G: -29.1323\n","[42/70][2/4] Loss_D: -0.7434 Loss_G: -13.7230\n","[42/70][3/4] Loss_D: -1.8852 Loss_G: -10.6908\n","[42/70][4/4] Loss_D: -1.7584 Loss_G: -13.3327\n","Epoch 42\n","[43/70][1/4] Loss_D: -0.4877 Loss_G: -10.2726\n","[43/70][2/4] Loss_D: -1.9702 Loss_G: -11.6677\n","[43/70][3/4] Loss_D: -0.0831 Loss_G: -17.6540\n","[43/70][4/4] Loss_D: -0.4976 Loss_G: -0.3130\n","Epoch 43\n","[44/70][1/4] Loss_D: -2.4321 Loss_G: -17.9858\n","[44/70][2/4] Loss_D: -2.2078 Loss_G: 9.9292\n","[44/70][3/4] Loss_D: -1.6957 Loss_G: -1.5336\n","[44/70][4/4] Loss_D: -0.7564 Loss_G: 14.3916\n","Epoch 44\n","[45/70][1/4] Loss_D: -1.0559 Loss_G: 5.2027\n","[45/70][2/4] Loss_D: -2.6080 Loss_G: 14.3240\n","[45/70][3/4] Loss_D: -2.1764 Loss_G: 13.3736\n","[45/70][4/4] Loss_D: -2.1211 Loss_G: -17.9681\n","Epoch 45\n","[46/70][1/4] Loss_D: -1.6714 Loss_G: -1.8705\n","[46/70][2/4] Loss_D: -2.3353 Loss_G: 7.8738\n","[46/70][3/4] Loss_D: -1.1901 Loss_G: -12.4569\n","[46/70][4/4] Loss_D: -0.9192 Loss_G: 20.9070\n","Epoch 46\n","[47/70][1/4] Loss_D: -0.0204 Loss_G: 34.2582\n","[47/70][2/4] Loss_D: 0.0962 Loss_G: 18.9296\n","[47/70][3/4] Loss_D: -2.9521 Loss_G: -17.9945\n","[47/70][4/4] Loss_D: -2.4196 Loss_G: -22.2013\n","Epoch 47\n","[48/70][1/4] Loss_D: -1.1918 Loss_G: -23.4246\n","[48/70][2/4] Loss_D: -0.9547 Loss_G: -2.6004\n","[48/70][3/4] Loss_D: -1.2102 Loss_G: 32.7392\n","[48/70][4/4] Loss_D: -2.3082 Loss_G: 17.9367\n","Epoch 48\n","[49/70][1/4] Loss_D: -1.9923 Loss_G: 6.5519\n","[49/70][2/4] Loss_D: -0.6145 Loss_G: -22.0331\n","[49/70][3/4] Loss_D: -1.7813 Loss_G: -24.2272\n","[49/70][4/4] Loss_D: -2.6345 Loss_G: 4.7746\n","Epoch 49\n","[50/70][1/4] Loss_D: -2.2354 Loss_G: 22.5041\n","[50/70][2/4] Loss_D: -1.4835 Loss_G: 23.2373\n","[50/70][3/4] Loss_D: -0.5935 Loss_G: 22.6929\n","[50/70][4/4] Loss_D: -1.2924 Loss_G: 5.9748\n","Epoch 50\n","[51/70][1/4] Loss_D: -1.8037 Loss_G: -18.4806\n","[51/70][2/4] Loss_D: -1.0396 Loss_G: -10.8770\n","[51/70][3/4] Loss_D: -0.1238 Loss_G: 4.2932\n","[51/70][4/4] Loss_D: -3.1950 Loss_G: -25.7996\n","Epoch 51\n","[52/70][1/4] Loss_D: -2.9583 Loss_G: -27.7745\n","[52/70][2/4] Loss_D: -1.1508 Loss_G: -21.9614\n","[52/70][3/4] Loss_D: -0.1415 Loss_G: -7.0688\n","[52/70][4/4] Loss_D: -2.5758 Loss_G: 0.4061\n","Epoch 52\n","[53/70][1/4] Loss_D: -1.5045 Loss_G: -20.6421\n","[53/70][2/4] Loss_D: -0.6469 Loss_G: -32.4425\n","[53/70][3/4] Loss_D: -0.6176 Loss_G: -37.8491\n","[53/70][4/4] Loss_D: -1.3231 Loss_G: -2.6415\n","Epoch 53\n","[54/70][1/4] Loss_D: -1.9029 Loss_G: 0.5358\n","[54/70][2/4] Loss_D: -1.8481 Loss_G: -7.5353\n","[54/70][3/4] Loss_D: -1.4612 Loss_G: -17.6971\n","[54/70][4/4] Loss_D: -0.5036 Loss_G: -52.4742\n","Epoch 54\n","[55/70][1/4] Loss_D: 0.0205 Loss_G: -48.0943\n","[55/70][2/4] Loss_D: -2.3643 Loss_G: -25.1270\n","[55/70][3/4] Loss_D: -0.5530 Loss_G: -27.9075\n","[55/70][4/4] Loss_D: -0.8800 Loss_G: -58.1277\n","Epoch 55\n","[56/70][1/4] Loss_D: -0.4137 Loss_G: -49.3672\n","[56/70][2/4] Loss_D: -2.1498 Loss_G: -4.5276\n","[56/70][3/4] Loss_D: -2.0517 Loss_G: 6.9756\n","[56/70][4/4] Loss_D: -0.9268 Loss_G: 9.0488\n","Epoch 56\n","[57/70][1/4] Loss_D: -0.2272 Loss_G: -7.5474\n","[57/70][2/4] Loss_D: -1.7363 Loss_G: -14.8029\n","[57/70][3/4] Loss_D: -1.1760 Loss_G: 5.1353\n","[57/70][4/4] Loss_D: -1.6809 Loss_G: -28.2268\n","Epoch 57\n","[58/70][1/4] Loss_D: -0.6046 Loss_G: -18.5570\n","[58/70][2/4] Loss_D: -1.4389 Loss_G: -1.7925\n","[58/70][3/4] Loss_D: -1.2098 Loss_G: -0.5093\n","[58/70][4/4] Loss_D: -0.7656 Loss_G: -11.1021\n","Epoch 58\n","[59/70][1/4] Loss_D: -2.7397 Loss_G: -37.5140\n","[59/70][2/4] Loss_D: -2.0074 Loss_G: -27.3940\n","[59/70][3/4] Loss_D: -1.7670 Loss_G: -20.7057\n","[59/70][4/4] Loss_D: -1.7279 Loss_G: -4.6899\n","Epoch 59\n","[60/70][1/4] Loss_D: -1.2672 Loss_G: 4.9491\n","[60/70][2/4] Loss_D: -0.5855 Loss_G: -27.6596\n","[60/70][3/4] Loss_D: -0.4111 Loss_G: -26.5532\n","[60/70][4/4] Loss_D: -0.9506 Loss_G: -16.4241\n","Epoch 60\n","[61/70][1/4] Loss_D: -1.5404 Loss_G: 23.1549\n","[61/70][2/4] Loss_D: -1.3902 Loss_G: -2.5202\n","[61/70][3/4] Loss_D: -1.5796 Loss_G: -26.8182\n","[61/70][4/4] Loss_D: -1.6188 Loss_G: -10.1949\n","Epoch 61\n","[62/70][1/4] Loss_D: -1.6305 Loss_G: 0.2433\n","[62/70][2/4] Loss_D: -1.2199 Loss_G: 2.9192\n","[62/70][3/4] Loss_D: -1.8477 Loss_G: 5.1965\n","[62/70][4/4] Loss_D: -0.9514 Loss_G: -19.3220\n","Epoch 62\n","[63/70][1/4] Loss_D: -1.7720 Loss_G: -18.4224\n","[63/70][2/4] Loss_D: -1.0173 Loss_G: 1.4754\n","[63/70][3/4] Loss_D: -0.8274 Loss_G: 3.0661\n","[63/70][4/4] Loss_D: -1.7254 Loss_G: -0.0455\n","Epoch 63\n","[64/70][1/4] Loss_D: -1.0713 Loss_G: -37.5917\n","[64/70][2/4] Loss_D: -0.8166 Loss_G: -23.1878\n","[64/70][3/4] Loss_D: -3.2448 Loss_G: 5.3437\n","[64/70][4/4] Loss_D: -2.8260 Loss_G: 7.0502\n","Epoch 64\n","[65/70][1/4] Loss_D: -0.0467 Loss_G: 10.4701\n","[65/70][2/4] Loss_D: -0.2254 Loss_G: -21.9906\n","[65/70][3/4] Loss_D: -3.1046 Loss_G: -19.7894\n","[65/70][4/4] Loss_D: -1.9794 Loss_G: -22.4111\n","Epoch 65\n","[66/70][1/4] Loss_D: -1.3043 Loss_G: -17.9885\n","[66/70][2/4] Loss_D: -0.0609 Loss_G: -7.8741\n","[66/70][3/4] Loss_D: -0.4916 Loss_G: -14.1680\n","[66/70][4/4] Loss_D: -2.1405 Loss_G: -27.5970\n","Epoch 66\n","[67/70][1/4] Loss_D: -1.6091 Loss_G: -26.8624\n","[67/70][2/4] Loss_D: -1.1756 Loss_G: -13.0387\n","[67/70][3/4] Loss_D: -2.0115 Loss_G: 13.4177\n","[67/70][4/4] Loss_D: -2.7904 Loss_G: 11.4067\n","Epoch 67\n","[68/70][1/4] Loss_D: -1.8828 Loss_G: 12.7600\n","[68/70][2/4] Loss_D: -0.8672 Loss_G: 6.2509\n","[68/70][3/4] Loss_D: -0.6347 Loss_G: -16.3968\n","[68/70][4/4] Loss_D: -0.9012 Loss_G: -27.0886\n","Epoch 68\n","[69/70][1/4] Loss_D: -3.0778 Loss_G: -3.0414\n","[69/70][2/4] Loss_D: -2.0126 Loss_G: 1.7207\n","[69/70][3/4] Loss_D: -0.0983 Loss_G: -33.9461\n","[69/70][4/4] Loss_D: -0.1733 Loss_G: -30.3394\n","Epoch 69\n","[70/70][1/4] Loss_D: -0.5572 Loss_G: 2.3225\n","[70/70][2/4] Loss_D: -1.8542 Loss_G: 8.2935\n","[70/70][3/4] Loss_D: -2.1837 Loss_G: 13.5572\n","[70/70][4/4] Loss_D: -1.1225 Loss_G: 8.9534\n","Epoch 70\n","[71/70][1/4] Loss_D: -0.3405 Loss_G: 7.0587\n","[71/70][2/4] Loss_D: -2.4360 Loss_G: -1.4642\n","[71/70][3/4] Loss_D: -1.6642 Loss_G: 6.2303\n","[71/70][4/4] Loss_D: -0.7469 Loss_G: 14.9715\n","Epoch 71\n","[72/70][1/4] Loss_D: -0.3639 Loss_G: 2.6405\n","[72/70][2/4] Loss_D: -1.8202 Loss_G: -12.8389\n","[72/70][3/4] Loss_D: -1.0164 Loss_G: -13.5676\n","[72/70][4/4] Loss_D: -1.0968 Loss_G: 9.0598\n","Epoch 72\n","[73/70][1/4] Loss_D: -2.5363 Loss_G: -0.9903\n","[73/70][2/4] Loss_D: -2.6162 Loss_G: -2.0498\n","[73/70][3/4] Loss_D: -0.8251 Loss_G: -16.6432\n","[73/70][4/4] Loss_D: -3.4398 Loss_G: -30.0582\n","Epoch 73\n","[74/70][1/4] Loss_D: -2.2212 Loss_G: -28.7951\n","[74/70][2/4] Loss_D: 0.0988 Loss_G: -19.6218\n","[74/70][3/4] Loss_D: -0.6418 Loss_G: 11.9857\n","[74/70][4/4] Loss_D: -1.6078 Loss_G: 13.7827\n","Epoch 74\n","[75/70][1/4] Loss_D: -2.6725 Loss_G: 6.9944\n","[75/70][2/4] Loss_D: -0.9353 Loss_G: -14.4155\n","[75/70][3/4] Loss_D: -1.9260 Loss_G: -20.9636\n","[75/70][4/4] Loss_D: -1.2436 Loss_G: 3.7725\n","Epoch 75\n","[76/70][1/4] Loss_D: -1.8726 Loss_G: 1.8885\n","[76/70][2/4] Loss_D: -2.1017 Loss_G: 10.0367\n","[76/70][3/4] Loss_D: -1.5126 Loss_G: 0.7834\n","[76/70][4/4] Loss_D: -1.4099 Loss_G: -14.1949\n","Epoch 76\n","[77/70][1/4] Loss_D: -1.9094 Loss_G: -12.7331\n","[77/70][2/4] Loss_D: -1.2305 Loss_G: -13.3071\n","[77/70][3/4] Loss_D: -1.0889 Loss_G: -12.4091\n","[77/70][4/4] Loss_D: -0.7153 Loss_G: -29.7885\n","Epoch 77\n","[78/70][1/4] Loss_D: -0.7908 Loss_G: -39.2153\n","[78/70][2/4] Loss_D: -1.2540 Loss_G: -30.3148\n","[78/70][3/4] Loss_D: -2.2185 Loss_G: -18.5506\n","[78/70][4/4] Loss_D: -0.9591 Loss_G: -32.1061\n","Epoch 78\n","[79/70][1/4] Loss_D: -1.2348 Loss_G: -29.7565\n","[79/70][2/4] Loss_D: -1.7649 Loss_G: -6.9841\n","[79/70][3/4] Loss_D: -1.7241 Loss_G: -5.5322\n","[79/70][4/4] Loss_D: -2.3081 Loss_G: -4.4849\n","Epoch 79\n","[80/70][1/4] Loss_D: -1.1370 Loss_G: -3.3554\n","[80/70][2/4] Loss_D: 2.0219 Loss_G: -7.4718\n","[80/70][3/4] Loss_D: -2.0406 Loss_G: -15.9299\n","[80/70][4/4] Loss_D: -0.8145 Loss_G: -8.2123\n","Epoch 80\n","[81/70][1/4] Loss_D: 0.3373 Loss_G: 11.3097\n","[81/70][2/4] Loss_D: -2.8715 Loss_G: 13.7713\n","[81/70][3/4] Loss_D: -1.6751 Loss_G: 7.0353\n","[81/70][4/4] Loss_D: 0.0749 Loss_G: -3.3509\n","Epoch 81\n","[82/70][1/4] Loss_D: -2.2000 Loss_G: -33.2750\n","[82/70][2/4] Loss_D: -1.6510 Loss_G: -19.4033\n","[82/70][3/4] Loss_D: -0.6648 Loss_G: -3.4358\n","[82/70][4/4] Loss_D: -1.5194 Loss_G: -1.5319\n","Epoch 82\n","[83/70][1/4] Loss_D: -4.3544 Loss_G: -5.6204\n","[83/70][2/4] Loss_D: -3.0557 Loss_G: -8.0333\n","[83/70][3/4] Loss_D: -1.4641 Loss_G: -8.9998\n","[83/70][4/4] Loss_D: -0.9129 Loss_G: -39.6778\n","Epoch 83\n","[84/70][1/4] Loss_D: -0.6305 Loss_G: -46.1675\n","[84/70][2/4] Loss_D: 0.9934 Loss_G: -57.4917\n","[84/70][3/4] Loss_D: 1.7768 Loss_G: -67.1144\n","[84/70][4/4] Loss_D: 2.7964 Loss_G: -78.7117\n","Epoch 84\n","[85/70][1/4] Loss_D: -3.0361 Loss_G: -64.5458\n","[85/70][2/4] Loss_D: -2.2685 Loss_G: -54.3755\n","[85/70][3/4] Loss_D: -1.8025 Loss_G: -51.3589\n","[85/70][4/4] Loss_D: -0.7313 Loss_G: -49.4849\n","Epoch 85\n","[86/70][1/4] Loss_D: 0.5693 Loss_G: -25.5422\n","[86/70][2/4] Loss_D: -2.3786 Loss_G: -18.3936\n","[86/70][3/4] Loss_D: -2.2214 Loss_G: -9.3128\n","[86/70][4/4] Loss_D: -1.8010 Loss_G: -17.6834\n","Epoch 86\n","[87/70][1/4] Loss_D: -1.2067 Loss_G: -17.1606\n","[87/70][2/4] Loss_D: -0.8628 Loss_G: -3.5449\n","[87/70][3/4] Loss_D: -2.0074 Loss_G: -25.9634\n","[87/70][4/4] Loss_D: -2.4446 Loss_G: -4.1583\n","Epoch 87\n","[88/70][1/4] Loss_D: -1.7441 Loss_G: -1.0784\n","[88/70][2/4] Loss_D: -0.9537 Loss_G: 6.9025\n","[88/70][3/4] Loss_D: -3.4799 Loss_G: -28.1499\n","[88/70][4/4] Loss_D: -2.8786 Loss_G: -25.9111\n","Epoch 88\n","[89/70][1/4] Loss_D: 0.0162 Loss_G: -24.0589\n","[89/70][2/4] Loss_D: 1.3498 Loss_G: -32.5239\n","[89/70][3/4] Loss_D: 2.2901 Loss_G: -51.0798\n","[89/70][4/4] Loss_D: 3.2455 Loss_G: -69.6503\n","Epoch 89\n","[90/70][1/4] Loss_D: 3.5517 Loss_G: -59.1409\n","[90/70][2/4] Loss_D: -3.0787 Loss_G: -13.7521\n","[90/70][3/4] Loss_D: -3.5246 Loss_G: -27.6611\n","[90/70][4/4] Loss_D: -3.4386 Loss_G: -38.8254\n","Epoch 90\n","[91/70][1/4] Loss_D: -4.0149 Loss_G: -39.4148\n","[91/70][2/4] Loss_D: -2.7729 Loss_G: -44.2150\n","[91/70][3/4] Loss_D: -0.3676 Loss_G: -37.7824\n","[91/70][4/4] Loss_D: -0.5780 Loss_G: -6.4118\n","Epoch 91\n","[92/70][1/4] Loss_D: -0.3467 Loss_G: 20.0608\n","[92/70][2/4] Loss_D: -2.8391 Loss_G: -0.1000\n","[92/70][3/4] Loss_D: -2.8001 Loss_G: -11.0385\n","[92/70][4/4] Loss_D: -2.5028 Loss_G: -3.9839\n","Epoch 92\n","[93/70][1/4] Loss_D: -1.1995 Loss_G: 1.0735\n","[93/70][2/4] Loss_D: -0.2120 Loss_G: 6.6603\n","[93/70][3/4] Loss_D: -0.0870 Loss_G: 1.2094\n","[93/70][4/4] Loss_D: -2.2108 Loss_G: -12.4856\n","Epoch 93\n","[94/70][1/4] Loss_D: -1.3715 Loss_G: -22.0049\n","[94/70][2/4] Loss_D: -0.9190 Loss_G: -20.1761\n","[94/70][3/4] Loss_D: -0.9673 Loss_G: 14.5313\n","[94/70][4/4] Loss_D: -1.1324 Loss_G: -10.8502\n","Epoch 94\n","[95/70][1/4] Loss_D: -1.4126 Loss_G: -19.9337\n","[95/70][2/4] Loss_D: -2.1823 Loss_G: -10.2387\n","[95/70][3/4] Loss_D: -1.8551 Loss_G: -11.5508\n","[95/70][4/4] Loss_D: -2.1804 Loss_G: -17.7115\n","Epoch 95\n","[96/70][1/4] Loss_D: -1.5370 Loss_G: -29.1162\n","[96/70][2/4] Loss_D: -1.6301 Loss_G: -4.7925\n","[96/70][3/4] Loss_D: -1.4511 Loss_G: -21.1767\n","[96/70][4/4] Loss_D: -1.8213 Loss_G: -19.3481\n","Epoch 96\n","[97/70][1/4] Loss_D: -2.2419 Loss_G: -18.0067\n","[97/70][2/4] Loss_D: -1.5600 Loss_G: -23.4279\n","[97/70][3/4] Loss_D: -1.2820 Loss_G: -38.4729\n","[97/70][4/4] Loss_D: -1.1422 Loss_G: -0.7487\n","Epoch 97\n","[98/70][1/4] Loss_D: -1.1080 Loss_G: -21.9870\n","[98/70][2/4] Loss_D: -1.7348 Loss_G: -27.9480\n","[98/70][3/4] Loss_D: -0.9498 Loss_G: -13.0278\n","[98/70][4/4] Loss_D: -1.3182 Loss_G: -4.5206\n","Epoch 98\n","[99/70][1/4] Loss_D: -1.4908 Loss_G: -19.0792\n","[99/70][2/4] Loss_D: -1.1547 Loss_G: 5.8765\n","[99/70][3/4] Loss_D: -2.4269 Loss_G: -7.8945\n","[99/70][4/4] Loss_D: -1.4247 Loss_G: -31.5259\n","Epoch 99\n","[100/70][1/4] Loss_D: -0.7616 Loss_G: 0.9594\n","[100/70][2/4] Loss_D: -2.1358 Loss_G: -27.9291\n","[100/70][3/4] Loss_D: -1.9729 Loss_G: -37.5875\n","[100/70][4/4] Loss_D: -2.0363 Loss_G: -15.8124\n"]}]},{"cell_type":"code","source":["# Guardar el modelo en un archivo .pth\n","gen_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/models/generator.pth\"\n","dis_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/models/discriminator.pth\"\n","\n","torch.save(generator.state_dict(), gen_path)\n","torch.save(discriminator.state_dict(), dis_path)\n","\n","# Función para generar una imagen aleatoria y guardarla en un archivo .jpg\n","def generar_imagen_aleatoria(generator_path, output_path):\n","    # Cargar los pesos del generador desde el archivo .pth\n","    generator = Generator()  # Reemplaza \"Generator()\" con la clase o función que define tu generador\n","    generator.load_state_dict(torch.load(generator_path))\n","    generator.eval()\n","\n","    # Generar una imagen aleatoria\n","    with torch.no_grad():\n","        noise = torch.randn(1, 128, 1, 1)  # Ajusta el tamaño del ruido según tu generador\n","        imagen_generada = generator(noise)\n","\n","    # Guardar la imagen generada en un archivo .jpg\n","    vutils.save_image(imagen_generada, output_path, normalize=True)\n"],"metadata":{"id":"aNfVHFEbQHSN","executionInfo":{"status":"ok","timestamp":1687685273854,"user_tz":-120,"elapsed":296,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Ejemplo de uso:\n","output_path = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/wGAN-v2_Images/models/output.jpg\"\n","generar_imagen_aleatoria(gen_path, output_path)"],"metadata":{"id":"QKgFDLfGt1c0","executionInfo":{"status":"ok","timestamp":1687685276827,"user_tz":-120,"elapsed":512,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AEwMELE4QI0L"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17toTO61P35IYYRAqWvrdVkCA6UMr2b8t","timestamp":1687110368398}],"gpuType":"T4","authorship_tag":"ABX9TyN2v54B3e+pIT5xoz9qFsBe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://github.com/AdityaVashista30/Image-generation-using-GANS-using-PyTorch-and-Cifar-10\n","\n","https://github.com/soumith/dcgan.torch/issues/2#issuecomment-164862299"],"metadata":{"id":"V5X4GmauqYh_"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"JynSOzTXtQsj","executionInfo":{"status":"ok","timestamp":1688487009169,"user_tz":-120,"elapsed":6238,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"outputs":[],"source":["#torch cuda\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Edis4UlrO3j5","executionInfo":{"status":"ok","timestamp":1688487026890,"user_tz":-120,"elapsed":15899,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"b0c26476-a354-4806-a721-40328ab78481"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# Importing the libraries\n","import os\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import numpy as np\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","from torch.autograd import Variable\n","import errno\n","\n","# Seteamos algunos hiperparametros que necesitaremos\n","batchSize = 64 #tamaño del batch\n","imageSize = 128 #tamaño de imagen\n","nz = 100 #tamaño de input del generador\n","ngf = 128 #tamaño de input del generador\n","ndf = int(ngf/4) #tamaño de input del discriminador\n","nc = 1 #numero de canales (1 porque trabajamos en escala de grises)\n","\n","\n","#Definimos una clase para cargar el dataset\n","class CustomDataset(data.Dataset):\n","    def __init__(self, X_folder, y_folder, transform=None):\n","        self.X_folder = X_folder\n","        self.y_folder = y_folder\n","        self.transform = transform\n","\n","        # Obtener la lista de nombres de archivo en las carpetas\n","        self.X_filenames = [filename for filename in os.listdir(X_folder) if filename.endswith('.jpg')]\n","        self.y_filenames = [filename for filename in os.listdir(y_folder) if filename.endswith('.jpg')]\n","\n","    def __len__(self):\n","        return len(self.X_filenames)\n","\n","    def __getitem__(self, index):\n","        # Obtener el nombre de archivo correspondiente a la posición del índice\n","        X_filename = self.X_filenames[index]\n","        y_filename = self.y_filenames[index]\n","\n","        # Verificar si el archivo tiene la extensión \".jpg\"\n","        if not X_filename.endswith(\".jpg\"):\n","            return self.__getitem__((index + 1) % len(self))\n","\n","        # Cargar las imágenes y las etiquetas\n","        X = Image.open(os.path.join(self.X_folder, X_filename)).convert(\"RGB\")\n","        y = Image.open(os.path.join(self.y_folder, y_filename)).convert(\"RGB\")\n","\n","        if self.transform:\n","            X = self.transform(X)\n","            y = self.transform(y)\n","\n","        return X, y\n","\n","    def get_images(self):\n","        images = []\n","        for X_filename in self.X_filenames:\n","            X = Image.open(os.path.join(self.X_folder, X_filename))\n","            if self.transform:\n","                X = self.transform(X)\n","            images.append(X)\n","        return images\n","\n","    def get_labels(self):\n","            labels = []\n","            for y_filename in self.y_filenames:\n","                y = Image.open(os.path.join(self.y_folder, y_filename))\n","                if self.transform:\n","                    y = self.transform(y)\n","                labels.append(y)\n","            return labels\n","\n","\n","# Definimos las rutas de las carpetas de entrenamiento y prueba\n","trainX_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/traindata/traindata/'\n","trainy_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/valdata/valdata/'\n","\n","# Creamos las transformaciones\n","transform = transforms.Compose([\n","    transforms.Resize((imageSize,imageSize)), #Ajuste de resolución\n","    transforms.Grayscale(), #Pasamos a escala de grises\n","    transforms.ToTensor(), #Convertimos en tensor\n","    transforms.Normalize((0.5), (0.5)),\n","])\n","\n","# Creamos el dataset personalizado de entrenamiento\n","dataset_full = CustomDataset(trainX_folder, trainy_folder, transform=transform)\n","dataset = dataset_full.get_images()\n","\n","# Creamos el dataloader\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2)\n","\n","# Definimos una función para inicializar los pesos tomando como entrada una red neuronal\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","# Creamos la clase que define el generador\n","class G(nn.Module):\n","\n","    def __init__(self):\n","        super(G, self).__init__()\n","        self.main = nn.Sequential(\n","            # La entrada será de tamaño nz, en este caso 100 y pasamos por una\n","            # capa de convolución transpuesta con salida ngf*16=2048\n","            nn.ConvTranspose2d(     nz, ngf * 16, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 16),\n","            nn.ReLU(True),\n","            # Pasamos por varias capas de convolucón transpuesta, reduciendo así\n","            # el tamaño. ngf = 128\n","            # (ngf*16) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # (ngf*8) x 8 x 8\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # (ngf*4) x 16 x 16\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # (ngf*2) x 32 x 32\n","            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # (ngf) x 64 x 64\n","            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # (nc) x 128 x 128\n","            # La salida será 1x128x128\n","        )\n","\n","\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Creamos el generador y lo pasamos a la GPU\n","netG = G().to(device)\n","netG.apply(weights_init)\n","\n","# Definimos la clase del discriminador\n","class D(nn.Module):\n","    def __init__(self):\n","        super(D, self).__init__()\n","        self.main = nn.Sequential(\n","            # La entrada será (nc) x 128 x 128\n","            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf) x 64 x 64\n","            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*2) x 32 x 32\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*4) x 16 x 16\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*8) x 8 x 8\n","            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 16),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*16) x 4 x 4\n","            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=False),\n","            nn.Sigmoid()\n","            # 1\n","        )\n","\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output.view(-1)\n","\n","\n","# Creamos el discriminador y lo pasamos a la GPU\n","netD = D().to(device)\n","netD.apply(weights_init)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKZoV58kwKKA","executionInfo":{"status":"ok","timestamp":1688487105379,"user_tz":-120,"elapsed":78492,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"f8669f57-ce9a-4dd5-f8e6-06c0b7f02139"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["D(\n","  (main): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (15): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!pip3 install torchview\n","!pip3 install graphviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5clAOFWUGmwM","executionInfo":{"status":"ok","timestamp":1688409142155,"user_tz":-120,"elapsed":8913,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"baf44a5f-aaeb-4ba0-890e-c0eef8970dd7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchview\n","  Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n","Installing collected packages: torchview\n","Successfully installed torchview-0.2.6\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"]}]},{"cell_type":"code","source":["from torchview import draw_graph\n","from torchvision.transforms import ToPILImage\n","import graphviz\n","\n","\n","model_gen = G()\n","model_dis = D()\n","\n","# Obtén el gráfico del modelo\n","model_graph_gen = draw_graph(model_gen, input_size=(1, 100, 1, 1), device='meta')\n","visual_graph_gen = model_graph_gen.visual_graph\n","\n","# Ajusta los estilos del grafo generador\n","visual_graph_gen.attr('node', shape='plain', style='filled', color='white')\n","visual_graph_gen.attr('graph', bgcolor='transparent')\n","#visual_graph_gen.attr(size='10,10!', margin='0.1')\n","\n","# Guarda el gráfico en formato DOT\n","dot_path_gen = \"modelo_gan_gen.dot\"\n","visual_graph_gen.save(dot_path_gen)\n","\n","# Convierte el archivo DOT a una imagen PNG usando Graphviz\n","output_path_gen = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/NN_Structure/modelo_gan_gen\"\n","graph_gen = graphviz.Source.from_file(dot_path_gen)\n","graph_gen.render(output_path_gen, format='pdf')\n","\n","# Obtén el gráfico del modelo\n","model_graph_dis = draw_graph(model_dis, input_size=(128, 1, 128, 128), device='meta')\n","visual_graph_dis = model_graph_dis.visual_graph\n","\n","# Ajusta los estilos del grafo discriminador\n","visual_graph_dis.attr('node', shape='plain', style='filled', color='white')\n","visual_graph_dis.attr('graph', bgcolor='transparent')\n","\n","# Guarda el gráfico en formato DOT\n","dot_path_dis = \"modelo_gan_dis.dot\"\n","visual_graph_dis.save(dot_path_dis)\n","\n","# Convierte el archivo DOT a una imagen PNG usando Graphviz\n","output_path_dis = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/NN_Structure/modelo_gan_dis\"\n","graph_dis = graphviz.Source.from_file(dot_path_dis)\n","graph_dis.render(output_path_dis, format='pdf')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RokgNv3NGio6","executionInfo":{"status":"ok","timestamp":1688409144252,"user_tz":-120,"elapsed":2103,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"95044caf-d834-4377-eaba-1cd2d05a593f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/NN_Structure/modelo_gan_dis.pdf'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Listas para almacenar los valores de loss\n","loss_G_values = []\n","loss_D_values = []\n","\n","# Comenzamos el entranamiento del GAN\n","criterion = nn.BCELoss()\n","optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n","#optimizerD = optim.SGD(netD.parameters(), lr=0.01, momentum=0.9)\n","#optimizerG = optim.SGD(netG.parameters(), lr=0.01, momentum=0.9)\n","\n","#Generamos carpetas para almacenar las imágenes creadas\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/Images')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/Images/fake_samples')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","\n","\n","for epoch in range(200):\n","    for i, data in enumerate(dataloader, 0): # iteramos sobre las imágenes del dataset\n","        # 1er paso: actualizamos los pesos de la red neuronal del discriminador\n","        netD.zero_grad()\n","        real = data.to(device) # Imagen real del dataset\n","        input = Variable(real).to(device) # la almacenamos en una variable\n","        target = torch.tensor(torch.ones(input.size()[0])).to(device) # Creamos el target\n","        output = netD(input)\n","        errD_real = criterion(output, target)\n","        # Entrenamos el discrimnador con una imagen false generada por el generador a partir de ruido\n","        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device)\n","        fake = netG(noise)\n","        target = Variable(torch.zeros(input.size()[0])).to(device)\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, target)\n","\n","        # Propagación hacia atrás de los errores del discriminador\n","        errD = errD_real + errD_fake\n","        errD.backward()\n","        optimizerD.step()\n","\n","        # 2º paso: actualizamos los pesos de la red neuronal del generador\n","\n","        netG.zero_grad()\n","        target = Variable(torch.ones(input.size()[0])).to(device)\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","\n","        #3er paso: Almaceno los valores de loss\n","        loss_G_values.append(errG.item())\n","        loss_D_values.append(errD.item())\n","\n","        # 4º paso: Sacamos por pantalla las pérdidas y alamacenamos un ejemplo de imagen real y las imagenes generadas del minibatch cada 100 pasos\n","\n","        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch+1, 200, i+1, len(dataloader), errD.data, errG.data))\n","        if i % 100 == 0: # Cada 100 pasos:\n","            vutils.save_image(real.cpu(), '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/Images/real_samples.png', normalize = True) # We save the real images of the minibatch.\n","            fake = netG(noise)\n","            vutils.save_image(fake.detach().cpu(), f'/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/Images/fake_samples/fake_samples_epoch_{epoch:03d}.png', normalize=True) # We also save the fake generated images of the minibatch."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85woEKOdkQPx","outputId":"8248e156-e09c-467b-c01f-571e49719645","executionInfo":{"status":"ok","timestamp":1688409753031,"user_tz":-120,"elapsed":608798,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-c15058fb8db1>:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target = torch.tensor(torch.ones(input.size()[0])).to(device) # Creamos el target\n"]},{"output_type":"stream","name":"stdout","text":["[1/200][1/4] Loss_D: 1.6833 Loss_G: 5.4555\n","[1/200][2/4] Loss_D: 6.5079 Loss_G: 2.4374\n","[1/200][3/4] Loss_D: 7.5006 Loss_G: 2.9678\n","[1/200][4/4] Loss_D: 7.8280 Loss_G: 4.0073\n","[2/200][1/4] Loss_D: 6.7163 Loss_G: 5.5114\n","[2/200][2/4] Loss_D: 5.7548 Loss_G: 7.2417\n","[2/200][3/4] Loss_D: 5.2529 Loss_G: 8.3089\n","[2/200][4/4] Loss_D: 5.5857 Loss_G: 8.9008\n","[3/200][1/4] Loss_D: 4.5706 Loss_G: 9.5837\n","[3/200][2/4] Loss_D: 4.3532 Loss_G: 10.3327\n","[3/200][3/4] Loss_D: 4.5226 Loss_G: 10.9253\n","[3/200][4/4] Loss_D: 4.6514 Loss_G: 11.2326\n","[4/200][1/4] Loss_D: 3.9821 Loss_G: 11.4530\n","[4/200][2/4] Loss_D: 3.3350 Loss_G: 11.9921\n","[4/200][3/4] Loss_D: 3.1006 Loss_G: 11.9763\n","[4/200][4/4] Loss_D: 3.6669 Loss_G: 12.9012\n","[5/200][1/4] Loss_D: 3.5750 Loss_G: 13.0092\n","[5/200][2/4] Loss_D: 3.0447 Loss_G: 11.6161\n","[5/200][3/4] Loss_D: 4.0870 Loss_G: 12.9080\n","[5/200][4/4] Loss_D: 2.6561 Loss_G: 10.3807\n","[6/200][1/4] Loss_D: 5.0820 Loss_G: 13.0751\n","[6/200][2/4] Loss_D: 2.5189 Loss_G: 12.2209\n","[6/200][3/4] Loss_D: 3.5665 Loss_G: 12.5998\n","[6/200][4/4] Loss_D: 2.6837 Loss_G: 12.7898\n","[7/200][1/4] Loss_D: 2.0811 Loss_G: 11.5845\n","[7/200][2/4] Loss_D: 2.9934 Loss_G: 13.6120\n","[7/200][3/4] Loss_D: 1.9431 Loss_G: 9.7327\n","[7/200][4/4] Loss_D: 5.6090 Loss_G: 12.9495\n","[8/200][1/4] Loss_D: 1.8195 Loss_G: 11.7624\n","[8/200][2/4] Loss_D: 2.1771 Loss_G: 12.6564\n","[8/200][3/4] Loss_D: 1.9825 Loss_G: 12.2783\n","[8/200][4/4] Loss_D: 2.3188 Loss_G: 11.2111\n","[9/200][1/4] Loss_D: 1.9500 Loss_G: 10.9214\n","[9/200][2/4] Loss_D: 2.1952 Loss_G: 12.8971\n","[9/200][3/4] Loss_D: 1.6156 Loss_G: 8.2825\n","[9/200][4/4] Loss_D: 3.6458 Loss_G: 11.7848\n","[10/200][1/4] Loss_D: 1.6810 Loss_G: 8.7971\n","[10/200][2/4] Loss_D: 2.7539 Loss_G: 11.4746\n","[10/200][3/4] Loss_D: 1.3141 Loss_G: 9.5287\n","[10/200][4/4] Loss_D: 2.5106 Loss_G: 11.6432\n","[11/200][1/4] Loss_D: 1.4255 Loss_G: 8.9897\n","[11/200][2/4] Loss_D: 3.6185 Loss_G: 13.1311\n","[11/200][3/4] Loss_D: 0.9374 Loss_G: 10.0222\n","[11/200][4/4] Loss_D: 1.6392 Loss_G: 9.3416\n","[12/200][1/4] Loss_D: 2.3058 Loss_G: 10.9321\n","[12/200][2/4] Loss_D: 0.7308 Loss_G: 8.6034\n","[12/200][3/4] Loss_D: 3.1453 Loss_G: 12.1870\n","[12/200][4/4] Loss_D: 1.1160 Loss_G: 9.1150\n","[13/200][1/4] Loss_D: 2.1905 Loss_G: 11.6617\n","[13/200][2/4] Loss_D: 1.1350 Loss_G: 8.7361\n","[13/200][3/4] Loss_D: 2.5546 Loss_G: 12.7323\n","[13/200][4/4] Loss_D: 0.8595 Loss_G: 8.9277\n","[14/200][1/4] Loss_D: 2.7658 Loss_G: 12.5077\n","[14/200][2/4] Loss_D: 1.1172 Loss_G: 9.0594\n","[14/200][3/4] Loss_D: 2.5302 Loss_G: 8.8143\n","[14/200][4/4] Loss_D: 1.3733 Loss_G: 7.9994\n","[15/200][1/4] Loss_D: 1.4980 Loss_G: 7.8864\n","[15/200][2/4] Loss_D: 1.3524 Loss_G: 7.7672\n","[15/200][3/4] Loss_D: 1.5651 Loss_G: 7.9519\n","[15/200][4/4] Loss_D: 1.6032 Loss_G: 7.8958\n","[16/200][1/4] Loss_D: 1.5645 Loss_G: 6.7386\n","[16/200][2/4] Loss_D: 2.4525 Loss_G: 6.8556\n","[16/200][3/4] Loss_D: 2.0940 Loss_G: 8.1120\n","[16/200][4/4] Loss_D: 2.0929 Loss_G: 8.0888\n","[17/200][1/4] Loss_D: 1.7968 Loss_G: 5.9667\n","[17/200][2/4] Loss_D: 2.3970 Loss_G: 7.5073\n","[17/200][3/4] Loss_D: 2.5248 Loss_G: 4.8304\n","[17/200][4/4] Loss_D: 1.9664 Loss_G: 4.0509\n","[18/200][1/4] Loss_D: 2.0941 Loss_G: 5.2524\n","[18/200][2/4] Loss_D: 1.6619 Loss_G: 4.2178\n","[18/200][3/4] Loss_D: 2.0894 Loss_G: 2.8364\n","[18/200][4/4] Loss_D: 2.1458 Loss_G: 2.7952\n","[19/200][1/4] Loss_D: 2.0529 Loss_G: 2.9583\n","[19/200][2/4] Loss_D: 2.2259 Loss_G: 3.9743\n","[19/200][3/4] Loss_D: 2.1104 Loss_G: 3.8356\n","[19/200][4/4] Loss_D: 2.2223 Loss_G: 2.4420\n","[20/200][1/4] Loss_D: 1.8256 Loss_G: 2.1741\n","[20/200][2/4] Loss_D: 1.7220 Loss_G: 3.2106\n","[20/200][3/4] Loss_D: 1.8288 Loss_G: 2.7454\n","[20/200][4/4] Loss_D: 1.9029 Loss_G: 1.7604\n","[21/200][1/4] Loss_D: 1.9954 Loss_G: 2.9109\n","[21/200][2/4] Loss_D: 1.4530 Loss_G: 2.6042\n","[21/200][3/4] Loss_D: 1.4389 Loss_G: 2.2367\n","[21/200][4/4] Loss_D: 1.5460 Loss_G: 2.3845\n","[22/200][1/4] Loss_D: 1.4032 Loss_G: 2.1972\n","[22/200][2/4] Loss_D: 1.6018 Loss_G: 2.6396\n","[22/200][3/4] Loss_D: 1.3579 Loss_G: 2.1988\n","[22/200][4/4] Loss_D: 1.4372 Loss_G: 2.4398\n","[23/200][1/4] Loss_D: 1.3823 Loss_G: 1.8089\n","[23/200][2/4] Loss_D: 1.2381 Loss_G: 1.6753\n","[23/200][3/4] Loss_D: 1.2171 Loss_G: 2.3511\n","[23/200][4/4] Loss_D: 1.2542 Loss_G: 2.0528\n","[24/200][1/4] Loss_D: 1.2928 Loss_G: 1.7769\n","[24/200][2/4] Loss_D: 1.3432 Loss_G: 1.8819\n","[24/200][3/4] Loss_D: 1.3018 Loss_G: 2.0094\n","[24/200][4/4] Loss_D: 1.3454 Loss_G: 2.4136\n","[25/200][1/4] Loss_D: 1.3964 Loss_G: 2.2509\n","[25/200][2/4] Loss_D: 1.3607 Loss_G: 1.8773\n","[25/200][3/4] Loss_D: 1.4311 Loss_G: 1.8389\n","[25/200][4/4] Loss_D: 1.4174 Loss_G: 1.9786\n","[26/200][1/4] Loss_D: 1.4420 Loss_G: 1.7355\n","[26/200][2/4] Loss_D: 1.3362 Loss_G: 2.3129\n","[26/200][3/4] Loss_D: 1.3772 Loss_G: 2.1441\n","[26/200][4/4] Loss_D: 1.4309 Loss_G: 1.7969\n","[27/200][1/4] Loss_D: 1.3842 Loss_G: 2.6627\n","[27/200][2/4] Loss_D: 1.5079 Loss_G: 2.4349\n","[27/200][3/4] Loss_D: 1.4101 Loss_G: 2.4219\n","[27/200][4/4] Loss_D: 1.8317 Loss_G: 2.3175\n","[28/200][1/4] Loss_D: 1.6520 Loss_G: 3.5119\n","[28/200][2/4] Loss_D: 1.7409 Loss_G: 3.4617\n","[28/200][3/4] Loss_D: 1.6704 Loss_G: 3.0489\n","[28/200][4/4] Loss_D: 1.6683 Loss_G: 4.7308\n","[29/200][1/4] Loss_D: 1.7464 Loss_G: 4.7475\n","[29/200][2/4] Loss_D: 2.0046 Loss_G: 4.3193\n","[29/200][3/4] Loss_D: 1.7354 Loss_G: 4.7033\n","[29/200][4/4] Loss_D: 2.1449 Loss_G: 4.0148\n","[30/200][1/4] Loss_D: 1.7741 Loss_G: 3.7300\n","[30/200][2/4] Loss_D: 1.5725 Loss_G: 4.2712\n","[30/200][3/4] Loss_D: 1.5232 Loss_G: 4.2167\n","[30/200][4/4] Loss_D: 1.3781 Loss_G: 4.0301\n","[31/200][1/4] Loss_D: 1.5040 Loss_G: 4.0060\n","[31/200][2/4] Loss_D: 1.6785 Loss_G: 3.6840\n","[31/200][3/4] Loss_D: 1.4545 Loss_G: 3.6922\n","[31/200][4/4] Loss_D: 1.4791 Loss_G: 2.7316\n","[32/200][1/4] Loss_D: 1.4511 Loss_G: 3.1926\n","[32/200][2/4] Loss_D: 1.3867 Loss_G: 3.2510\n","[32/200][3/4] Loss_D: 1.4846 Loss_G: 2.9432\n","[32/200][4/4] Loss_D: 1.4050 Loss_G: 2.7918\n","[33/200][1/4] Loss_D: 1.5562 Loss_G: 3.3324\n","[33/200][2/4] Loss_D: 1.5869 Loss_G: 3.6955\n","[33/200][3/4] Loss_D: 1.8266 Loss_G: 2.8722\n","[33/200][4/4] Loss_D: 1.5210 Loss_G: 2.4666\n","[34/200][1/4] Loss_D: 1.4007 Loss_G: 3.6654\n","[34/200][2/4] Loss_D: 1.2968 Loss_G: 2.6988\n","[34/200][3/4] Loss_D: 1.3836 Loss_G: 2.4094\n","[34/200][4/4] Loss_D: 1.2274 Loss_G: 3.6580\n","[35/200][1/4] Loss_D: 1.2060 Loss_G: 2.9249\n","[35/200][2/4] Loss_D: 1.1068 Loss_G: 2.1611\n","[35/200][3/4] Loss_D: 1.1858 Loss_G: 2.3937\n","[35/200][4/4] Loss_D: 1.2308 Loss_G: 2.7257\n","[36/200][1/4] Loss_D: 1.2081 Loss_G: 2.6706\n","[36/200][2/4] Loss_D: 1.6051 Loss_G: 2.3578\n","[36/200][3/4] Loss_D: 1.2918 Loss_G: 2.7037\n","[36/200][4/4] Loss_D: 1.4311 Loss_G: 3.0080\n","[37/200][1/4] Loss_D: 1.5349 Loss_G: 2.5741\n","[37/200][2/4] Loss_D: 1.0454 Loss_G: 2.6010\n","[37/200][3/4] Loss_D: 1.1176 Loss_G: 2.6197\n","[37/200][4/4] Loss_D: 1.2243 Loss_G: 2.2320\n","[38/200][1/4] Loss_D: 1.4119 Loss_G: 2.0162\n","[38/200][2/4] Loss_D: 1.5373 Loss_G: 2.0130\n","[38/200][3/4] Loss_D: 1.5145 Loss_G: 2.1049\n","[38/200][4/4] Loss_D: 1.5370 Loss_G: 2.3706\n","[39/200][1/4] Loss_D: 1.3500 Loss_G: 2.1981\n","[39/200][2/4] Loss_D: 1.2348 Loss_G: 1.8457\n","[39/200][3/4] Loss_D: 1.1041 Loss_G: 2.2146\n","[39/200][4/4] Loss_D: 1.1311 Loss_G: 2.1094\n","[40/200][1/4] Loss_D: 1.1411 Loss_G: 2.0128\n","[40/200][2/4] Loss_D: 1.0317 Loss_G: 2.0912\n","[40/200][3/4] Loss_D: 1.2857 Loss_G: 2.4142\n","[40/200][4/4] Loss_D: 1.1061 Loss_G: 2.3862\n","[41/200][1/4] Loss_D: 1.1746 Loss_G: 2.0276\n","[41/200][2/4] Loss_D: 1.3364 Loss_G: 2.0737\n","[41/200][3/4] Loss_D: 1.1363 Loss_G: 1.8473\n","[41/200][4/4] Loss_D: 1.2460 Loss_G: 1.6132\n","[42/200][1/4] Loss_D: 1.6259 Loss_G: 2.1965\n","[42/200][2/4] Loss_D: 1.1216 Loss_G: 2.3484\n","[42/200][3/4] Loss_D: 1.2516 Loss_G: 1.9999\n","[42/200][4/4] Loss_D: 1.1564 Loss_G: 1.8246\n","[43/200][1/4] Loss_D: 1.2711 Loss_G: 1.4359\n","[43/200][2/4] Loss_D: 1.3215 Loss_G: 1.6620\n","[43/200][3/4] Loss_D: 1.1565 Loss_G: 1.7140\n","[43/200][4/4] Loss_D: 1.0213 Loss_G: 2.0320\n","[44/200][1/4] Loss_D: 0.9883 Loss_G: 1.9641\n","[44/200][2/4] Loss_D: 1.1404 Loss_G: 1.4769\n","[44/200][3/4] Loss_D: 1.4803 Loss_G: 1.8665\n","[44/200][4/4] Loss_D: 1.2651 Loss_G: 2.1350\n","[45/200][1/4] Loss_D: 1.3334 Loss_G: 2.0203\n","[45/200][2/4] Loss_D: 1.5532 Loss_G: 1.5312\n","[45/200][3/4] Loss_D: 1.2119 Loss_G: 1.6997\n","[45/200][4/4] Loss_D: 1.2201 Loss_G: 1.6685\n","[46/200][1/4] Loss_D: 1.2570 Loss_G: 1.6145\n","[46/200][2/4] Loss_D: 1.5446 Loss_G: 1.5182\n","[46/200][3/4] Loss_D: 1.3615 Loss_G: 1.6322\n","[46/200][4/4] Loss_D: 1.0767 Loss_G: 1.7072\n","[47/200][1/4] Loss_D: 1.1912 Loss_G: 1.5832\n","[47/200][2/4] Loss_D: 1.1732 Loss_G: 1.6107\n","[47/200][3/4] Loss_D: 1.2303 Loss_G: 1.9681\n","[47/200][4/4] Loss_D: 1.2135 Loss_G: 1.6147\n","[48/200][1/4] Loss_D: 1.1904 Loss_G: 1.4433\n","[48/200][2/4] Loss_D: 1.1410 Loss_G: 1.3483\n","[48/200][3/4] Loss_D: 1.1834 Loss_G: 1.6861\n","[48/200][4/4] Loss_D: 1.1049 Loss_G: 1.5747\n","[49/200][1/4] Loss_D: 1.1042 Loss_G: 1.7926\n","[49/200][2/4] Loss_D: 1.2179 Loss_G: 1.7292\n","[49/200][3/4] Loss_D: 1.1140 Loss_G: 1.5091\n","[49/200][4/4] Loss_D: 1.1675 Loss_G: 1.7157\n","[50/200][1/4] Loss_D: 1.1342 Loss_G: 1.5689\n","[50/200][2/4] Loss_D: 1.1613 Loss_G: 1.4537\n","[50/200][3/4] Loss_D: 0.8994 Loss_G: 1.5463\n","[50/200][4/4] Loss_D: 1.2035 Loss_G: 1.5397\n","[51/200][1/4] Loss_D: 1.1376 Loss_G: 1.9444\n","[51/200][2/4] Loss_D: 1.1369 Loss_G: 1.7623\n","[51/200][3/4] Loss_D: 1.3145 Loss_G: 1.6871\n","[51/200][4/4] Loss_D: 1.3630 Loss_G: 1.4981\n","[52/200][1/4] Loss_D: 0.9518 Loss_G: 1.5307\n","[52/200][2/4] Loss_D: 0.9994 Loss_G: 1.6226\n","[52/200][3/4] Loss_D: 1.1703 Loss_G: 1.4605\n","[52/200][4/4] Loss_D: 1.1660 Loss_G: 1.5423\n","[53/200][1/4] Loss_D: 1.0768 Loss_G: 1.7348\n","[53/200][2/4] Loss_D: 1.1032 Loss_G: 1.6759\n","[53/200][3/4] Loss_D: 1.0965 Loss_G: 1.6941\n","[53/200][4/4] Loss_D: 0.9996 Loss_G: 1.6688\n","[54/200][1/4] Loss_D: 1.0484 Loss_G: 1.6033\n","[54/200][2/4] Loss_D: 1.0951 Loss_G: 1.8309\n","[54/200][3/4] Loss_D: 0.9512 Loss_G: 1.7636\n","[54/200][4/4] Loss_D: 1.0867 Loss_G: 1.3027\n","[55/200][1/4] Loss_D: 1.1305 Loss_G: 1.4679\n","[55/200][2/4] Loss_D: 1.0884 Loss_G: 1.5431\n","[55/200][3/4] Loss_D: 1.0622 Loss_G: 1.6215\n","[55/200][4/4] Loss_D: 0.8665 Loss_G: 1.9153\n","[56/200][1/4] Loss_D: 0.9432 Loss_G: 1.5264\n","[56/200][2/4] Loss_D: 0.8259 Loss_G: 1.5724\n","[56/200][3/4] Loss_D: 0.7818 Loss_G: 1.8494\n","[56/200][4/4] Loss_D: 1.0272 Loss_G: 1.8027\n","[57/200][1/4] Loss_D: 1.1156 Loss_G: 1.9252\n","[57/200][2/4] Loss_D: 1.2007 Loss_G: 2.2195\n","[57/200][3/4] Loss_D: 1.2334 Loss_G: 1.9763\n","[57/200][4/4] Loss_D: 1.1942 Loss_G: 1.6254\n","[58/200][1/4] Loss_D: 0.9570 Loss_G: 1.9023\n","[58/200][2/4] Loss_D: 0.9469 Loss_G: 2.1603\n","[58/200][3/4] Loss_D: 1.0734 Loss_G: 1.7480\n","[58/200][4/4] Loss_D: 1.1405 Loss_G: 1.5489\n","[59/200][1/4] Loss_D: 0.9912 Loss_G: 1.7444\n","[59/200][2/4] Loss_D: 1.2636 Loss_G: 1.4711\n","[59/200][3/4] Loss_D: 1.2431 Loss_G: 1.6961\n","[59/200][4/4] Loss_D: 1.0717 Loss_G: 2.4273\n","[60/200][1/4] Loss_D: 0.8500 Loss_G: 1.9833\n","[60/200][2/4] Loss_D: 1.0787 Loss_G: 1.3486\n","[60/200][3/4] Loss_D: 1.0494 Loss_G: 1.6820\n","[60/200][4/4] Loss_D: 1.1798 Loss_G: 1.8557\n","[61/200][1/4] Loss_D: 0.8808 Loss_G: 1.9608\n","[61/200][2/4] Loss_D: 1.2122 Loss_G: 1.3541\n","[61/200][3/4] Loss_D: 1.0339 Loss_G: 1.2768\n","[61/200][4/4] Loss_D: 1.0343 Loss_G: 1.6284\n","[62/200][1/4] Loss_D: 0.8913 Loss_G: 1.8236\n","[62/200][2/4] Loss_D: 0.8953 Loss_G: 1.6745\n","[62/200][3/4] Loss_D: 0.9681 Loss_G: 1.5849\n","[62/200][4/4] Loss_D: 1.0796 Loss_G: 1.7605\n","[63/200][1/4] Loss_D: 1.0024 Loss_G: 1.7770\n","[63/200][2/4] Loss_D: 0.9696 Loss_G: 1.7971\n","[63/200][3/4] Loss_D: 1.3166 Loss_G: 1.4966\n","[63/200][4/4] Loss_D: 0.9877 Loss_G: 1.4583\n","[64/200][1/4] Loss_D: 0.9331 Loss_G: 1.9405\n","[64/200][2/4] Loss_D: 1.1425 Loss_G: 1.6843\n","[64/200][3/4] Loss_D: 1.1089 Loss_G: 1.4333\n","[64/200][4/4] Loss_D: 0.9486 Loss_G: 1.8212\n","[65/200][1/4] Loss_D: 1.0596 Loss_G: 1.8636\n","[65/200][2/4] Loss_D: 1.2088 Loss_G: 1.3235\n","[65/200][3/4] Loss_D: 0.9314 Loss_G: 1.9550\n","[65/200][4/4] Loss_D: 0.9875 Loss_G: 1.6709\n","[66/200][1/4] Loss_D: 0.8458 Loss_G: 1.6967\n","[66/200][2/4] Loss_D: 0.9129 Loss_G: 1.6406\n","[66/200][3/4] Loss_D: 0.7966 Loss_G: 1.7882\n","[66/200][4/4] Loss_D: 0.9304 Loss_G: 1.6355\n","[67/200][1/4] Loss_D: 0.9150 Loss_G: 1.5918\n","[67/200][2/4] Loss_D: 1.0162 Loss_G: 1.6609\n","[67/200][3/4] Loss_D: 0.8785 Loss_G: 1.9282\n","[67/200][4/4] Loss_D: 0.9649 Loss_G: 1.7774\n","[68/200][1/4] Loss_D: 0.9056 Loss_G: 1.5873\n","[68/200][2/4] Loss_D: 0.9783 Loss_G: 1.6455\n","[68/200][3/4] Loss_D: 1.0552 Loss_G: 1.7560\n","[68/200][4/4] Loss_D: 1.0012 Loss_G: 1.5578\n","[69/200][1/4] Loss_D: 0.9784 Loss_G: 1.6639\n","[69/200][2/4] Loss_D: 0.7857 Loss_G: 2.0113\n","[69/200][3/4] Loss_D: 0.9573 Loss_G: 1.6412\n","[69/200][4/4] Loss_D: 0.8528 Loss_G: 1.8309\n","[70/200][1/4] Loss_D: 0.6818 Loss_G: 2.0009\n","[70/200][2/4] Loss_D: 0.8447 Loss_G: 1.7843\n","[70/200][3/4] Loss_D: 0.8147 Loss_G: 1.9617\n","[70/200][4/4] Loss_D: 1.0512 Loss_G: 1.8186\n","[71/200][1/4] Loss_D: 0.8618 Loss_G: 1.9049\n","[71/200][2/4] Loss_D: 0.8056 Loss_G: 1.8123\n","[71/200][3/4] Loss_D: 0.9356 Loss_G: 2.0550\n","[71/200][4/4] Loss_D: 1.0546 Loss_G: 1.6870\n","[72/200][1/4] Loss_D: 0.9556 Loss_G: 1.5707\n","[72/200][2/4] Loss_D: 0.9469 Loss_G: 1.8754\n","[72/200][3/4] Loss_D: 0.8412 Loss_G: 2.0085\n","[72/200][4/4] Loss_D: 1.1208 Loss_G: 1.5370\n","[73/200][1/4] Loss_D: 0.9453 Loss_G: 1.7785\n","[73/200][2/4] Loss_D: 0.8542 Loss_G: 1.7482\n","[73/200][3/4] Loss_D: 0.8503 Loss_G: 1.7815\n","[73/200][4/4] Loss_D: 0.7952 Loss_G: 1.8560\n","[74/200][1/4] Loss_D: 0.8152 Loss_G: 1.9402\n","[74/200][2/4] Loss_D: 0.6620 Loss_G: 2.0659\n","[74/200][3/4] Loss_D: 0.9891 Loss_G: 1.5843\n","[74/200][4/4] Loss_D: 0.9517 Loss_G: 1.9062\n","[75/200][1/4] Loss_D: 0.8179 Loss_G: 1.9059\n","[75/200][2/4] Loss_D: 0.7811 Loss_G: 1.8115\n","[75/200][3/4] Loss_D: 1.1479 Loss_G: 1.5575\n","[75/200][4/4] Loss_D: 0.9941 Loss_G: 1.8826\n","[76/200][1/4] Loss_D: 0.6690 Loss_G: 2.2433\n","[76/200][2/4] Loss_D: 0.9863 Loss_G: 2.0849\n","[76/200][3/4] Loss_D: 0.7748 Loss_G: 2.1626\n","[76/200][4/4] Loss_D: 0.8230 Loss_G: 2.0978\n","[77/200][1/4] Loss_D: 0.7022 Loss_G: 2.4692\n","[77/200][2/4] Loss_D: 0.8352 Loss_G: 2.1356\n","[77/200][3/4] Loss_D: 0.9015 Loss_G: 1.9997\n","[77/200][4/4] Loss_D: 0.8059 Loss_G: 1.8822\n","[78/200][1/4] Loss_D: 1.1632 Loss_G: 2.5043\n","[78/200][2/4] Loss_D: 0.6391 Loss_G: 3.0018\n","[78/200][3/4] Loss_D: 0.9667 Loss_G: 1.8267\n","[78/200][4/4] Loss_D: 0.9801 Loss_G: 1.5655\n","[79/200][1/4] Loss_D: 0.8419 Loss_G: 2.4359\n","[79/200][2/4] Loss_D: 0.7761 Loss_G: 2.4253\n","[79/200][3/4] Loss_D: 1.0903 Loss_G: 1.7776\n","[79/200][4/4] Loss_D: 1.0628 Loss_G: 1.8416\n","[80/200][1/4] Loss_D: 0.7158 Loss_G: 2.3831\n","[80/200][2/4] Loss_D: 1.0127 Loss_G: 2.0183\n","[80/200][3/4] Loss_D: 0.9541 Loss_G: 1.8380\n","[80/200][4/4] Loss_D: 0.8699 Loss_G: 2.1099\n","[81/200][1/4] Loss_D: 0.7120 Loss_G: 2.4358\n","[81/200][2/4] Loss_D: 0.7052 Loss_G: 2.3248\n","[81/200][3/4] Loss_D: 0.8099 Loss_G: 2.0743\n","[81/200][4/4] Loss_D: 0.9264 Loss_G: 1.9024\n","[82/200][1/4] Loss_D: 0.7747 Loss_G: 2.4003\n","[82/200][2/4] Loss_D: 0.6395 Loss_G: 2.3605\n","[82/200][3/4] Loss_D: 0.9219 Loss_G: 1.8325\n","[82/200][4/4] Loss_D: 0.9041 Loss_G: 1.8337\n","[83/200][1/4] Loss_D: 0.8130 Loss_G: 2.2040\n","[83/200][2/4] Loss_D: 0.6927 Loss_G: 1.9887\n","[83/200][3/4] Loss_D: 0.9223 Loss_G: 1.8555\n","[83/200][4/4] Loss_D: 0.8271 Loss_G: 2.1885\n","[84/200][1/4] Loss_D: 1.0712 Loss_G: 2.0628\n","[84/200][2/4] Loss_D: 1.0106 Loss_G: 2.4020\n","[84/200][3/4] Loss_D: 1.0035 Loss_G: 1.6803\n","[84/200][4/4] Loss_D: 0.9463 Loss_G: 1.7343\n","[85/200][1/4] Loss_D: 0.8960 Loss_G: 2.0201\n","[85/200][2/4] Loss_D: 0.9059 Loss_G: 1.7431\n","[85/200][3/4] Loss_D: 1.0055 Loss_G: 1.7953\n","[85/200][4/4] Loss_D: 1.1111 Loss_G: 2.0251\n","[86/200][1/4] Loss_D: 0.8175 Loss_G: 2.4377\n","[86/200][2/4] Loss_D: 0.9629 Loss_G: 2.1706\n","[86/200][3/4] Loss_D: 0.8080 Loss_G: 2.2888\n","[86/200][4/4] Loss_D: 0.8735 Loss_G: 2.1901\n","[87/200][1/4] Loss_D: 1.1145 Loss_G: 2.7847\n","[87/200][2/4] Loss_D: 1.0998 Loss_G: 1.8711\n","[87/200][3/4] Loss_D: 0.8714 Loss_G: 1.7797\n","[87/200][4/4] Loss_D: 0.9056 Loss_G: 2.1296\n","[88/200][1/4] Loss_D: 0.8605 Loss_G: 2.4122\n","[88/200][2/4] Loss_D: 0.9022 Loss_G: 2.5607\n","[88/200][3/4] Loss_D: 0.8603 Loss_G: 1.8903\n","[88/200][4/4] Loss_D: 0.7465 Loss_G: 1.8167\n","[89/200][1/4] Loss_D: 0.9002 Loss_G: 2.2930\n","[89/200][2/4] Loss_D: 0.7354 Loss_G: 2.3209\n","[89/200][3/4] Loss_D: 0.9672 Loss_G: 1.6719\n","[89/200][4/4] Loss_D: 0.8859 Loss_G: 1.7589\n","[90/200][1/4] Loss_D: 0.8643 Loss_G: 1.8917\n","[90/200][2/4] Loss_D: 0.8708 Loss_G: 1.8952\n","[90/200][3/4] Loss_D: 0.8862 Loss_G: 2.0044\n","[90/200][4/4] Loss_D: 0.8029 Loss_G: 1.7839\n","[91/200][1/4] Loss_D: 0.8405 Loss_G: 1.5820\n","[91/200][2/4] Loss_D: 1.0051 Loss_G: 1.8366\n","[91/200][3/4] Loss_D: 0.8069 Loss_G: 2.1745\n","[91/200][4/4] Loss_D: 1.0315 Loss_G: 1.8008\n","[92/200][1/4] Loss_D: 0.8101 Loss_G: 2.5205\n","[92/200][2/4] Loss_D: 0.9370 Loss_G: 2.0570\n","[92/200][3/4] Loss_D: 0.8379 Loss_G: 2.0308\n","[92/200][4/4] Loss_D: 0.8417 Loss_G: 2.7220\n","[93/200][1/4] Loss_D: 0.7921 Loss_G: 3.3886\n","[93/200][2/4] Loss_D: 0.9231 Loss_G: 1.9889\n","[93/200][3/4] Loss_D: 0.9178 Loss_G: 1.9773\n","[93/200][4/4] Loss_D: 0.9315 Loss_G: 2.1887\n","[94/200][1/4] Loss_D: 0.9385 Loss_G: 1.9782\n","[94/200][2/4] Loss_D: 0.9591 Loss_G: 2.1749\n","[94/200][3/4] Loss_D: 0.9222 Loss_G: 1.8681\n","[94/200][4/4] Loss_D: 0.7200 Loss_G: 2.1243\n","[95/200][1/4] Loss_D: 0.7344 Loss_G: 2.1841\n","[95/200][2/4] Loss_D: 0.8490 Loss_G: 2.1435\n","[95/200][3/4] Loss_D: 0.8810 Loss_G: 1.8041\n","[95/200][4/4] Loss_D: 0.8586 Loss_G: 2.3657\n","[96/200][1/4] Loss_D: 0.7707 Loss_G: 2.3312\n","[96/200][2/4] Loss_D: 0.6744 Loss_G: 2.4005\n","[96/200][3/4] Loss_D: 1.0858 Loss_G: 1.8829\n","[96/200][4/4] Loss_D: 0.9807 Loss_G: 2.4166\n","[97/200][1/4] Loss_D: 0.8219 Loss_G: 2.6938\n","[97/200][2/4] Loss_D: 0.9028 Loss_G: 2.5597\n","[97/200][3/4] Loss_D: 0.8784 Loss_G: 2.2764\n","[97/200][4/4] Loss_D: 1.0148 Loss_G: 2.2280\n","[98/200][1/4] Loss_D: 0.7725 Loss_G: 2.3595\n","[98/200][2/4] Loss_D: 0.9486 Loss_G: 1.7429\n","[98/200][3/4] Loss_D: 0.8903 Loss_G: 1.5650\n","[98/200][4/4] Loss_D: 0.8485 Loss_G: 2.8908\n","[99/200][1/4] Loss_D: 0.9350 Loss_G: 1.8429\n","[99/200][2/4] Loss_D: 0.9013 Loss_G: 2.7315\n","[99/200][3/4] Loss_D: 0.7867 Loss_G: 2.1977\n","[99/200][4/4] Loss_D: 0.5633 Loss_G: 2.1502\n","[100/200][1/4] Loss_D: 0.8570 Loss_G: 2.8082\n","[100/200][2/4] Loss_D: 1.0856 Loss_G: 1.5661\n","[100/200][3/4] Loss_D: 0.9026 Loss_G: 2.2597\n","[100/200][4/4] Loss_D: 0.8022 Loss_G: 2.5384\n","[101/200][1/4] Loss_D: 0.7934 Loss_G: 2.0556\n","[101/200][2/4] Loss_D: 0.9262 Loss_G: 1.8972\n","[101/200][3/4] Loss_D: 0.9917 Loss_G: 2.6790\n","[101/200][4/4] Loss_D: 1.0901 Loss_G: 2.4526\n","[102/200][1/4] Loss_D: 0.8031 Loss_G: 2.2452\n","[102/200][2/4] Loss_D: 0.7591 Loss_G: 2.3598\n","[102/200][3/4] Loss_D: 0.8938 Loss_G: 2.2136\n","[102/200][4/4] Loss_D: 0.7679 Loss_G: 2.3001\n","[103/200][1/4] Loss_D: 0.8420 Loss_G: 1.8659\n","[103/200][2/4] Loss_D: 0.8712 Loss_G: 2.2805\n","[103/200][3/4] Loss_D: 0.7545 Loss_G: 2.0069\n","[103/200][4/4] Loss_D: 0.8152 Loss_G: 1.9460\n","[104/200][1/4] Loss_D: 0.8764 Loss_G: 1.9981\n","[104/200][2/4] Loss_D: 0.9025 Loss_G: 2.1990\n","[104/200][3/4] Loss_D: 0.9082 Loss_G: 2.1363\n","[104/200][4/4] Loss_D: 0.8465 Loss_G: 2.1389\n","[105/200][1/4] Loss_D: 0.7270 Loss_G: 2.1587\n","[105/200][2/4] Loss_D: 0.8811 Loss_G: 2.8976\n","[105/200][3/4] Loss_D: 0.9644 Loss_G: 1.9106\n","[105/200][4/4] Loss_D: 0.8986 Loss_G: 2.0717\n","[106/200][1/4] Loss_D: 0.8679 Loss_G: 2.5274\n","[106/200][2/4] Loss_D: 0.9154 Loss_G: 1.8966\n","[106/200][3/4] Loss_D: 0.9759 Loss_G: 1.8291\n","[106/200][4/4] Loss_D: 0.7927 Loss_G: 2.5005\n","[107/200][1/4] Loss_D: 0.7335 Loss_G: 2.0862\n","[107/200][2/4] Loss_D: 0.7854 Loss_G: 2.1250\n","[107/200][3/4] Loss_D: 0.9378 Loss_G: 1.7096\n","[107/200][4/4] Loss_D: 1.0522 Loss_G: 1.9875\n","[108/200][1/4] Loss_D: 0.9114 Loss_G: 2.0758\n","[108/200][2/4] Loss_D: 0.9012 Loss_G: 1.9023\n","[108/200][3/4] Loss_D: 0.9817 Loss_G: 1.7134\n","[108/200][4/4] Loss_D: 1.0075 Loss_G: 2.1349\n","[109/200][1/4] Loss_D: 0.9366 Loss_G: 1.9180\n","[109/200][2/4] Loss_D: 0.9147 Loss_G: 1.6158\n","[109/200][3/4] Loss_D: 0.9526 Loss_G: 2.3659\n","[109/200][4/4] Loss_D: 0.8542 Loss_G: 2.1207\n","[110/200][1/4] Loss_D: 0.8173 Loss_G: 1.4209\n","[110/200][2/4] Loss_D: 0.8018 Loss_G: 1.7807\n","[110/200][3/4] Loss_D: 0.9252 Loss_G: 2.0004\n","[110/200][4/4] Loss_D: 0.9341 Loss_G: 1.8420\n","[111/200][1/4] Loss_D: 0.9223 Loss_G: 1.9349\n","[111/200][2/4] Loss_D: 0.8874 Loss_G: 1.7179\n","[111/200][3/4] Loss_D: 1.0274 Loss_G: 1.8317\n","[111/200][4/4] Loss_D: 0.8370 Loss_G: 1.7397\n","[112/200][1/4] Loss_D: 0.8844 Loss_G: 2.1004\n","[112/200][2/4] Loss_D: 0.8978 Loss_G: 2.2420\n","[112/200][3/4] Loss_D: 0.8980 Loss_G: 1.7201\n","[112/200][4/4] Loss_D: 0.9680 Loss_G: 1.6689\n","[113/200][1/4] Loss_D: 1.0263 Loss_G: 2.2250\n","[113/200][2/4] Loss_D: 0.8016 Loss_G: 2.0961\n","[113/200][3/4] Loss_D: 1.2583 Loss_G: 1.4616\n","[113/200][4/4] Loss_D: 1.2075 Loss_G: 2.6552\n","[114/200][1/4] Loss_D: 0.7622 Loss_G: 2.3498\n","[114/200][2/4] Loss_D: 0.9286 Loss_G: 1.9733\n","[114/200][3/4] Loss_D: 1.0364 Loss_G: 2.7964\n","[114/200][4/4] Loss_D: 0.9710 Loss_G: 1.8566\n","[115/200][1/4] Loss_D: 0.8460 Loss_G: 2.0043\n","[115/200][2/4] Loss_D: 0.8693 Loss_G: 1.7938\n","[115/200][3/4] Loss_D: 1.0943 Loss_G: 1.9402\n","[115/200][4/4] Loss_D: 0.9937 Loss_G: 2.0025\n","[116/200][1/4] Loss_D: 0.9602 Loss_G: 1.7564\n","[116/200][2/4] Loss_D: 0.7725 Loss_G: 2.0910\n","[116/200][3/4] Loss_D: 0.8552 Loss_G: 1.8502\n","[116/200][4/4] Loss_D: 0.9041 Loss_G: 1.9059\n","[117/200][1/4] Loss_D: 0.7954 Loss_G: 2.3097\n","[117/200][2/4] Loss_D: 0.9065 Loss_G: 1.6025\n","[117/200][3/4] Loss_D: 1.0798 Loss_G: 2.1573\n","[117/200][4/4] Loss_D: 0.8203 Loss_G: 2.0881\n","[118/200][1/4] Loss_D: 0.7947 Loss_G: 1.8715\n","[118/200][2/4] Loss_D: 1.0419 Loss_G: 2.0965\n","[118/200][3/4] Loss_D: 0.7988 Loss_G: 2.1532\n","[118/200][4/4] Loss_D: 1.0972 Loss_G: 1.9729\n","[119/200][1/4] Loss_D: 0.8000 Loss_G: 2.0045\n","[119/200][2/4] Loss_D: 0.8483 Loss_G: 2.1121\n","[119/200][3/4] Loss_D: 0.9300 Loss_G: 1.8504\n","[119/200][4/4] Loss_D: 0.7302 Loss_G: 2.0623\n","[120/200][1/4] Loss_D: 0.7816 Loss_G: 2.1673\n","[120/200][2/4] Loss_D: 0.7325 Loss_G: 2.0025\n","[120/200][3/4] Loss_D: 0.8904 Loss_G: 2.0288\n","[120/200][4/4] Loss_D: 0.9311 Loss_G: 1.8645\n","[121/200][1/4] Loss_D: 0.8396 Loss_G: 2.1922\n","[121/200][2/4] Loss_D: 0.9200 Loss_G: 1.7901\n","[121/200][3/4] Loss_D: 1.0451 Loss_G: 2.1105\n","[121/200][4/4] Loss_D: 0.8517 Loss_G: 2.2567\n","[122/200][1/4] Loss_D: 0.8029 Loss_G: 2.4062\n","[122/200][2/4] Loss_D: 0.8210 Loss_G: 2.1332\n","[122/200][3/4] Loss_D: 1.2711 Loss_G: 1.7798\n","[122/200][4/4] Loss_D: 0.6866 Loss_G: 2.2658\n","[123/200][1/4] Loss_D: 0.7068 Loss_G: 2.0637\n","[123/200][2/4] Loss_D: 0.9177 Loss_G: 2.3640\n","[123/200][3/4] Loss_D: 0.8553 Loss_G: 1.8387\n","[123/200][4/4] Loss_D: 0.8841 Loss_G: 1.9211\n","[124/200][1/4] Loss_D: 0.7717 Loss_G: 2.1768\n","[124/200][2/4] Loss_D: 0.7540 Loss_G: 2.1097\n","[124/200][3/4] Loss_D: 0.7769 Loss_G: 1.8223\n","[124/200][4/4] Loss_D: 1.0478 Loss_G: 2.1056\n","[125/200][1/4] Loss_D: 0.8004 Loss_G: 2.3838\n","[125/200][2/4] Loss_D: 1.0458 Loss_G: 1.5017\n","[125/200][3/4] Loss_D: 0.8830 Loss_G: 2.2495\n","[125/200][4/4] Loss_D: 0.9447 Loss_G: 2.1010\n","[126/200][1/4] Loss_D: 0.6559 Loss_G: 2.0203\n","[126/200][2/4] Loss_D: 0.8356 Loss_G: 2.4608\n","[126/200][3/4] Loss_D: 0.8628 Loss_G: 2.1429\n","[126/200][4/4] Loss_D: 0.8186 Loss_G: 1.5123\n","[127/200][1/4] Loss_D: 1.0291 Loss_G: 2.3509\n","[127/200][2/4] Loss_D: 0.7718 Loss_G: 2.0578\n","[127/200][3/4] Loss_D: 0.6227 Loss_G: 2.1206\n","[127/200][4/4] Loss_D: 0.8645 Loss_G: 1.9092\n","[128/200][1/4] Loss_D: 0.8283 Loss_G: 2.4475\n","[128/200][2/4] Loss_D: 0.8619 Loss_G: 2.0949\n","[128/200][3/4] Loss_D: 0.8756 Loss_G: 2.0160\n","[128/200][4/4] Loss_D: 0.8309 Loss_G: 2.1661\n","[129/200][1/4] Loss_D: 0.7785 Loss_G: 1.7701\n","[129/200][2/4] Loss_D: 0.8945 Loss_G: 2.0732\n","[129/200][3/4] Loss_D: 0.7949 Loss_G: 2.2720\n","[129/200][4/4] Loss_D: 0.7885 Loss_G: 1.8832\n","[130/200][1/4] Loss_D: 0.8093 Loss_G: 2.3816\n","[130/200][2/4] Loss_D: 0.8258 Loss_G: 2.1546\n","[130/200][3/4] Loss_D: 0.7698 Loss_G: 2.1009\n","[130/200][4/4] Loss_D: 0.7057 Loss_G: 2.0731\n","[131/200][1/4] Loss_D: 0.6966 Loss_G: 2.0761\n","[131/200][2/4] Loss_D: 0.7452 Loss_G: 2.2182\n","[131/200][3/4] Loss_D: 0.8838 Loss_G: 1.6679\n","[131/200][4/4] Loss_D: 0.9688 Loss_G: 2.8903\n","[132/200][1/4] Loss_D: 0.8347 Loss_G: 2.1918\n","[132/200][2/4] Loss_D: 0.8532 Loss_G: 1.9770\n","[132/200][3/4] Loss_D: 0.8531 Loss_G: 1.9562\n","[132/200][4/4] Loss_D: 0.7655 Loss_G: 2.3604\n","[133/200][1/4] Loss_D: 0.7694 Loss_G: 1.6410\n","[133/200][2/4] Loss_D: 0.6934 Loss_G: 2.0977\n","[133/200][3/4] Loss_D: 0.8011 Loss_G: 2.5061\n","[133/200][4/4] Loss_D: 0.7688 Loss_G: 1.8340\n","[134/200][1/4] Loss_D: 0.7105 Loss_G: 1.9533\n","[134/200][2/4] Loss_D: 0.7868 Loss_G: 2.7264\n","[134/200][3/4] Loss_D: 0.8542 Loss_G: 1.6069\n","[134/200][4/4] Loss_D: 0.8998 Loss_G: 1.8622\n","[135/200][1/4] Loss_D: 0.8395 Loss_G: 1.9595\n","[135/200][2/4] Loss_D: 0.7470 Loss_G: 2.0840\n","[135/200][3/4] Loss_D: 0.8977 Loss_G: 1.7071\n","[135/200][4/4] Loss_D: 0.8007 Loss_G: 2.0642\n","[136/200][1/4] Loss_D: 0.7695 Loss_G: 2.2039\n","[136/200][2/4] Loss_D: 0.6504 Loss_G: 1.8029\n","[136/200][3/4] Loss_D: 0.8044 Loss_G: 1.9286\n","[136/200][4/4] Loss_D: 0.8960 Loss_G: 1.7132\n","[137/200][1/4] Loss_D: 0.9094 Loss_G: 2.1486\n","[137/200][2/4] Loss_D: 0.8651 Loss_G: 1.7860\n","[137/200][3/4] Loss_D: 0.7768 Loss_G: 2.1794\n","[137/200][4/4] Loss_D: 0.5925 Loss_G: 1.9520\n","[138/200][1/4] Loss_D: 0.7616 Loss_G: 1.8027\n","[138/200][2/4] Loss_D: 0.7337 Loss_G: 2.4161\n","[138/200][3/4] Loss_D: 0.7216 Loss_G: 2.1157\n","[138/200][4/4] Loss_D: 0.8155 Loss_G: 1.3913\n","[139/200][1/4] Loss_D: 0.9027 Loss_G: 2.8735\n","[139/200][2/4] Loss_D: 0.6393 Loss_G: 2.1680\n","[139/200][3/4] Loss_D: 0.7550 Loss_G: 1.6227\n","[139/200][4/4] Loss_D: 0.9272 Loss_G: 2.2476\n","[140/200][1/4] Loss_D: 0.8337 Loss_G: 1.8414\n","[140/200][2/4] Loss_D: 0.7466 Loss_G: 1.8581\n","[140/200][3/4] Loss_D: 0.6817 Loss_G: 2.0017\n","[140/200][4/4] Loss_D: 0.7413 Loss_G: 2.1180\n","[141/200][1/4] Loss_D: 0.6191 Loss_G: 2.0140\n","[141/200][2/4] Loss_D: 0.7271 Loss_G: 2.2758\n","[141/200][3/4] Loss_D: 0.8855 Loss_G: 1.9292\n","[141/200][4/4] Loss_D: 0.7621 Loss_G: 2.0326\n","[142/200][1/4] Loss_D: 0.7325 Loss_G: 1.9245\n","[142/200][2/4] Loss_D: 0.7325 Loss_G: 2.5867\n","[142/200][3/4] Loss_D: 0.8621 Loss_G: 1.7687\n","[142/200][4/4] Loss_D: 0.8193 Loss_G: 2.4236\n","[143/200][1/4] Loss_D: 0.6864 Loss_G: 1.9722\n","[143/200][2/4] Loss_D: 0.6771 Loss_G: 2.1495\n","[143/200][3/4] Loss_D: 0.6708 Loss_G: 2.1191\n","[143/200][4/4] Loss_D: 0.7824 Loss_G: 2.0557\n","[144/200][1/4] Loss_D: 0.7340 Loss_G: 2.2398\n","[144/200][2/4] Loss_D: 0.5983 Loss_G: 2.4277\n","[144/200][3/4] Loss_D: 0.7549 Loss_G: 1.9073\n","[144/200][4/4] Loss_D: 0.7294 Loss_G: 2.1108\n","[145/200][1/4] Loss_D: 0.7119 Loss_G: 2.2789\n","[145/200][2/4] Loss_D: 0.7597 Loss_G: 2.3588\n","[145/200][3/4] Loss_D: 0.8028 Loss_G: 1.6725\n","[145/200][4/4] Loss_D: 0.7375 Loss_G: 2.2783\n","[146/200][1/4] Loss_D: 0.6925 Loss_G: 2.2700\n","[146/200][2/4] Loss_D: 0.6932 Loss_G: 1.8762\n","[146/200][3/4] Loss_D: 0.7385 Loss_G: 1.9083\n","[146/200][4/4] Loss_D: 0.6788 Loss_G: 2.2810\n","[147/200][1/4] Loss_D: 0.6335 Loss_G: 2.2504\n","[147/200][2/4] Loss_D: 0.7623 Loss_G: 1.8328\n","[147/200][3/4] Loss_D: 0.7328 Loss_G: 2.0460\n","[147/200][4/4] Loss_D: 0.7315 Loss_G: 2.2150\n","[148/200][1/4] Loss_D: 0.7204 Loss_G: 2.4637\n","[148/200][2/4] Loss_D: 0.7334 Loss_G: 1.7946\n","[148/200][3/4] Loss_D: 0.6787 Loss_G: 2.0432\n","[148/200][4/4] Loss_D: 0.8688 Loss_G: 2.0313\n","[149/200][1/4] Loss_D: 0.7344 Loss_G: 1.9966\n","[149/200][2/4] Loss_D: 0.6811 Loss_G: 2.2739\n","[149/200][3/4] Loss_D: 0.5796 Loss_G: 2.2782\n","[149/200][4/4] Loss_D: 0.7645 Loss_G: 2.3199\n","[150/200][1/4] Loss_D: 0.6408 Loss_G: 2.1716\n","[150/200][2/4] Loss_D: 0.7140 Loss_G: 1.7779\n","[150/200][3/4] Loss_D: 0.6646 Loss_G: 2.0731\n","[150/200][4/4] Loss_D: 0.6293 Loss_G: 2.3079\n","[151/200][1/4] Loss_D: 0.6841 Loss_G: 2.0947\n","[151/200][2/4] Loss_D: 0.6488 Loss_G: 2.2568\n","[151/200][3/4] Loss_D: 0.7885 Loss_G: 1.9726\n","[151/200][4/4] Loss_D: 0.6763 Loss_G: 2.0971\n","[152/200][1/4] Loss_D: 0.7641 Loss_G: 1.9799\n","[152/200][2/4] Loss_D: 0.6574 Loss_G: 2.0781\n","[152/200][3/4] Loss_D: 0.6569 Loss_G: 2.3896\n","[152/200][4/4] Loss_D: 0.6465 Loss_G: 2.1887\n","[153/200][1/4] Loss_D: 0.6622 Loss_G: 2.4341\n","[153/200][2/4] Loss_D: 0.6841 Loss_G: 1.6000\n","[153/200][3/4] Loss_D: 0.9516 Loss_G: 2.8508\n","[153/200][4/4] Loss_D: 0.7632 Loss_G: 2.1154\n","[154/200][1/4] Loss_D: 0.7351 Loss_G: 1.8649\n","[154/200][2/4] Loss_D: 0.5085 Loss_G: 2.2822\n","[154/200][3/4] Loss_D: 0.7029 Loss_G: 2.6601\n","[154/200][4/4] Loss_D: 0.7223 Loss_G: 2.1861\n","[155/200][1/4] Loss_D: 0.7235 Loss_G: 2.6363\n","[155/200][2/4] Loss_D: 0.6620 Loss_G: 1.9973\n","[155/200][3/4] Loss_D: 0.7077 Loss_G: 2.4890\n","[155/200][4/4] Loss_D: 0.7513 Loss_G: 2.4040\n","[156/200][1/4] Loss_D: 0.6493 Loss_G: 2.0809\n","[156/200][2/4] Loss_D: 0.6544 Loss_G: 2.2508\n","[156/200][3/4] Loss_D: 0.6383 Loss_G: 2.4968\n","[156/200][4/4] Loss_D: 0.6667 Loss_G: 2.2432\n","[157/200][1/4] Loss_D: 0.6292 Loss_G: 2.6177\n","[157/200][2/4] Loss_D: 0.6494 Loss_G: 2.0556\n","[157/200][3/4] Loss_D: 0.7566 Loss_G: 2.1910\n","[157/200][4/4] Loss_D: 0.7277 Loss_G: 2.2653\n","[158/200][1/4] Loss_D: 0.6508 Loss_G: 2.6172\n","[158/200][2/4] Loss_D: 0.6750 Loss_G: 1.9306\n","[158/200][3/4] Loss_D: 0.5991 Loss_G: 2.7254\n","[158/200][4/4] Loss_D: 0.6644 Loss_G: 1.8329\n","[159/200][1/4] Loss_D: 0.6784 Loss_G: 2.7904\n","[159/200][2/4] Loss_D: 0.6649 Loss_G: 2.4424\n","[159/200][3/4] Loss_D: 0.6319 Loss_G: 2.0969\n","[159/200][4/4] Loss_D: 0.6471 Loss_G: 2.3592\n","[160/200][1/4] Loss_D: 0.7054 Loss_G: 2.2439\n","[160/200][2/4] Loss_D: 0.6033 Loss_G: 2.3129\n","[160/200][3/4] Loss_D: 0.6113 Loss_G: 2.2852\n","[160/200][4/4] Loss_D: 0.6282 Loss_G: 2.6544\n","[161/200][1/4] Loss_D: 0.6492 Loss_G: 2.0041\n","[161/200][2/4] Loss_D: 0.5675 Loss_G: 2.3735\n","[161/200][3/4] Loss_D: 0.5670 Loss_G: 2.2452\n","[161/200][4/4] Loss_D: 0.6119 Loss_G: 2.0711\n","[162/200][1/4] Loss_D: 0.6364 Loss_G: 2.8424\n","[162/200][2/4] Loss_D: 0.5850 Loss_G: 2.3609\n","[162/200][3/4] Loss_D: 0.6589 Loss_G: 1.8046\n","[162/200][4/4] Loss_D: 0.6973 Loss_G: 2.8598\n","[163/200][1/4] Loss_D: 0.5546 Loss_G: 2.4196\n","[163/200][2/4] Loss_D: 0.7420 Loss_G: 1.5281\n","[163/200][3/4] Loss_D: 0.8012 Loss_G: 2.6975\n","[163/200][4/4] Loss_D: 0.6785 Loss_G: 1.9352\n","[164/200][1/4] Loss_D: 0.6654 Loss_G: 2.9022\n","[164/200][2/4] Loss_D: 0.6998 Loss_G: 1.6909\n","[164/200][3/4] Loss_D: 0.7624 Loss_G: 1.9087\n","[164/200][4/4] Loss_D: 0.6402 Loss_G: 2.5649\n","[165/200][1/4] Loss_D: 0.4408 Loss_G: 2.7219\n","[165/200][2/4] Loss_D: 0.6193 Loss_G: 2.0888\n","[165/200][3/4] Loss_D: 0.4695 Loss_G: 2.2672\n","[165/200][4/4] Loss_D: 0.7030 Loss_G: 2.3070\n","[166/200][1/4] Loss_D: 0.4455 Loss_G: 2.8404\n","[166/200][2/4] Loss_D: 0.6357 Loss_G: 2.1269\n","[166/200][3/4] Loss_D: 0.6980 Loss_G: 2.7061\n","[166/200][4/4] Loss_D: 0.7104 Loss_G: 2.2328\n","[167/200][1/4] Loss_D: 0.6610 Loss_G: 2.5840\n","[167/200][2/4] Loss_D: 0.5999 Loss_G: 2.1993\n","[167/200][3/4] Loss_D: 0.6546 Loss_G: 2.6385\n","[167/200][4/4] Loss_D: 0.5238 Loss_G: 2.3690\n","[168/200][1/4] Loss_D: 0.5757 Loss_G: 2.2774\n","[168/200][2/4] Loss_D: 0.5856 Loss_G: 2.1335\n","[168/200][3/4] Loss_D: 0.6647 Loss_G: 2.0058\n","[168/200][4/4] Loss_D: 0.5657 Loss_G: 2.6567\n","[169/200][1/4] Loss_D: 0.4744 Loss_G: 2.5124\n","[169/200][2/4] Loss_D: 0.7179 Loss_G: 1.9694\n","[169/200][3/4] Loss_D: 0.6246 Loss_G: 2.9862\n","[169/200][4/4] Loss_D: 0.7933 Loss_G: 1.6797\n","[170/200][1/4] Loss_D: 0.8445 Loss_G: 3.4020\n","[170/200][2/4] Loss_D: 0.6466 Loss_G: 2.4365\n","[170/200][3/4] Loss_D: 0.5466 Loss_G: 1.9046\n","[170/200][4/4] Loss_D: 0.6510 Loss_G: 2.4739\n","[171/200][1/4] Loss_D: 0.6697 Loss_G: 2.5464\n","[171/200][2/4] Loss_D: 0.6660 Loss_G: 1.9906\n","[171/200][3/4] Loss_D: 0.6705 Loss_G: 2.0611\n","[171/200][4/4] Loss_D: 0.6004 Loss_G: 3.3712\n","[172/200][1/4] Loss_D: 0.6342 Loss_G: 2.1709\n","[172/200][2/4] Loss_D: 0.4504 Loss_G: 2.1910\n","[172/200][3/4] Loss_D: 0.6241 Loss_G: 2.7106\n","[172/200][4/4] Loss_D: 0.5756 Loss_G: 2.1847\n","[173/200][1/4] Loss_D: 0.5018 Loss_G: 2.3880\n","[173/200][2/4] Loss_D: 0.4844 Loss_G: 2.5809\n","[173/200][3/4] Loss_D: 0.6730 Loss_G: 2.0950\n","[173/200][4/4] Loss_D: 0.6786 Loss_G: 3.3523\n","[174/200][1/4] Loss_D: 0.6222 Loss_G: 1.9961\n","[174/200][2/4] Loss_D: 0.6734 Loss_G: 3.0019\n","[174/200][3/4] Loss_D: 0.6778 Loss_G: 2.2429\n","[174/200][4/4] Loss_D: 0.6837 Loss_G: 2.6751\n","[175/200][1/4] Loss_D: 0.5561 Loss_G: 3.1583\n","[175/200][2/4] Loss_D: 0.5789 Loss_G: 2.3071\n","[175/200][3/4] Loss_D: 0.5694 Loss_G: 2.0972\n","[175/200][4/4] Loss_D: 0.6278 Loss_G: 3.2403\n","[176/200][1/4] Loss_D: 0.5008 Loss_G: 2.5319\n","[176/200][2/4] Loss_D: 0.6288 Loss_G: 1.7902\n","[176/200][3/4] Loss_D: 0.7513 Loss_G: 3.2697\n","[176/200][4/4] Loss_D: 0.8742 Loss_G: 1.6416\n","[177/200][1/4] Loss_D: 0.7216 Loss_G: 3.2723\n","[177/200][2/4] Loss_D: 0.5990 Loss_G: 2.7928\n","[177/200][3/4] Loss_D: 0.6090 Loss_G: 2.0004\n","[177/200][4/4] Loss_D: 0.4971 Loss_G: 2.6207\n","[178/200][1/4] Loss_D: 0.4770 Loss_G: 2.6423\n","[178/200][2/4] Loss_D: 0.5081 Loss_G: 2.6127\n","[178/200][3/4] Loss_D: 0.5473 Loss_G: 2.0709\n","[178/200][4/4] Loss_D: 0.6449 Loss_G: 2.4850\n","[179/200][1/4] Loss_D: 0.5003 Loss_G: 2.9831\n","[179/200][2/4] Loss_D: 0.5972 Loss_G: 2.1851\n","[179/200][3/4] Loss_D: 0.5144 Loss_G: 2.2176\n","[179/200][4/4] Loss_D: 0.6479 Loss_G: 3.9927\n","[180/200][1/4] Loss_D: 0.7051 Loss_G: 2.1603\n","[180/200][2/4] Loss_D: 0.5472 Loss_G: 2.3206\n","[180/200][3/4] Loss_D: 0.5738 Loss_G: 2.5522\n","[180/200][4/4] Loss_D: 0.6573 Loss_G: 3.0542\n","[181/200][1/4] Loss_D: 0.4361 Loss_G: 2.7632\n","[181/200][2/4] Loss_D: 0.5668 Loss_G: 2.2048\n","[181/200][3/4] Loss_D: 0.7046 Loss_G: 2.4201\n","[181/200][4/4] Loss_D: 0.6967 Loss_G: 2.3145\n","[182/200][1/4] Loss_D: 0.4888 Loss_G: 2.7955\n","[182/200][2/4] Loss_D: 0.4557 Loss_G: 2.4170\n","[182/200][3/4] Loss_D: 0.5075 Loss_G: 2.3223\n","[182/200][4/4] Loss_D: 0.6226 Loss_G: 2.2801\n","[183/200][1/4] Loss_D: 0.4948 Loss_G: 2.3326\n","[183/200][2/4] Loss_D: 0.5307 Loss_G: 2.7280\n","[183/200][3/4] Loss_D: 0.5753 Loss_G: 1.9085\n","[183/200][4/4] Loss_D: 0.5284 Loss_G: 2.5125\n","[184/200][1/4] Loss_D: 0.4847 Loss_G: 2.9886\n","[184/200][2/4] Loss_D: 0.5332 Loss_G: 2.3061\n","[184/200][3/4] Loss_D: 0.6111 Loss_G: 1.5894\n","[184/200][4/4] Loss_D: 0.6366 Loss_G: 3.5551\n","[185/200][1/4] Loss_D: 0.4867 Loss_G: 2.7589\n","[185/200][2/4] Loss_D: 0.5224 Loss_G: 1.8870\n","[185/200][3/4] Loss_D: 0.5996 Loss_G: 3.2187\n","[185/200][4/4] Loss_D: 0.5726 Loss_G: 2.4649\n","[186/200][1/4] Loss_D: 0.4830 Loss_G: 2.4291\n","[186/200][2/4] Loss_D: 0.5603 Loss_G: 3.0205\n","[186/200][3/4] Loss_D: 0.6102 Loss_G: 1.7787\n","[186/200][4/4] Loss_D: 0.7118 Loss_G: 3.0403\n","[187/200][1/4] Loss_D: 0.5274 Loss_G: 2.7744\n","[187/200][2/4] Loss_D: 0.4122 Loss_G: 2.2400\n","[187/200][3/4] Loss_D: 0.5639 Loss_G: 2.4160\n","[187/200][4/4] Loss_D: 0.5722 Loss_G: 2.8935\n","[188/200][1/4] Loss_D: 0.6037 Loss_G: 2.2113\n","[188/200][2/4] Loss_D: 0.5357 Loss_G: 2.5974\n","[188/200][3/4] Loss_D: 0.4515 Loss_G: 2.9483\n","[188/200][4/4] Loss_D: 0.4492 Loss_G: 2.3722\n","[189/200][1/4] Loss_D: 0.4833 Loss_G: 2.9528\n","[189/200][2/4] Loss_D: 0.5610 Loss_G: 2.2085\n","[189/200][3/4] Loss_D: 0.4804 Loss_G: 2.1719\n","[189/200][4/4] Loss_D: 0.5402 Loss_G: 2.8128\n","[190/200][1/4] Loss_D: 0.4379 Loss_G: 2.7484\n","[190/200][2/4] Loss_D: 0.5106 Loss_G: 2.3195\n","[190/200][3/4] Loss_D: 0.4946 Loss_G: 2.5831\n","[190/200][4/4] Loss_D: 0.5291 Loss_G: 2.2304\n","[191/200][1/4] Loss_D: 0.4678 Loss_G: 2.7314\n","[191/200][2/4] Loss_D: 0.5296 Loss_G: 2.4955\n","[191/200][3/4] Loss_D: 0.4509 Loss_G: 2.3383\n","[191/200][4/4] Loss_D: 0.4975 Loss_G: 2.6052\n","[192/200][1/4] Loss_D: 0.4964 Loss_G: 3.1273\n","[192/200][2/4] Loss_D: 0.5805 Loss_G: 1.8375\n","[192/200][3/4] Loss_D: 0.6337 Loss_G: 2.9659\n","[192/200][4/4] Loss_D: 0.4503 Loss_G: 2.5331\n","[193/200][1/4] Loss_D: 0.5229 Loss_G: 2.1986\n","[193/200][2/4] Loss_D: 0.4872 Loss_G: 2.6057\n","[193/200][3/4] Loss_D: 0.4268 Loss_G: 2.8269\n","[193/200][4/4] Loss_D: 0.5909 Loss_G: 1.8067\n","[194/200][1/4] Loss_D: 0.5314 Loss_G: 2.9497\n","[194/200][2/4] Loss_D: 0.4238 Loss_G: 2.8405\n","[194/200][3/4] Loss_D: 0.5494 Loss_G: 2.0820\n","[194/200][4/4] Loss_D: 0.5029 Loss_G: 2.2402\n","[195/200][1/4] Loss_D: 0.6242 Loss_G: 2.9199\n","[195/200][2/4] Loss_D: 0.4447 Loss_G: 2.6060\n","[195/200][3/4] Loss_D: 0.4664 Loss_G: 2.2366\n","[195/200][4/4] Loss_D: 0.5211 Loss_G: 2.5382\n","[196/200][1/4] Loss_D: 0.4639 Loss_G: 3.2288\n","[196/200][2/4] Loss_D: 0.4781 Loss_G: 2.0409\n","[196/200][3/4] Loss_D: 0.5523 Loss_G: 2.7885\n","[196/200][4/4] Loss_D: 0.5337 Loss_G: 2.6418\n","[197/200][1/4] Loss_D: 0.4962 Loss_G: 2.0674\n","[197/200][2/4] Loss_D: 0.4332 Loss_G: 2.9953\n","[197/200][3/4] Loss_D: 0.4526 Loss_G: 2.3800\n","[197/200][4/4] Loss_D: 0.4490 Loss_G: 2.3368\n","[198/200][1/4] Loss_D: 0.4245 Loss_G: 2.7402\n","[198/200][2/4] Loss_D: 0.4815 Loss_G: 2.6580\n","[198/200][3/4] Loss_D: 0.4873 Loss_G: 2.4296\n","[198/200][4/4] Loss_D: 0.5296 Loss_G: 2.5567\n","[199/200][1/4] Loss_D: 0.4456 Loss_G: 2.7071\n","[199/200][2/4] Loss_D: 0.4909 Loss_G: 2.7531\n","[199/200][3/4] Loss_D: 0.4808 Loss_G: 2.3824\n","[199/200][4/4] Loss_D: 0.4390 Loss_G: 2.4598\n","[200/200][1/4] Loss_D: 0.4747 Loss_G: 2.8522\n","[200/200][2/4] Loss_D: 0.4222 Loss_G: 3.0646\n","[200/200][3/4] Loss_D: 0.4323 Loss_G: 2.5056\n","[200/200][4/4] Loss_D: 0.5063 Loss_G: 2.2959\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Generar gráfica del loss del generador y del discriminador\n","epochs = range(1, 201)  # Número total de epochs\n","plt.plot(epochs, loss_G_values[0:400:2], label='Generator Loss')\n","plt.plot(epochs, loss_D_values[0:400:2], label='Discriminator Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Guardar la gráfica como un archivo .png\n","plt.savefig('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/loss_graph.png')\n","\n","# Mostrar la gráfica en pantalla\n","plt.show()"],"metadata":{"id":"j9xK7HzbhNtH","executionInfo":{"status":"aborted","timestamp":1688408293465,"user_tz":-120,"elapsed":6,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Guardamos el modelo en un archivo .pth\n","gen_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/generator.pth'\n","dis_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/discriminator.pth'\n","\n","torch.save(netG.state_dict(), gen_path)\n","torch.save(netD.state_dict(), dis_path)\n","\n","# Función para generar una imagen aleatoria y guardarla en un archivo .jpg\n","def generar_imagen_aleatoria(generator_path, output_path):\n","    # Cargamos los pesos del generador desde el archivo .pth\n","    generator = G()\n","    generator.load_state_dict(torch.load(generator_path))\n","    generator.eval()\n","\n","    # Generamos una imagen aleatoria\n","    with torch.no_grad():\n","        noise = torch.randn(1, 100, 1, 1)\n","        imagen_generada = generator(noise)\n","\n","    # Guardamos la imagen generada en un archivo .jpg\n","    vutils.save_image(imagen_generada, output_path, normalize=True)"],"metadata":{"id":"5pWH3V48K2Cd","executionInfo":{"status":"aborted","timestamp":1688408293466,"user_tz":-120,"elapsed":7,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generamos 100 imágenes y las almacenamos\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/fotos_generadas')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","gen_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/generator.pth'\n","for i in range(100):\n","  generar_imagen_aleatoria(gen_path, f\"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/fotos_generadas/output_{i}.jpg\")"],"metadata":{"id":"TiMj2z3nLpQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","generator_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3_1/models/generator.pth'\n","\n","\n","# Seteamos algunos hiperparametros que necesitaremos\n","nz = 100 #tamaño de input del generador\n","ngf = 128 #tamaño de input del generador\n","nc = 1 #numero de canales (1 porque trabajamos en escala de grises)\n","\n","class gan_gen(nn.Module):\n","\n","    def __init__(self):\n","        super(gan_gen, self).__init__()\n","        self.main = nn.Sequential(\n","            # La entrada será de tamaño nz, en este caso 100 y pasamos por una\n","            # capa de convolución transpuesta con salida ngf*16=2048\n","            nn.ConvTranspose2d(     nz, ngf * 16, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 16),\n","            nn.ReLU(True),\n","            # Pasamos por varias capas de convolucón transpuesta, reduciendo así\n","            # el tamaño. ngf = 128\n","            # (ngf*16) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # (ngf*8) x 8 x 8\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # (ngf*4) x 16 x 16\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # (ngf*2) x 32 x 32\n","            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # (ngf) x 64 x 64\n","            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # (nc) x 128 x 128\n","            # La salida será 1x128x128\n","        )\n","\n","\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","#Cargamos los pesos del generador del modelo:\n","state_dict = torch.load(generator_path, map_location=torch.device('cpu'))\n","\n","# Obtener el estado del diccionario actual del generador\n","current_state_dict = gan_gen.state_dict()\n","\n","# Filtrar las claves del estado del diccionario cargado que existen en el estado del diccionario actual\n","filtered_state_dict = {key: value for key, value in state_dict.items() if key in current_state_dict}\n","\n","# Cargar el estado del diccionario filtrado en el generador\n","gan_gen.load_state_dict(filtered_state_dict, strict=False)\n","\n","\n","#gan_gen.load_state_dict(torch.load(generator_path, map_location=torch.device('cpu')))\n","gan_gen.eval()\n","\n","# Generamos una imagen aleatoria\n","with torch.no_grad():\n","    noise = torch.randn(1, 100, 1, 1)\n","    generated_img = gan_gen(noise)\n","\n","# Convertir el tensor de imagen a un rango de 0 a 255\n","generated_img = (generated_img * 255).clamp(0, 255).byte()\n","\n","# Asegurar que la forma del tensor sea adecuada\n","generated_img = generated_img.squeeze(0)  # Eliminar dimensión adicional (1, H, W) -> (H, W)\n","\n","# Convertir el tensor de imagen a un arreglo NumPy y ajustar el tipo de datos\n","generated_img_np = generated_img.squeeze().cpu().numpy().astype(np.uint8)\n","\n","# Crear una imagen PIL a partir del arreglo NumPy\n","generated_img_pil = Image.fromarray(generated_img_np)\n","\n","# Guardar la imagen generada en una lista\n","generated_images = []\n","generated_images.append(generated_img_pil)\n","\n","# Guardar las imágenes generadas en el directorio de descarga\n","generated_image_paths = []\n","\n","download_dir = 'downloads/'\n","os.makedirs(download_dir, exist_ok=True)\n","\n","for i, image in enumerate(generated_images):\n","    generated_image_path = os.path.join(download_dir, f'generated_image_{i}.jpg')\n","    image.save(generated_image_path)\n","    generated_image_paths.append(generated_image_path)"],"metadata":{"id":"kUBHM0ybptXY","executionInfo":{"status":"ok","timestamp":1688487422878,"user_tz":-120,"elapsed":989,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XLq3LC9ctHtE"},"execution_count":null,"outputs":[]}]}
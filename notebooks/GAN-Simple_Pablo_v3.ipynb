{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17toTO61P35IYYRAqWvrdVkCA6UMr2b8t","timestamp":1687110368398}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://github.com/AdityaVashista30/Image-generation-using-GANS-using-PyTorch-and-Cifar-10\n","\n","https://github.com/soumith/dcgan.torch/issues/2#issuecomment-164862299"],"metadata":{"id":"V5X4GmauqYh_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JynSOzTXtQsj"},"outputs":[],"source":["#torch cuda\n","import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Edis4UlrO3j5","executionInfo":{"status":"ok","timestamp":1688403230650,"user_tz":-120,"elapsed":14497,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"e48011a4-9eea-4e92-86a7-a9957dda8922"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# Importing the libraries\n","import os\n","import numpy as np\n","from PIL import Image\n","import cv2\n","import numpy as np\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","from torch.autograd import Variable\n","import errno\n","\n","# Seteamos algunos hiperparametros que necesitaremos\n","batchSize = 128 #tamaño del batch\n","imageSize = 128 #tamaño de imagen\n","nz = 100 #tamaño de input del generador\n","ngf = 128 #tamaño de input del generador\n","ndf = int(ngf/4) #tamaño de input del discriminador\n","nc = 1 #numero de canales (1 porque trabajamos en escala de grises)\n","\n","\n","#Definimos una clase para cargar el dataset\n","class CustomDataset(data.Dataset):\n","    def __init__(self, X_folder, y_folder, transform=None):\n","        self.X_folder = X_folder\n","        self.y_folder = y_folder\n","        self.transform = transform\n","\n","        # Obtener la lista de nombres de archivo en las carpetas\n","        self.X_filenames = [filename for filename in os.listdir(X_folder) if filename.endswith('.jpg')]\n","        self.y_filenames = [filename for filename in os.listdir(y_folder) if filename.endswith('.jpg')]\n","\n","    def __len__(self):\n","        return len(self.X_filenames)\n","\n","    def __getitem__(self, index):\n","        # Obtener el nombre de archivo correspondiente a la posición del índice\n","        X_filename = self.X_filenames[index]\n","        y_filename = self.y_filenames[index]\n","\n","        # Verificar si el archivo tiene la extensión \".jpg\"\n","        if not X_filename.endswith(\".jpg\"):\n","            return self.__getitem__((index + 1) % len(self))\n","\n","        # Cargar las imágenes y las etiquetas\n","        X = Image.open(os.path.join(self.X_folder, X_filename)).convert(\"RGB\")\n","        y = Image.open(os.path.join(self.y_folder, y_filename)).convert(\"RGB\")\n","\n","        if self.transform:\n","            X = self.transform(X)\n","            y = self.transform(y)\n","\n","        return X, y\n","\n","    def get_images(self):\n","        images = []\n","        for X_filename in self.X_filenames:\n","            X = Image.open(os.path.join(self.X_folder, X_filename))\n","            if self.transform:\n","                X = self.transform(X)\n","            images.append(X)\n","        return images\n","\n","    def get_labels(self):\n","            labels = []\n","            for y_filename in self.y_filenames:\n","                y = Image.open(os.path.join(self.y_folder, y_filename))\n","                if self.transform:\n","                    y = self.transform(y)\n","                labels.append(y)\n","            return labels\n","\n","\n","# Definimos las rutas de las carpetas de entrenamiento y prueba\n","trainX_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/traindata/traindata/'\n","trainy_folder = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/CRACK500/valdata/valdata/'\n","\n","# Creamos las transformaciones\n","transform = transforms.Compose([\n","    transforms.Resize((imageSize,imageSize)), #Ajuste de resolución\n","    transforms.Grayscale(), #Pasamos a escala de grises\n","    transforms.ToTensor(), #Convertimos en tensor\n","    transforms.Normalize((0.5), (0.5)),\n","])\n","\n","# Creamos el dataset personalizado de entrenamiento\n","dataset_full = CustomDataset(trainX_folder, trainy_folder, transform=transform)\n","dataset = dataset_full.get_images()\n","\n","# Creamos el dataloader\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2)\n","\n","# Definimos una función para inicializar los pesos tomando como entrada una red neuronal\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","# Creamos la clase que define el generador\n","class G(nn.Module):\n","\n","    def __init__(self):\n","        super(G, self).__init__()\n","        self.main = nn.Sequential(\n","            # La entrada será de tamaño nz, en este caso 100 y pasamos por una\n","            # capa de convolución transpuesta con salida ngf*16=2048\n","            nn.ConvTranspose2d(     nz, ngf * 16, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 16),\n","            nn.ReLU(True),\n","            # Pasamos por varias capas de convolucón transpuesta, reduciendo así\n","            # el tamaño. ngf = 128\n","            # (ngf*16) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # (ngf*8) x 8 x 8\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # (ngf*4) x 16 x 16\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # (ngf*2) x 32 x 32\n","            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # (ngf) x 64 x 64\n","            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # (nc) x 128 x 128\n","            # La salida será 1x128x128\n","        )\n","\n","\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Definimos la clase del discriminador\n","class D(nn.Module):\n","    def __init__(self):\n","        super(D, self).__init__()\n","        self.main = nn.Sequential(\n","            # La entrada será (nc) x 128 x 128\n","            nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf) x 64 x 64\n","            nn.Conv2d(ndf, ndf * 2, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*2) x 32 x 32\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*4) x 16 x 16\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*8) x 8 x 8\n","            nn.Conv2d(ndf * 8, ndf * 16, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ndf * 16),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # (ndf*16) x 4 x 4\n","            nn.Conv2d(ndf * 16, 1, 4, stride=1, padding=0, bias=False),\n","            nn.Sigmoid()\n","            # 1\n","        )\n","\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output.view(-1)\n","\n","\n","# Creamos el discriminador y lo pasamos a la GPU\n","netD = D().to(device)\n","netD.apply(weights_init)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKZoV58kwKKA","executionInfo":{"status":"ok","timestamp":1688403296846,"user_tz":-120,"elapsed":66199,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"12e3201a-2b0c-413b-dce7-9782ae2f329c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["D(\n","  (main): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n","    (15): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!pip3 install torchview\n","!pip3 install graphviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mV_lKkJwYKG","executionInfo":{"status":"ok","timestamp":1688404608541,"user_tz":-120,"elapsed":8924,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"5280dad1-7fb4-47c8-cd3b-8b7bdde75cc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchview\n","  Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n","Installing collected packages: torchview\n","Successfully installed torchview-0.2.6\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"]}]},{"cell_type":"code","source":["from torchview import draw_graph\n","from torchvision.transforms import ToPILImage\n","import graphviz\n","\n","\n","model_gen = G()\n","model_dis = D()\n","\n","# Obtén el gráfico del modelo\n","model_graph_gen = draw_graph(model_gen, input_size=(1, 100, 1, 1), device='meta')\n","visual_graph_gen = model_graph_gen.visual_graph\n","\n","# Ajusta los estilos del grafo generador\n","visual_graph_gen.attr('node', shape='plain', style='filled', color='white')\n","visual_graph_gen.attr('graph', bgcolor='transparent')\n","#visual_graph_gen.attr(size='10,10!', margin='0.1')\n","\n","# Guarda el gráfico en formato DOT\n","dot_path_gen = \"modelo_gan_gen.dot\"\n","visual_graph_gen.save(dot_path_gen)\n","\n","# Convierte el archivo DOT a una imagen PNG usando Graphviz\n","output_path_gen = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/NN_Structure/modelo_gan_gen\"\n","graph_gen = graphviz.Source.from_file(dot_path_gen)\n","graph_gen.render(output_path_gen, format='pdf')\n","\n","# Obtén el gráfico del modelo\n","model_graph_dis = draw_graph(model_dis, input_size=(128, 1, 128, 128), device='meta')\n","visual_graph_dis = model_graph_dis.visual_graph\n","\n","# Ajusta los estilos del grafo discriminador\n","visual_graph_dis.attr('node', shape='plain', style='filled', color='white')\n","visual_graph_dis.attr('graph', bgcolor='transparent')\n","\n","# Guarda el gráfico en formato DOT\n","dot_path_dis = \"modelo_gan_dis.dot\"\n","visual_graph_dis.save(dot_path_dis)\n","\n","# Convierte el archivo DOT a una imagen PNG usando Graphviz\n","output_path_dis = \"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/NN_Structure/modelo_gan_dis\"\n","graph_dis = graphviz.Source.from_file(dot_path_dis)\n","graph_dis.render(output_path_dis, format='pdf')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"lcieqKRuwcTo","executionInfo":{"status":"ok","timestamp":1688404618358,"user_tz":-120,"elapsed":1575,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}},"outputId":"40e61e56-2b5a-49f2-99ef-34cc1bb1ee6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/NN_Structure/modelo_gan_dis.pdf'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Comenzamos el entranamiento del GAN\n","criterion = nn.BCELoss()\n","optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n","\n","#Generamos carpetas para almacenar las imágenes creadas\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/Images')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/Images/fake_samples')\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","\n","\n","for epoch in range(200):\n","    for i, data in enumerate(dataloader, 0): # iteramos sobre las imágenes del dataset\n","        # 1er paso: actualizamos los pesos de la red neuronal del discriminador\n","        netD.zero_grad()\n","        real = data.to(device) # Imagen real del dataset\n","        input = Variable(real).to(device) # la almacenamos en una variable\n","        target = torch.tensor(torch.ones(input.size()[0])).to(device) # Creamos el target\n","        output = netD(input)\n","        errD_real = criterion(output, target)\n","        # Entrenamos el discrimnador con una imagen false generada por el generador a partir de ruido\n","        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device)\n","        fake = netG(noise)\n","        target = Variable(torch.zeros(input.size()[0])).to(device)\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, target)\n","\n","        # Propagación hacia atrás de los errores del discriminador\n","        errD = errD_real + errD_fake\n","        errD.backward()\n","        optimizerD.step()\n","\n","        # 2º paso: actualizamos los pesos de la red neuronal del generador\n","\n","        netG.zero_grad()\n","        target = Variable(torch.ones(input.size()[0])).to(device)\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","\n","        # 3er paso: Sacamos por pantalla las pérdidas y alamacenamos un ejemplo de imagen real y las imagenes generadas del minibatch cada 100 pasos\n","\n","        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch+1, 200, i+1, len(dataloader), errD.data, errG.data))\n","        if i % 100 == 0: # Cada 100 pasos:\n","            vutils.save_image(real.cpu(), '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/Images/real_samples.png', normalize = True) # We save the real images of the minibatch.\n","            fake = netG(noise)\n","            vutils.save_image(fake.detach().cpu(), f'/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/Images/fake_samples/fake_samples_epoch_{epoch:03d}.png', normalize=True) # We also save the fake generated images of the minibatch."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85woEKOdkQPx","outputId":"f9069f5b-4724-453d-ffaa-ea6e398644c5","executionInfo":{"status":"ok","timestamp":1688404231519,"user_tz":-120,"elapsed":934693,"user":{"displayName":"Pablo Bolívar","userId":"01242547030775017581"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-c19b5941a3e7>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target = torch.tensor(torch.ones(input.size()[0])).to(device) # Creamos el target\n"]},{"output_type":"stream","name":"stdout","text":["[1/200][1/2] Loss_D: 1.6916 Loss_G: 4.0773\n","[1/200][2/2] Loss_D: 7.8790 Loss_G: 1.2015\n","[2/200][1/2] Loss_D: 7.8252 Loss_G: 2.4569\n","[2/200][2/2] Loss_D: 7.0933 Loss_G: 4.3632\n","[3/200][1/2] Loss_D: 6.5516 Loss_G: 5.3046\n","[3/200][2/2] Loss_D: 7.2906 Loss_G: 5.2604\n","[4/200][1/2] Loss_D: 6.5142 Loss_G: 6.7785\n","[4/200][2/2] Loss_D: 5.9808 Loss_G: 8.0357\n","[5/200][1/2] Loss_D: 5.4359 Loss_G: 8.9804\n","[5/200][2/2] Loss_D: 5.4875 Loss_G: 9.9083\n","[6/200][1/2] Loss_D: 4.9891 Loss_G: 10.4767\n","[6/200][2/2] Loss_D: 5.5457 Loss_G: 10.6964\n","[7/200][1/2] Loss_D: 5.1520 Loss_G: 11.3048\n","[7/200][2/2] Loss_D: 4.6005 Loss_G: 12.1376\n","[8/200][1/2] Loss_D: 3.9155 Loss_G: 12.3562\n","[8/200][2/2] Loss_D: 3.2920 Loss_G: 12.2050\n","[9/200][1/2] Loss_D: 3.7246 Loss_G: 12.9953\n","[9/200][2/2] Loss_D: 2.7084 Loss_G: 11.5665\n","[10/200][1/2] Loss_D: 3.9000 Loss_G: 12.5281\n","[10/200][2/2] Loss_D: 2.3049 Loss_G: 10.1807\n","[11/200][1/2] Loss_D: 4.5104 Loss_G: 12.3111\n","[11/200][2/2] Loss_D: 2.1828 Loss_G: 10.4576\n","[12/200][1/2] Loss_D: 3.5682 Loss_G: 12.4491\n","[12/200][2/2] Loss_D: 2.1938 Loss_G: 11.0119\n","[13/200][1/2] Loss_D: 2.9641 Loss_G: 13.1472\n","[13/200][2/2] Loss_D: 1.9300 Loss_G: 9.8418\n","[14/200][1/2] Loss_D: 4.3422 Loss_G: 11.9375\n","[14/200][2/2] Loss_D: 1.8443 Loss_G: 9.8754\n","[15/200][1/2] Loss_D: 2.5762 Loss_G: 10.7848\n","[15/200][2/2] Loss_D: 1.9541 Loss_G: 8.6105\n","[16/200][1/2] Loss_D: 3.5144 Loss_G: 11.0512\n","[16/200][2/2] Loss_D: 1.9752 Loss_G: 8.3528\n","[17/200][1/2] Loss_D: 3.3704 Loss_G: 9.6632\n","[17/200][2/2] Loss_D: 1.9202 Loss_G: 9.6239\n","[18/200][1/2] Loss_D: 2.1041 Loss_G: 9.2688\n","[18/200][2/2] Loss_D: 1.8473 Loss_G: 8.4224\n","[19/200][1/2] Loss_D: 2.0989 Loss_G: 9.5224\n","[19/200][2/2] Loss_D: 1.4809 Loss_G: 8.1944\n","[20/200][1/2] Loss_D: 2.0466 Loss_G: 8.7068\n","[20/200][2/2] Loss_D: 1.5058 Loss_G: 7.5027\n","[21/200][1/2] Loss_D: 1.5872 Loss_G: 7.9589\n","[21/200][2/2] Loss_D: 1.6202 Loss_G: 8.4580\n","[22/200][1/2] Loss_D: 1.6757 Loss_G: 9.0907\n","[22/200][2/2] Loss_D: 1.5526 Loss_G: 7.5095\n","[23/200][1/2] Loss_D: 1.5424 Loss_G: 7.5812\n","[23/200][2/2] Loss_D: 1.6126 Loss_G: 6.8036\n","[24/200][1/2] Loss_D: 2.4871 Loss_G: 10.1025\n","[24/200][2/2] Loss_D: 1.2544 Loss_G: 7.3037\n","[25/200][1/2] Loss_D: 2.4481 Loss_G: 9.5624\n","[25/200][2/2] Loss_D: 1.5590 Loss_G: 7.5057\n","[26/200][1/2] Loss_D: 2.7709 Loss_G: 9.8920\n","[26/200][2/2] Loss_D: 1.1662 Loss_G: 7.1033\n","[27/200][1/2] Loss_D: 2.1331 Loss_G: 7.8889\n","[27/200][2/2] Loss_D: 1.7907 Loss_G: 7.7866\n","[28/200][1/2] Loss_D: 1.7149 Loss_G: 7.4815\n","[28/200][2/2] Loss_D: 1.9001 Loss_G: 6.3906\n","[29/200][1/2] Loss_D: 1.5182 Loss_G: 5.6237\n","[29/200][2/2] Loss_D: 1.5889 Loss_G: 4.9423\n","[30/200][1/2] Loss_D: 2.1256 Loss_G: 5.4657\n","[30/200][2/2] Loss_D: 2.0578 Loss_G: 6.0134\n","[31/200][1/2] Loss_D: 1.7200 Loss_G: 4.0083\n","[31/200][2/2] Loss_D: 2.3229 Loss_G: 3.6658\n","[32/200][1/2] Loss_D: 2.1843 Loss_G: 3.3976\n","[32/200][2/2] Loss_D: 1.8062 Loss_G: 3.2432\n","[33/200][1/2] Loss_D: 1.8561 Loss_G: 3.4548\n","[33/200][2/2] Loss_D: 1.7653 Loss_G: 3.5592\n","[34/200][1/2] Loss_D: 1.9032 Loss_G: 3.2870\n","[34/200][2/2] Loss_D: 2.0964 Loss_G: 4.0842\n","[35/200][1/2] Loss_D: 1.9438 Loss_G: 2.2340\n","[35/200][2/2] Loss_D: 1.9445 Loss_G: 2.6932\n","[36/200][1/2] Loss_D: 1.5896 Loss_G: 3.2198\n","[36/200][2/2] Loss_D: 1.3468 Loss_G: 2.3869\n","[37/200][1/2] Loss_D: 2.0863 Loss_G: 3.4017\n","[37/200][2/2] Loss_D: 1.7140 Loss_G: 2.7532\n","[38/200][1/2] Loss_D: 1.9356 Loss_G: 2.6495\n","[38/200][2/2] Loss_D: 1.6269 Loss_G: 2.3952\n","[39/200][1/2] Loss_D: 1.3827 Loss_G: 1.9991\n","[39/200][2/2] Loss_D: 1.4662 Loss_G: 2.2051\n","[40/200][1/2] Loss_D: 1.2417 Loss_G: 2.0482\n","[40/200][2/2] Loss_D: 1.5237 Loss_G: 2.4256\n","[41/200][1/2] Loss_D: 1.4489 Loss_G: 2.2207\n","[41/200][2/2] Loss_D: 1.9032 Loss_G: 3.0834\n","[42/200][1/2] Loss_D: 1.6066 Loss_G: 2.5428\n","[42/200][2/2] Loss_D: 1.4361 Loss_G: 1.6532\n","[43/200][1/2] Loss_D: 1.5231 Loss_G: 1.8477\n","[43/200][2/2] Loss_D: 1.3952 Loss_G: 2.0780\n","[44/200][1/2] Loss_D: 1.2943 Loss_G: 1.8455\n","[44/200][2/2] Loss_D: 1.3465 Loss_G: 2.1176\n","[45/200][1/2] Loss_D: 1.4504 Loss_G: 2.3105\n","[45/200][2/2] Loss_D: 1.2736 Loss_G: 2.1439\n","[46/200][1/2] Loss_D: 1.3739 Loss_G: 1.8631\n","[46/200][2/2] Loss_D: 1.3294 Loss_G: 1.9036\n","[47/200][1/2] Loss_D: 1.3533 Loss_G: 2.2482\n","[47/200][2/2] Loss_D: 1.2711 Loss_G: 2.1121\n","[48/200][1/2] Loss_D: 1.1332 Loss_G: 1.7701\n","[48/200][2/2] Loss_D: 1.4660 Loss_G: 1.7142\n","[49/200][1/2] Loss_D: 1.4669 Loss_G: 1.9056\n","[49/200][2/2] Loss_D: 1.4726 Loss_G: 2.0753\n","[50/200][1/2] Loss_D: 1.3917 Loss_G: 1.9323\n","[50/200][2/2] Loss_D: 1.4101 Loss_G: 1.6231\n","[51/200][1/2] Loss_D: 1.3641 Loss_G: 1.8169\n","[51/200][2/2] Loss_D: 1.4429 Loss_G: 1.9533\n","[52/200][1/2] Loss_D: 1.4081 Loss_G: 1.8338\n","[52/200][2/2] Loss_D: 1.4711 Loss_G: 2.2448\n","[53/200][1/2] Loss_D: 1.4624 Loss_G: 2.2702\n","[53/200][2/2] Loss_D: 1.5087 Loss_G: 1.7502\n","[54/200][1/2] Loss_D: 1.8048 Loss_G: 2.2604\n","[54/200][2/2] Loss_D: 1.3705 Loss_G: 2.3086\n","[55/200][1/2] Loss_D: 1.2952 Loss_G: 1.9526\n","[55/200][2/2] Loss_D: 1.5763 Loss_G: 1.8507\n","[56/200][1/2] Loss_D: 1.4959 Loss_G: 1.8157\n","[56/200][2/2] Loss_D: 1.2561 Loss_G: 1.9962\n","[57/200][1/2] Loss_D: 1.5037 Loss_G: 2.6111\n","[57/200][2/2] Loss_D: 1.2671 Loss_G: 2.7864\n","[58/200][1/2] Loss_D: 1.2172 Loss_G: 2.2877\n","[58/200][2/2] Loss_D: 1.8011 Loss_G: 3.2468\n","[59/200][1/2] Loss_D: 1.6733 Loss_G: 3.6695\n","[59/200][2/2] Loss_D: 1.6555 Loss_G: 3.4283\n","[60/200][1/2] Loss_D: 1.5527 Loss_G: 3.3832\n","[60/200][2/2] Loss_D: 1.6631 Loss_G: 5.1751\n","[61/200][1/2] Loss_D: 1.2720 Loss_G: 3.0378\n","[61/200][2/2] Loss_D: 1.0144 Loss_G: 2.6454\n","[62/200][1/2] Loss_D: 1.1924 Loss_G: 3.6196\n","[62/200][2/2] Loss_D: 1.3325 Loss_G: 3.2720\n","[63/200][1/2] Loss_D: 2.0144 Loss_G: 4.2525\n","[63/200][2/2] Loss_D: 1.6593 Loss_G: 4.1274\n","[64/200][1/2] Loss_D: 1.2388 Loss_G: 2.9600\n","[64/200][2/2] Loss_D: 1.1814 Loss_G: 2.2218\n","[65/200][1/2] Loss_D: 1.0942 Loss_G: 2.8471\n","[65/200][2/2] Loss_D: 0.8585 Loss_G: 2.8209\n","[66/200][1/2] Loss_D: 0.9086 Loss_G: 2.8007\n","[66/200][2/2] Loss_D: 1.3198 Loss_G: 2.9322\n","[67/200][1/2] Loss_D: 1.2948 Loss_G: 3.1915\n","[67/200][2/2] Loss_D: 1.2174 Loss_G: 3.2149\n","[68/200][1/2] Loss_D: 1.4827 Loss_G: 2.8888\n","[68/200][2/2] Loss_D: 1.1509 Loss_G: 3.0442\n","[69/200][1/2] Loss_D: 1.1278 Loss_G: 2.6389\n","[69/200][2/2] Loss_D: 1.2749 Loss_G: 2.4987\n","[70/200][1/2] Loss_D: 1.2687 Loss_G: 2.4797\n","[70/200][2/2] Loss_D: 1.4448 Loss_G: 2.4667\n","[71/200][1/2] Loss_D: 1.3640 Loss_G: 2.4337\n","[71/200][2/2] Loss_D: 1.1962 Loss_G: 2.2641\n","[72/200][1/2] Loss_D: 1.3750 Loss_G: 2.3514\n","[72/200][2/2] Loss_D: 1.6406 Loss_G: 2.7410\n","[73/200][1/2] Loss_D: 1.1104 Loss_G: 2.9631\n","[73/200][2/2] Loss_D: 1.0402 Loss_G: 2.2646\n","[74/200][1/2] Loss_D: 1.0914 Loss_G: 1.8881\n","[74/200][2/2] Loss_D: 1.1293 Loss_G: 2.3335\n","[75/200][1/2] Loss_D: 1.3133 Loss_G: 2.2732\n","[75/200][2/2] Loss_D: 1.4070 Loss_G: 2.4264\n","[76/200][1/2] Loss_D: 1.7109 Loss_G: 2.8785\n","[76/200][2/2] Loss_D: 1.1644 Loss_G: 2.7813\n","[77/200][1/2] Loss_D: 1.2375 Loss_G: 1.9014\n","[77/200][2/2] Loss_D: 1.3299 Loss_G: 2.0955\n","[78/200][1/2] Loss_D: 1.3065 Loss_G: 2.0453\n","[78/200][2/2] Loss_D: 1.1818 Loss_G: 1.8559\n","[79/200][1/2] Loss_D: 1.0464 Loss_G: 1.6815\n","[79/200][2/2] Loss_D: 1.1153 Loss_G: 1.6946\n","[80/200][1/2] Loss_D: 0.9387 Loss_G: 1.9667\n","[80/200][2/2] Loss_D: 0.9855 Loss_G: 1.9942\n","[81/200][1/2] Loss_D: 0.9502 Loss_G: 1.9533\n","[81/200][2/2] Loss_D: 0.9041 Loss_G: 1.9203\n","[82/200][1/2] Loss_D: 0.9557 Loss_G: 1.8274\n","[82/200][2/2] Loss_D: 1.0311 Loss_G: 1.7612\n","[83/200][1/2] Loss_D: 1.2025 Loss_G: 1.9677\n","[83/200][2/2] Loss_D: 1.0762 Loss_G: 1.6534\n","[84/200][1/2] Loss_D: 1.2021 Loss_G: 1.7213\n","[84/200][2/2] Loss_D: 1.1426 Loss_G: 1.7025\n","[85/200][1/2] Loss_D: 1.0522 Loss_G: 1.6100\n","[85/200][2/2] Loss_D: 0.9378 Loss_G: 1.6956\n","[86/200][1/2] Loss_D: 1.1175 Loss_G: 1.5749\n","[86/200][2/2] Loss_D: 1.1281 Loss_G: 1.8609\n","[87/200][1/2] Loss_D: 1.3804 Loss_G: 1.8024\n","[87/200][2/2] Loss_D: 1.0626 Loss_G: 2.0271\n","[88/200][1/2] Loss_D: 0.9789 Loss_G: 1.9778\n","[88/200][2/2] Loss_D: 0.9203 Loss_G: 1.9328\n","[89/200][1/2] Loss_D: 0.9026 Loss_G: 1.9196\n","[89/200][2/2] Loss_D: 1.2399 Loss_G: 1.5751\n","[90/200][1/2] Loss_D: 1.1863 Loss_G: 1.5545\n","[90/200][2/2] Loss_D: 1.2210 Loss_G: 1.7331\n","[91/200][1/2] Loss_D: 1.0583 Loss_G: 1.7823\n","[91/200][2/2] Loss_D: 1.1384 Loss_G: 1.5518\n","[92/200][1/2] Loss_D: 1.0811 Loss_G: 1.5356\n","[92/200][2/2] Loss_D: 1.0397 Loss_G: 1.7209\n","[93/200][1/2] Loss_D: 0.9535 Loss_G: 1.7543\n","[93/200][2/2] Loss_D: 0.9538 Loss_G: 1.5649\n","[94/200][1/2] Loss_D: 1.0001 Loss_G: 1.6137\n","[94/200][2/2] Loss_D: 0.9940 Loss_G: 1.8980\n","[95/200][1/2] Loss_D: 0.8862 Loss_G: 1.9132\n","[95/200][2/2] Loss_D: 0.9917 Loss_G: 1.4277\n","[96/200][1/2] Loss_D: 1.0051 Loss_G: 1.6263\n","[96/200][2/2] Loss_D: 1.0770 Loss_G: 1.9746\n","[97/200][1/2] Loss_D: 1.0833 Loss_G: 1.9161\n","[97/200][2/2] Loss_D: 1.1647 Loss_G: 1.7574\n","[98/200][1/2] Loss_D: 1.0575 Loss_G: 1.7808\n","[98/200][2/2] Loss_D: 1.2280 Loss_G: 1.8129\n","[99/200][1/2] Loss_D: 1.0910 Loss_G: 1.6576\n","[99/200][2/2] Loss_D: 1.0565 Loss_G: 1.6086\n","[100/200][1/2] Loss_D: 1.0721 Loss_G: 1.5770\n","[100/200][2/2] Loss_D: 1.1656 Loss_G: 1.8110\n","[101/200][1/2] Loss_D: 1.0408 Loss_G: 1.7024\n","[101/200][2/2] Loss_D: 1.0112 Loss_G: 1.6641\n","[102/200][1/2] Loss_D: 0.8949 Loss_G: 1.8636\n","[102/200][2/2] Loss_D: 1.0854 Loss_G: 1.7389\n","[103/200][1/2] Loss_D: 1.0236 Loss_G: 1.7239\n","[103/200][2/2] Loss_D: 1.0266 Loss_G: 2.0002\n","[104/200][1/2] Loss_D: 1.0929 Loss_G: 1.6200\n","[104/200][2/2] Loss_D: 1.0242 Loss_G: 2.0503\n","[105/200][1/2] Loss_D: 0.9406 Loss_G: 2.0133\n","[105/200][2/2] Loss_D: 1.0451 Loss_G: 1.7312\n","[106/200][1/2] Loss_D: 0.9484 Loss_G: 1.6667\n","[106/200][2/2] Loss_D: 0.9784 Loss_G: 2.1865\n","[107/200][1/2] Loss_D: 1.0022 Loss_G: 1.6504\n","[107/200][2/2] Loss_D: 0.9583 Loss_G: 1.6460\n","[108/200][1/2] Loss_D: 1.0939 Loss_G: 1.9667\n","[108/200][2/2] Loss_D: 1.1444 Loss_G: 1.6373\n","[109/200][1/2] Loss_D: 1.1209 Loss_G: 1.6751\n","[109/200][2/2] Loss_D: 1.0635 Loss_G: 1.8368\n","[110/200][1/2] Loss_D: 0.9414 Loss_G: 1.9127\n","[110/200][2/2] Loss_D: 0.9725 Loss_G: 1.8840\n","[111/200][1/2] Loss_D: 0.9506 Loss_G: 1.9696\n","[111/200][2/2] Loss_D: 0.9275 Loss_G: 1.9854\n","[112/200][1/2] Loss_D: 0.8784 Loss_G: 2.0212\n","[112/200][2/2] Loss_D: 0.9635 Loss_G: 2.1488\n","[113/200][1/2] Loss_D: 0.9705 Loss_G: 2.0435\n","[113/200][2/2] Loss_D: 0.9331 Loss_G: 1.8212\n","[114/200][1/2] Loss_D: 0.8932 Loss_G: 2.1946\n","[114/200][2/2] Loss_D: 1.0850 Loss_G: 1.6354\n","[115/200][1/2] Loss_D: 0.9301 Loss_G: 2.0358\n","[115/200][2/2] Loss_D: 1.0387 Loss_G: 1.5365\n","[116/200][1/2] Loss_D: 0.8321 Loss_G: 1.5420\n","[116/200][2/2] Loss_D: 0.9160 Loss_G: 1.6950\n","[117/200][1/2] Loss_D: 0.8327 Loss_G: 1.9596\n","[117/200][2/2] Loss_D: 0.9052 Loss_G: 1.6361\n","[118/200][1/2] Loss_D: 0.8592 Loss_G: 2.1340\n","[118/200][2/2] Loss_D: 0.8239 Loss_G: 2.3907\n","[119/200][1/2] Loss_D: 0.7927 Loss_G: 1.9631\n","[119/200][2/2] Loss_D: 0.7944 Loss_G: 2.3082\n","[120/200][1/2] Loss_D: 0.8813 Loss_G: 1.9226\n","[120/200][2/2] Loss_D: 0.8565 Loss_G: 1.9777\n","[121/200][1/2] Loss_D: 0.8307 Loss_G: 2.0808\n","[121/200][2/2] Loss_D: 0.9797 Loss_G: 1.6571\n","[122/200][1/2] Loss_D: 0.8361 Loss_G: 1.7513\n","[122/200][2/2] Loss_D: 0.9578 Loss_G: 1.8240\n","[123/200][1/2] Loss_D: 0.9729 Loss_G: 1.7658\n","[123/200][2/2] Loss_D: 0.9712 Loss_G: 2.0413\n","[124/200][1/2] Loss_D: 0.9956 Loss_G: 2.5525\n","[124/200][2/2] Loss_D: 1.1845 Loss_G: 1.9792\n","[125/200][1/2] Loss_D: 1.1126 Loss_G: 2.0096\n","[125/200][2/2] Loss_D: 0.9545 Loss_G: 2.5605\n","[126/200][1/2] Loss_D: 0.9306 Loss_G: 2.4995\n","[126/200][2/2] Loss_D: 0.7755 Loss_G: 2.2423\n","[127/200][1/2] Loss_D: 0.8645 Loss_G: 2.1977\n","[127/200][2/2] Loss_D: 0.8600 Loss_G: 2.7723\n","[128/200][1/2] Loss_D: 0.9656 Loss_G: 2.1799\n","[128/200][2/2] Loss_D: 1.0603 Loss_G: 2.0848\n","[129/200][1/2] Loss_D: 0.8780 Loss_G: 2.4411\n","[129/200][2/2] Loss_D: 0.9824 Loss_G: 1.5335\n","[130/200][1/2] Loss_D: 0.8325 Loss_G: 2.6056\n","[130/200][2/2] Loss_D: 0.8122 Loss_G: 2.2187\n","[131/200][1/2] Loss_D: 0.8106 Loss_G: 1.8943\n","[131/200][2/2] Loss_D: 0.8280 Loss_G: 1.7207\n","[132/200][1/2] Loss_D: 0.7900 Loss_G: 1.9386\n","[132/200][2/2] Loss_D: 1.0251 Loss_G: 1.1605\n","[133/200][1/2] Loss_D: 1.0566 Loss_G: 2.2331\n","[133/200][2/2] Loss_D: 0.8590 Loss_G: 1.9708\n","[134/200][1/2] Loss_D: 0.9094 Loss_G: 1.5492\n","[134/200][2/2] Loss_D: 1.0051 Loss_G: 2.3911\n","[135/200][1/2] Loss_D: 1.0664 Loss_G: 1.7889\n","[135/200][2/2] Loss_D: 0.9830 Loss_G: 1.5529\n","[136/200][1/2] Loss_D: 0.9518 Loss_G: 1.7711\n","[136/200][2/2] Loss_D: 0.9605 Loss_G: 1.9660\n","[137/200][1/2] Loss_D: 0.9101 Loss_G: 1.4967\n","[137/200][2/2] Loss_D: 0.8777 Loss_G: 1.6417\n","[138/200][1/2] Loss_D: 0.9777 Loss_G: 2.1202\n","[138/200][2/2] Loss_D: 1.1055 Loss_G: 1.9586\n","[139/200][1/2] Loss_D: 1.0423 Loss_G: 1.8427\n","[139/200][2/2] Loss_D: 0.9163 Loss_G: 2.2005\n","[140/200][1/2] Loss_D: 0.9345 Loss_G: 1.7941\n","[140/200][2/2] Loss_D: 1.0404 Loss_G: 1.5450\n","[141/200][1/2] Loss_D: 0.9624 Loss_G: 1.7458\n","[141/200][2/2] Loss_D: 0.9078 Loss_G: 2.3962\n","[142/200][1/2] Loss_D: 0.9278 Loss_G: 2.2353\n","[142/200][2/2] Loss_D: 1.0260 Loss_G: 2.0059\n","[143/200][1/2] Loss_D: 0.9832 Loss_G: 2.3886\n","[143/200][2/2] Loss_D: 1.0227 Loss_G: 2.2624\n","[144/200][1/2] Loss_D: 0.9412 Loss_G: 2.1837\n","[144/200][2/2] Loss_D: 0.9403 Loss_G: 2.1331\n","[145/200][1/2] Loss_D: 1.0937 Loss_G: 2.9580\n","[145/200][2/2] Loss_D: 0.7905 Loss_G: 2.6294\n","[146/200][1/2] Loss_D: 0.9836 Loss_G: 2.4501\n","[146/200][2/2] Loss_D: 1.1696 Loss_G: 3.0220\n","[147/200][1/2] Loss_D: 0.9482 Loss_G: 2.7948\n","[147/200][2/2] Loss_D: 0.9349 Loss_G: 2.3722\n","[148/200][1/2] Loss_D: 0.9536 Loss_G: 2.6691\n","[148/200][2/2] Loss_D: 0.8173 Loss_G: 2.5612\n","[149/200][1/2] Loss_D: 0.9629 Loss_G: 2.0148\n","[149/200][2/2] Loss_D: 0.9566 Loss_G: 1.9824\n","[150/200][1/2] Loss_D: 0.9595 Loss_G: 2.2498\n","[150/200][2/2] Loss_D: 1.0103 Loss_G: 1.7025\n","[151/200][1/2] Loss_D: 0.9250 Loss_G: 1.6809\n","[151/200][2/2] Loss_D: 0.8648 Loss_G: 2.1315\n","[152/200][1/2] Loss_D: 0.7976 Loss_G: 1.9500\n","[152/200][2/2] Loss_D: 0.7848 Loss_G: 1.9230\n","[153/200][1/2] Loss_D: 0.8212 Loss_G: 2.0552\n","[153/200][2/2] Loss_D: 0.7299 Loss_G: 2.0688\n","[154/200][1/2] Loss_D: 0.8253 Loss_G: 1.9532\n","[154/200][2/2] Loss_D: 0.9041 Loss_G: 1.9964\n","[155/200][1/2] Loss_D: 0.8054 Loss_G: 1.8298\n","[155/200][2/2] Loss_D: 0.8728 Loss_G: 1.7464\n","[156/200][1/2] Loss_D: 1.0743 Loss_G: 2.2239\n","[156/200][2/2] Loss_D: 1.1463 Loss_G: 1.4683\n","[157/200][1/2] Loss_D: 0.9576 Loss_G: 1.6153\n","[157/200][2/2] Loss_D: 0.9903 Loss_G: 2.3949\n","[158/200][1/2] Loss_D: 0.9077 Loss_G: 1.8893\n","[158/200][2/2] Loss_D: 0.8756 Loss_G: 1.6403\n","[159/200][1/2] Loss_D: 0.8346 Loss_G: 2.1645\n","[159/200][2/2] Loss_D: 0.7146 Loss_G: 2.0101\n","[160/200][1/2] Loss_D: 0.8213 Loss_G: 1.6821\n","[160/200][2/2] Loss_D: 0.9894 Loss_G: 1.7561\n","[161/200][1/2] Loss_D: 0.9429 Loss_G: 1.7003\n","[161/200][2/2] Loss_D: 0.8518 Loss_G: 1.7473\n","[162/200][1/2] Loss_D: 0.9836 Loss_G: 1.9289\n","[162/200][2/2] Loss_D: 0.8426 Loss_G: 1.8138\n","[163/200][1/2] Loss_D: 0.9733 Loss_G: 1.5488\n","[163/200][2/2] Loss_D: 0.8914 Loss_G: 1.9584\n","[164/200][1/2] Loss_D: 0.9628 Loss_G: 1.5465\n","[164/200][2/2] Loss_D: 0.8987 Loss_G: 1.8881\n","[165/200][1/2] Loss_D: 0.8525 Loss_G: 2.0551\n","[165/200][2/2] Loss_D: 1.0598 Loss_G: 1.5455\n","[166/200][1/2] Loss_D: 1.0564 Loss_G: 2.1501\n","[166/200][2/2] Loss_D: 0.9607 Loss_G: 2.1905\n","[167/200][1/2] Loss_D: 0.8624 Loss_G: 2.0242\n","[167/200][2/2] Loss_D: 1.0251 Loss_G: 2.1008\n","[168/200][1/2] Loss_D: 0.9089 Loss_G: 2.2129\n","[168/200][2/2] Loss_D: 0.7784 Loss_G: 2.0749\n","[169/200][1/2] Loss_D: 0.8465 Loss_G: 2.4094\n","[169/200][2/2] Loss_D: 0.7429 Loss_G: 2.0662\n","[170/200][1/2] Loss_D: 0.9405 Loss_G: 2.1642\n","[170/200][2/2] Loss_D: 0.9294 Loss_G: 2.1261\n","[171/200][1/2] Loss_D: 0.8507 Loss_G: 1.9906\n","[171/200][2/2] Loss_D: 0.9507 Loss_G: 1.8103\n","[172/200][1/2] Loss_D: 0.8667 Loss_G: 2.0985\n","[172/200][2/2] Loss_D: 0.9724 Loss_G: 1.8599\n","[173/200][1/2] Loss_D: 0.8324 Loss_G: 1.9373\n","[173/200][2/2] Loss_D: 0.7319 Loss_G: 1.8940\n","[174/200][1/2] Loss_D: 0.8207 Loss_G: 2.2518\n","[174/200][2/2] Loss_D: 0.7709 Loss_G: 2.0216\n","[175/200][1/2] Loss_D: 0.7895 Loss_G: 1.9856\n","[175/200][2/2] Loss_D: 0.7697 Loss_G: 1.9347\n","[176/200][1/2] Loss_D: 0.8841 Loss_G: 2.0876\n","[176/200][2/2] Loss_D: 0.9752 Loss_G: 2.1438\n","[177/200][1/2] Loss_D: 0.9357 Loss_G: 2.0493\n","[177/200][2/2] Loss_D: 0.7985 Loss_G: 2.7435\n","[178/200][1/2] Loss_D: 0.7390 Loss_G: 2.0979\n","[178/200][2/2] Loss_D: 0.8241 Loss_G: 1.8853\n","[179/200][1/2] Loss_D: 0.8716 Loss_G: 2.6931\n","[179/200][2/2] Loss_D: 0.9411 Loss_G: 1.6787\n","[180/200][1/2] Loss_D: 0.9601 Loss_G: 2.5199\n","[180/200][2/2] Loss_D: 0.8221 Loss_G: 2.1495\n","[181/200][1/2] Loss_D: 0.8184 Loss_G: 2.1232\n","[181/200][2/2] Loss_D: 0.8817 Loss_G: 1.9960\n","[182/200][1/2] Loss_D: 0.8425 Loss_G: 2.0508\n","[182/200][2/2] Loss_D: 0.8263 Loss_G: 1.8265\n","[183/200][1/2] Loss_D: 0.8791 Loss_G: 2.3006\n","[183/200][2/2] Loss_D: 0.9291 Loss_G: 1.6849\n","[184/200][1/2] Loss_D: 0.8527 Loss_G: 2.1931\n","[184/200][2/2] Loss_D: 0.7970 Loss_G: 1.9369\n","[185/200][1/2] Loss_D: 0.8395 Loss_G: 1.8697\n","[185/200][2/2] Loss_D: 0.9360 Loss_G: 1.8077\n","[186/200][1/2] Loss_D: 0.8410 Loss_G: 2.0138\n","[186/200][2/2] Loss_D: 0.8477 Loss_G: 2.1388\n","[187/200][1/2] Loss_D: 0.8622 Loss_G: 1.9610\n","[187/200][2/2] Loss_D: 0.9753 Loss_G: 2.4159\n","[188/200][1/2] Loss_D: 0.8796 Loss_G: 1.9890\n","[188/200][2/2] Loss_D: 0.9668 Loss_G: 1.6486\n","[189/200][1/2] Loss_D: 0.9308 Loss_G: 2.8315\n","[189/200][2/2] Loss_D: 1.0195 Loss_G: 1.7085\n","[190/200][1/2] Loss_D: 0.8195 Loss_G: 1.9155\n","[190/200][2/2] Loss_D: 0.8390 Loss_G: 2.3905\n","[191/200][1/2] Loss_D: 0.9136 Loss_G: 1.9937\n","[191/200][2/2] Loss_D: 1.0440 Loss_G: 2.0241\n","[192/200][1/2] Loss_D: 0.9326 Loss_G: 1.8926\n","[192/200][2/2] Loss_D: 0.9018 Loss_G: 1.7704\n","[193/200][1/2] Loss_D: 0.8297 Loss_G: 1.7337\n","[193/200][2/2] Loss_D: 0.9335 Loss_G: 1.9465\n","[194/200][1/2] Loss_D: 0.9477 Loss_G: 2.3750\n","[194/200][2/2] Loss_D: 0.9840 Loss_G: 1.4996\n","[195/200][1/2] Loss_D: 0.9317 Loss_G: 2.3975\n","[195/200][2/2] Loss_D: 0.8503 Loss_G: 1.9235\n","[196/200][1/2] Loss_D: 0.8143 Loss_G: 1.8066\n","[196/200][2/2] Loss_D: 0.8583 Loss_G: 1.8290\n","[197/200][1/2] Loss_D: 0.9462 Loss_G: 2.0681\n","[197/200][2/2] Loss_D: 1.0280 Loss_G: 1.6036\n","[198/200][1/2] Loss_D: 0.9993 Loss_G: 1.8581\n","[198/200][2/2] Loss_D: 0.9289 Loss_G: 1.7231\n","[199/200][1/2] Loss_D: 0.9801 Loss_G: 2.0649\n","[199/200][2/2] Loss_D: 0.9296 Loss_G: 1.7226\n","[200/200][1/2] Loss_D: 0.8816 Loss_G: 1.9849\n","[200/200][2/2] Loss_D: 0.8514 Loss_G: 1.9403\n"]}]},{"cell_type":"code","source":["# Guardamos el modelo en un archivo .pth\n","gen_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models/generator.pth'\n","dis_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models/discriminator.pth'\n","\n","torch.save(netG.state_dict(), gen_path)\n","torch.save(netD.state_dict(), dis_path)\n","\n","# Función para generar una imagen aleatoria y guardarla en un archivo .jpg\n","def generar_imagen_aleatoria(generator_path, output_path):\n","    # Cargamos los pesos del generador desde el archivo .pth\n","    generator = G()\n","    generator.load_state_dict(torch.load(generator_path))\n","    generator.eval()\n","\n","    # Generamos una imagen aleatoria\n","    with torch.no_grad():\n","        noise = torch.randn(1, 100, 1, 1)\n","        imagen_generada = generator(noise)\n","\n","    # Guardamos la imagen generada en un archivo .jpg\n","    vutils.save_image(imagen_generada, output_path, normalize=True)"],"metadata":{"id":"5pWH3V48K2Cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generamos 100 imágenes y las almacenamos\n","try:\n","    os.mkdir('/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models/fotos_generadas')\n","except OSError as e:\n","    if e.errno != errno.EEXIST:\n","        raise\n","\n","gen_path = '/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models/generator.pth'\n","for i in range(100):\n","  generar_imagen_aleatoria(gen_path, f\"/content/gdrive/MyDrive/Dev/AI_MsC/TFM/BestNotebooks/GAN-Simple_Pablo_v3/models/fotos_generadas/output_{i}.jpg\")"],"metadata":{"id":"TiMj2z3nLpQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qvnnCETJvCD5"},"execution_count":null,"outputs":[]}]}